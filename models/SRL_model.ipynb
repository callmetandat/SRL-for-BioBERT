{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../data_transformations.py --transform_file 'transform_file_conll.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-07 14:01:57.402333: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-07 14:01:57.446626: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-07 14:01:58.137210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Current Directory:  /mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/models../data/coNLL_tsv\n",
      "task object created from task file...\n",
      "bert model tokenizer loaded for config bert-base-uncased\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_train.tsv\n",
      "Processing Started...\n",
      "Data Size:  41740\n",
      "number of threads:  7\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|▏                                       | 29/5962 [00:00<00:20, 284.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|▏                                       | 20/5962 [00:00<00:29, 199.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|▏                                       | 21/5962 [00:00<00:31, 191.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "  0%|▏                                       | 21/5962 [00:00<00:30, 194.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 58/5962 [00:00<00:24, 237.99it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                        | 14/5962 [00:00<00:47, 124.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▎                                       | 41/5962 [00:00<00:33, 175.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                        | 13/5962 [00:00<00:48, 123.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▎                                       | 41/5962 [00:00<00:38, 152.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                        | 20/5962 [00:00<01:07, 87.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▌                                       | 83/5962 [00:00<00:32, 181.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                       | 27/5962 [00:00<00:57, 102.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                       | 26/5962 [00:00<00:47, 124.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  1%|▍                                       | 59/5962 [00:00<00:38, 151.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "  1%|▍                                       | 57/5962 [00:00<00:39, 150.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏                                        | 31/5962 [00:00<01:03, 93.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 47/5962 [00:00<00:42, 140.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▍                                       | 73/5962 [00:00<00:41, 141.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 44/5962 [00:00<00:41, 141.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▌                                       | 77/5962 [00:00<00:35, 166.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 42/5962 [00:00<01:01, 96.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  2%|▋                                      | 103/5962 [00:00<00:39, 147.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 71/5962 [00:00<00:33, 175.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▌                                       | 88/5962 [00:00<00:42, 136.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 63/5962 [00:00<00:37, 158.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 54/5962 [00:00<00:57, 102.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 119/5962 [00:00<00:42, 137.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 115/5962 [00:00<00:32, 179.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                       | 79/5962 [00:00<00:39, 149.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 66/5962 [00:00<00:55, 106.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  2%|▋                                      | 111/5962 [00:00<00:37, 157.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 115/5962 [00:00<00:29, 198.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▉                                      | 134/5962 [00:00<00:32, 178.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 95/5962 [00:00<00:38, 150.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                       | 81/5962 [00:00<00:50, 116.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▊                                      | 125/5962 [00:00<00:40, 142.40it/s]\u001b[A\u001b[A\n",
      "  2%|▊                                      | 127/5962 [00:00<00:39, 146.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▉                                      | 150/5962 [00:00<00:41, 140.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▉                                      | 152/5962 [00:00<00:33, 170.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▉                                      | 148/5962 [00:00<00:35, 166.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▌                                       | 93/5962 [00:00<00:56, 104.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  2%|▉                                      | 142/5962 [00:00<00:42, 136.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                      | 157/5962 [00:00<00:29, 194.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                      | 165/5962 [00:01<00:46, 125.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█                                      | 170/5962 [00:01<00:38, 151.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 104/5962 [00:01<01:00, 97.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█                                      | 166/5962 [00:01<00:41, 139.82it/s]\u001b[A\u001b[A\n",
      "  3%|█                                      | 156/5962 [00:01<00:47, 122.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                     | 178/5962 [00:01<00:48, 119.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 124/5962 [00:01<00:56, 102.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▏                                     | 186/5962 [00:01<00:41, 138.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 116/5962 [00:01<00:58, 100.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▏                                     | 181/5962 [00:01<00:43, 133.74it/s]\u001b[A\u001b[A\n",
      "  3%|█                                      | 169/5962 [00:01<00:48, 118.89it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                     | 196/5962 [00:01<00:36, 159.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▏                                     | 191/5962 [00:01<00:51, 112.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                       | 127/5962 [00:01<01:00, 96.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                       | 136/5962 [00:01<01:00, 95.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  3%|█▏                                     | 182/5962 [00:01<00:48, 119.32it/s]\u001b[A\n",
      "\n",
      "  3%|█▎                                     | 196/5962 [00:01<00:45, 127.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▎                                     | 205/5962 [00:01<00:49, 116.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "  3%|█▎                                     | 199/5962 [00:01<00:43, 132.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 213/5962 [00:01<00:42, 134.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                       | 137/5962 [00:01<01:04, 89.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                       | 147/5962 [00:01<01:04, 90.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▎                                     | 210/5962 [00:01<00:46, 123.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 217/5962 [00:01<00:51, 111.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▍                                     | 218/5962 [00:01<00:39, 146.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 158/5962 [00:01<01:02, 93.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▍                                     | 227/5962 [00:01<00:42, 134.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                       | 147/5962 [00:01<01:09, 83.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 228/5962 [00:01<00:46, 123.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 230/5962 [00:01<00:49, 116.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▌                                     | 236/5962 [00:01<00:37, 153.36it/s]\u001b[A\n",
      "\n",
      "  4%|█▌                                     | 244/5962 [00:01<00:40, 142.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                      | 168/5962 [00:01<01:02, 92.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 156/5962 [00:01<01:08, 84.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 242/5962 [00:01<00:50, 112.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 241/5962 [00:01<00:51, 110.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▋                                     | 252/5962 [00:01<00:39, 146.20it/s]\u001b[A\n",
      "\n",
      "  4%|█▋                                     | 260/5962 [00:01<00:38, 146.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                      | 178/5962 [00:01<01:05, 88.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 165/5962 [00:01<01:12, 80.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 255/5962 [00:01<00:49, 114.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▋                                     | 267/5962 [00:01<00:39, 145.87it/s]\u001b[A\n",
      "\n",
      "  5%|█▊                                     | 277/5962 [00:01<00:37, 151.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 253/5962 [00:01<00:56, 101.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 188/5962 [00:01<01:04, 89.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 297/5962 [00:01<00:37, 152.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                     | 268/5962 [00:02<00:48, 116.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▊                                     | 283/5962 [00:01<00:38, 148.52it/s]\u001b[A\n",
      "\n",
      "  5%|█▉                                     | 297/5962 [00:02<00:35, 160.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                      | 264/5962 [00:01<00:56, 99.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 198/5962 [00:01<01:03, 90.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|██                                     | 313/5962 [00:02<00:38, 148.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                     | 280/5962 [00:02<00:49, 113.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▉                                     | 298/5962 [00:02<00:38, 147.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                     | 284/5962 [00:02<00:46, 122.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  5%|██                                     | 314/5962 [00:02<00:37, 151.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▍                                      | 208/5962 [00:01<01:06, 86.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 328/5962 [00:02<00:38, 147.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 193/5962 [00:02<01:12, 79.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▉                                     | 292/5962 [00:02<00:53, 105.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 305/5962 [00:02<00:39, 142.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▏                                    | 332/5962 [00:02<00:35, 158.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 217/5962 [00:02<01:05, 87.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 345/5962 [00:02<00:36, 152.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 303/5962 [00:02<00:55, 102.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▎                                    | 349/5962 [00:02<00:35, 158.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                     | 321/5962 [00:02<00:40, 140.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 361/5962 [00:02<00:36, 153.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▏                                    | 328/5962 [00:02<00:49, 112.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                     | 316/5962 [00:02<00:53, 106.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▍                                    | 365/5962 [00:02<00:37, 150.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 210/5962 [00:02<01:32, 61.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                     | 327/5962 [00:02<01:04, 87.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                      | 234/5962 [00:02<01:38, 58.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▎                                     | 341/5962 [00:02<01:05, 85.56it/s]\u001b[A\n",
      "\n",
      "  6%|██▍                                    | 381/5962 [00:02<00:45, 121.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 377/5962 [00:02<00:55, 100.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 217/5962 [00:02<01:46, 54.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                     | 337/5962 [00:02<01:02, 90.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▎                                     | 353/5962 [00:02<01:02, 90.26it/s]\u001b[A\n",
      "\n",
      "  7%|██▌                                    | 395/5962 [00:02<00:49, 112.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                      | 241/5962 [00:02<01:49, 52.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                     | 347/5962 [00:02<01:05, 85.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▍                                     | 365/5962 [00:02<00:59, 94.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▌                                     | 390/5962 [00:02<01:07, 82.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▋                                    | 407/5962 [00:02<00:50, 110.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                     | 359/5962 [00:03<01:01, 90.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                      | 229/5962 [00:02<01:59, 47.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                      | 247/5962 [00:02<02:01, 46.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▌                                     | 376/5962 [00:03<01:02, 89.44it/s]\u001b[A\n",
      "\n",
      "  7%|██▋                                    | 419/5962 [00:03<00:50, 110.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                     | 369/5962 [00:03<01:01, 91.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▋                                     | 401/5962 [00:03<01:16, 72.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                      | 234/5962 [00:03<02:09, 44.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▊                                    | 432/5962 [00:03<00:49, 110.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▌                                    | 395/5962 [00:03<00:52, 105.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▌                                     | 379/5962 [00:03<01:00, 92.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▌                                     | 386/5962 [00:03<01:12, 76.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                      | 240/5962 [00:03<01:59, 47.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                      | 258/5962 [00:03<02:11, 43.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▌                                     | 390/5962 [00:03<01:04, 86.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                      | 249/5962 [00:03<01:41, 56.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▊                                     | 422/5962 [00:03<01:09, 80.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                      | 263/5962 [00:03<02:12, 43.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▉                                     | 444/5962 [00:03<01:08, 80.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▊                                     | 418/5962 [00:03<00:56, 97.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▋                                     | 404/5962 [00:03<00:56, 98.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                      | 257/5962 [00:03<01:34, 60.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▉                                     | 433/5962 [00:03<01:05, 84.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███                                     | 457/5962 [00:03<01:00, 90.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                      | 269/5962 [00:03<02:02, 46.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▊                                    | 427/5962 [00:03<00:42, 131.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▊                                     | 410/5962 [00:03<01:12, 76.86it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                      | 264/5962 [00:03<01:31, 62.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▉                                     | 445/5962 [00:03<00:59, 92.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                      | 278/5962 [00:03<01:39, 56.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███▏                                    | 468/5962 [00:03<00:58, 93.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|██▉                                    | 452/5962 [00:03<00:42, 128.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▉                                    | 445/5962 [00:03<00:38, 143.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "  8%|███                                    | 462/5962 [00:03<00:49, 111.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                      | 275/5962 [00:03<01:17, 73.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                     | 311/5962 [00:03<00:44, 127.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 466/5962 [00:03<00:43, 126.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  8%|██▉                                    | 453/5962 [00:03<00:41, 131.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "  8%|███                                    | 464/5962 [00:03<00:35, 153.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███▏                                    | 479/5962 [00:03<01:02, 87.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                      | 287/5962 [00:03<01:07, 84.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 339/5962 [00:03<00:33, 167.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 483/5962 [00:03<00:40, 135.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  8%|███                                    | 475/5962 [00:03<00:36, 152.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 480/5962 [00:03<00:36, 151.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 303/5962 [00:03<00:54, 103.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 358/5962 [00:03<00:34, 163.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 501/5962 [00:03<00:37, 147.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 497/5962 [00:04<00:34, 156.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███▎                                    | 499/5962 [00:04<01:01, 89.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                     | 317/5962 [00:03<00:49, 113.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 376/5962 [00:03<00:34, 162.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 520/5962 [00:03<00:34, 157.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 521/5962 [00:04<00:30, 179.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 334/5962 [00:04<00:44, 127.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▍                                    | 511/5962 [00:04<00:57, 94.93it/s]\u001b[A\u001b[A\n",
      "  9%|███▎                                   | 510/5962 [00:04<00:38, 141.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 552/5962 [00:04<00:25, 214.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 578/5962 [00:04<00:26, 201.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▌                                    | 393/5962 [00:04<00:36, 152.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▍                                   | 529/5962 [00:04<00:47, 115.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 348/5962 [00:04<00:45, 123.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 599/5962 [00:04<00:27, 198.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▌                                   | 541/5962 [00:04<00:47, 114.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 409/5962 [00:04<00:38, 143.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 574/5962 [00:04<00:27, 196.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▍                                   | 526/5962 [00:04<00:47, 115.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 361/5962 [00:04<00:49, 112.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|████                                   | 625/5962 [00:04<00:25, 212.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▋                                   | 570/5962 [00:04<00:33, 159.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 595/5962 [00:04<00:27, 194.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 378/5962 [00:04<00:43, 127.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▌                                   | 539/5962 [00:04<00:49, 108.49it/s]\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 651/5962 [00:04<00:23, 224.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                    | 443/5962 [00:04<00:35, 153.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▊                                   | 587/5962 [00:04<00:34, 154.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 589/5962 [00:04<00:37, 142.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 615/5962 [00:04<00:31, 169.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▌                                   | 551/5962 [00:04<00:53, 100.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 462/5962 [00:04<00:34, 161.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 674/5962 [00:04<00:25, 205.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|████                                   | 616/5962 [00:04<00:28, 189.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 405/5962 [00:04<00:43, 127.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 633/5962 [00:04<00:32, 162.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 483/5962 [00:04<00:31, 173.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 703/5962 [00:04<00:23, 228.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████▏                                  | 636/5962 [00:04<00:29, 181.60it/s]\u001b[A\u001b[A\n",
      "  9%|███▊                                    | 562/5962 [00:04<00:57, 93.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 623/5962 [00:04<00:37, 142.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 650/5962 [00:04<00:32, 163.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 501/5962 [00:04<00:33, 164.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 727/5962 [00:04<00:23, 220.82it/s]\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▊                                    | 572/5962 [00:04<00:57, 93.38it/s]\u001b[A\n",
      "\n",
      " 11%|████▎                                  | 655/5962 [00:04<00:29, 178.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 673/5962 [00:04<00:29, 179.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 519/5962 [00:04<00:32, 166.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 755/5962 [00:04<00:22, 235.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                     | 430/5962 [00:04<00:55, 99.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▊                                   | 589/5962 [00:04<00:48, 111.05it/s]\u001b[A\n",
      "\n",
      " 12%|████▌                                  | 699/5962 [00:05<00:26, 201.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 655/5962 [00:04<00:37, 142.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 536/5962 [00:04<00:32, 166.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████                                  | 779/5962 [00:05<00:22, 227.55it/s]\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▉                                   | 611/5962 [00:05<00:39, 136.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 720/5962 [00:05<00:26, 200.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 12%|████▌                                  | 693/5962 [00:05<00:33, 157.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 670/5962 [00:05<00:38, 137.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 553/5962 [00:04<00:32, 165.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 11%|████                                   | 628/5962 [00:05<00:37, 143.74it/s]\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 742/5962 [00:05<00:25, 204.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                     | 451/5962 [00:05<01:01, 89.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 685/5962 [00:05<00:37, 140.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 12%|████▋                                  | 710/5962 [00:05<00:35, 148.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▋                                   | 571/5962 [00:05<00:32, 165.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|████▉                                  | 763/5962 [00:05<00:25, 201.10it/s]\u001b[A\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 825/5962 [00:05<00:25, 199.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 468/5962 [00:05<00:51, 106.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 705/5962 [00:05<00:33, 155.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 589/5962 [00:05<00:31, 168.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▎                                  | 663/5962 [00:05<00:34, 154.07it/s]\u001b[A\n",
      "\n",
      " 12%|████▋                                  | 726/5962 [00:05<00:39, 133.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 846/5962 [00:05<00:25, 200.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 488/5962 [00:05<00:42, 129.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 721/5962 [00:05<00:34, 152.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 784/5962 [00:05<00:28, 180.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▍                                  | 686/5962 [00:05<00:30, 175.09it/s]\u001b[A\n",
      "\n",
      " 12%|████▊                                  | 740/5962 [00:05<00:39, 130.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 867/5962 [00:05<00:25, 196.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 737/5962 [00:05<00:35, 148.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 502/5962 [00:05<00:44, 122.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▌                                  | 705/5962 [00:05<00:29, 178.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▎                                 | 803/5962 [00:05<00:32, 157.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|████▉                                  | 754/5962 [00:05<00:41, 126.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 887/5962 [00:05<00:26, 190.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 518/5962 [00:05<00:41, 129.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▋                                  | 725/5962 [00:05<00:28, 182.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 820/5962 [00:05<00:32, 160.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████                                  | 767/5962 [00:05<00:43, 120.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 644/5962 [00:05<00:38, 138.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 907/5962 [00:05<00:27, 181.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 532/5962 [00:05<00:44, 123.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 837/5962 [00:05<00:32, 159.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▊                                  | 744/5962 [00:05<00:32, 159.36it/s]\u001b[A\n",
      "\n",
      " 13%|█████                                  | 781/5962 [00:05<00:42, 123.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 659/5962 [00:05<00:37, 139.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████                                 | 926/5962 [00:05<00:29, 170.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 550/5962 [00:05<00:40, 135.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 856/5962 [00:06<00:30, 166.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 675/5962 [00:05<00:36, 143.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|████▉                                  | 761/5962 [00:05<00:35, 146.28it/s]\u001b[A\n",
      "\n",
      " 13%|█████▏                                 | 794/5962 [00:06<00:43, 118.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 566/5962 [00:05<00:38, 139.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 874/5962 [00:06<00:30, 169.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 693/5962 [00:05<00:34, 152.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 799/5962 [00:05<00:44, 117.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 586/5962 [00:06<00:34, 153.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▊                                 | 896/5962 [00:06<00:27, 181.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 961/5962 [00:06<00:33, 149.43it/s]\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████                                  | 777/5962 [00:06<00:42, 122.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 709/5962 [00:06<00:34, 150.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 812/5962 [00:06<00:45, 112.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 602/5962 [00:06<00:38, 140.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 981/5962 [00:06<00:30, 161.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▍                                  | 817/5962 [00:06<00:52, 97.84it/s]\u001b[A\u001b[A\n",
      " 13%|█████▏                                 | 796/5962 [00:06<00:37, 137.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 729/5962 [00:06<00:32, 163.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 830/5962 [00:06<00:41, 124.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████                                 | 933/5962 [00:06<00:29, 169.66it/s]\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▎                                 | 813/5962 [00:06<00:35, 144.61it/s]\u001b[A\n",
      "\n",
      " 14%|█████▌                                  | 827/5962 [00:06<00:52, 97.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 617/5962 [00:06<00:39, 135.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 747/5962 [00:06<00:31, 167.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 848/5962 [00:06<00:37, 137.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▍                               | 1015/5962 [00:06<00:30, 162.80it/s]\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████▏                                | 953/5962 [00:06<00:28, 175.46it/s]\u001b[A\n",
      "\n",
      " 14%|█████▌                                  | 838/5962 [00:06<00:51, 98.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 776/5962 [00:06<00:25, 201.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 631/5962 [00:06<00:40, 131.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▋                                 | 864/5962 [00:06<00:36, 141.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▌                                 | 853/5962 [00:06<00:31, 164.77it/s]\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1037/5962 [00:06<00:28, 173.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▎                                 | 804/5962 [00:06<00:23, 223.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▎                                | 971/5962 [00:06<00:31, 160.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 879/5962 [00:06<00:36, 138.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 645/5962 [00:06<00:47, 112.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▋                               | 1058/5962 [00:06<00:26, 181.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 827/5962 [00:06<00:23, 216.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▊                                  | 859/5962 [00:06<00:52, 96.36it/s]\u001b[A\u001b[A\n",
      " 17%|██████▍                                | 988/5962 [00:06<00:33, 150.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 657/5962 [00:06<00:51, 102.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▊                                  | 870/5962 [00:06<00:51, 98.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1077/5962 [00:06<00:29, 167.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 894/5962 [00:06<00:41, 120.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▊                                 | 887/5962 [00:06<00:33, 153.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                               | 1005/5962 [00:06<00:32, 154.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 677/5962 [00:06<00:42, 125.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▊                                 | 887/5962 [00:06<00:43, 116.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 909/5962 [00:06<00:39, 127.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▉                                 | 914/5962 [00:06<00:28, 179.89it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1024/5962 [00:07<00:30, 160.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1095/5962 [00:06<00:31, 154.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 693/5962 [00:06<00:40, 130.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▉                                 | 900/5962 [00:07<00:42, 118.46it/s]\u001b[A\u001b[A\n",
      " 16%|██████▏                                | 938/5962 [00:07<00:25, 196.28it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████                                 | 923/5962 [00:06<00:41, 121.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████                               | 1111/5962 [00:07<00:31, 153.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 897/5962 [00:06<00:26, 190.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 711/5962 [00:07<00:36, 143.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▉                                 | 915/5962 [00:07<00:40, 125.63it/s]\u001b[A\u001b[A\n",
      " 16%|██████▎                                | 959/5962 [00:07<00:27, 184.52it/s]\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1061/5962 [00:07<00:29, 165.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 936/5962 [00:07<00:46, 108.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 917/5962 [00:07<00:27, 181.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 728/5962 [00:07<00:34, 150.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████                                 | 929/5962 [00:07<00:39, 128.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1147/5962 [00:07<00:29, 163.61it/s]\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▊                               | 1078/5962 [00:07<00:32, 150.77it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 744/5962 [00:07<00:35, 146.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▏                                | 942/5962 [00:07<00:41, 122.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▍                              | 1168/5962 [00:07<00:27, 176.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 936/5962 [00:07<00:32, 152.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▌                                | 997/5962 [00:07<00:28, 174.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1094/5962 [00:07<00:35, 138.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▏                                | 955/5962 [00:07<00:42, 116.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 760/5962 [00:07<00:38, 133.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1186/5962 [00:07<00:28, 168.59it/s]\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▍                               | 1015/5962 [00:07<00:29, 169.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████                               | 1117/5962 [00:07<00:30, 157.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▎                                | 968/5962 [00:07<00:41, 120.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                 | 958/5962 [00:07<01:03, 78.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▋                              | 1207/5962 [00:07<00:26, 178.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 774/5962 [00:07<00:42, 121.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▌                               | 1033/5962 [00:07<00:29, 164.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1140/5962 [00:07<00:27, 175.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1225/5962 [00:07<00:28, 165.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                 | 967/5962 [00:07<01:11, 70.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▍                                | 981/5962 [00:07<00:49, 100.22it/s]\u001b[A\u001b[A\n",
      " 18%|██████▋                               | 1050/5962 [00:07<00:32, 150.16it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 983/5962 [00:07<00:41, 118.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                 | 975/5962 [00:07<01:11, 69.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 992/5962 [00:07<00:51, 96.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1242/5962 [00:07<00:35, 132.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 997/5962 [00:07<00:40, 122.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▊                               | 1066/5962 [00:07<00:38, 127.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                 | 986/5962 [00:07<01:04, 77.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▌                                | 1003/5962 [00:08<00:50, 99.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▍                              | 1175/5962 [00:08<00:35, 133.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████                              | 1257/5962 [00:08<00:34, 135.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                               | 1010/5962 [00:07<00:40, 123.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▉                               | 1087/5962 [00:08<00:33, 145.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 999/5962 [00:07<00:55, 88.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▍                               | 1016/5962 [00:08<00:46, 106.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1195/5962 [00:08<00:32, 147.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▏                             | 1279/5962 [00:08<00:29, 156.51it/s]\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████                               | 1103/5962 [00:08<00:33, 145.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1023/5962 [00:08<00:42, 116.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 1011/5962 [00:08<00:51, 96.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 830/5962 [00:08<00:42, 120.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▋                              | 1211/5962 [00:08<00:32, 146.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1300/5962 [00:08<00:27, 167.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1035/5962 [00:08<00:43, 114.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▏                              | 1119/5962 [00:08<00:34, 138.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1026/5962 [00:08<00:45, 108.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▋                               | 1047/5962 [00:08<00:39, 123.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1227/5962 [00:08<00:32, 144.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▋                               | 1053/5962 [00:08<00:37, 130.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▎                              | 1140/5962 [00:08<00:30, 155.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                               | 1043/5962 [00:08<00:40, 122.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1242/5962 [00:08<00:32, 144.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▊                               | 1060/5962 [00:08<00:46, 104.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1068/5962 [00:08<00:36, 134.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▌                             | 1337/5962 [00:08<00:31, 146.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▋                               | 1059/5962 [00:08<00:37, 131.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▎                              | 1157/5962 [00:08<00:32, 149.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                              | 1260/5962 [00:08<00:30, 152.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1084/5962 [00:08<00:34, 141.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1074/5962 [00:08<00:37, 130.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 873/5962 [00:08<00:45, 112.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████                                | 1072/5962 [00:08<00:52, 93.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▏                             | 1276/5962 [00:08<00:30, 153.03it/s]\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▍                              | 1173/5962 [00:08<00:34, 138.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                               | 1101/5962 [00:08<00:32, 147.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1093/5962 [00:08<00:33, 143.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 889/5962 [00:08<00:42, 120.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▌                              | 1192/5962 [00:08<00:31, 150.54it/s]\u001b[A\n",
      "\n",
      " 22%|████████▏                             | 1292/5962 [00:08<00:30, 151.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1368/5962 [00:08<00:34, 133.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1119/5962 [00:08<00:31, 156.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 903/5962 [00:08<00:41, 122.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1124/5962 [00:08<00:26, 179.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▎                             | 1308/5962 [00:08<00:30, 152.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1382/5962 [00:08<00:35, 129.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1142/5962 [00:08<00:27, 175.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████▏                               | 1092/5962 [00:08<00:59, 81.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████                                 | 919/5962 [00:08<00:38, 131.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|███████▊                              | 1233/5962 [00:08<00:27, 174.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1142/5962 [00:08<00:29, 165.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▍                              | 1167/5962 [00:08<00:24, 195.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1324/5962 [00:09<00:36, 128.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████▏                               | 1101/5962 [00:09<01:00, 79.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 933/5962 [00:09<00:38, 130.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|███████▉                              | 1251/5962 [00:09<00:26, 174.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                              | 1159/5962 [00:09<00:30, 155.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|████████▉                             | 1411/5962 [00:09<00:35, 127.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▌                             | 1338/5962 [00:09<00:37, 121.79it/s]\u001b[A\u001b[A\n",
      " 21%|████████▏                             | 1277/5962 [00:09<00:23, 197.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 947/5962 [00:09<00:41, 121.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▍                              | 1175/5962 [00:09<00:31, 153.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████                             | 1427/5962 [00:09<00:33, 134.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▎                               | 1122/5962 [00:09<00:53, 89.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1357/5962 [00:09<00:33, 137.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 964/5962 [00:09<00:37, 133.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▎                             | 1298/5962 [00:09<00:26, 179.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1193/5962 [00:09<00:29, 160.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1446/5962 [00:09<00:30, 148.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▊                             | 1375/5962 [00:09<00:30, 148.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1227/5962 [00:09<00:27, 172.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 978/5962 [00:09<00:39, 125.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▍                               | 1143/5962 [00:09<00:52, 91.68it/s]\n",
      "\n",
      "\n",
      " 25%|█████████▎                            | 1462/5962 [00:09<00:33, 134.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                              | 1210/5962 [00:09<00:33, 142.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1391/5962 [00:09<00:39, 115.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▌                               | 1153/5962 [00:09<00:55, 86.57it/s]\u001b[A\u001b[A\n",
      " 22%|████████▍                             | 1317/5962 [00:09<00:40, 115.05it/s]\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1476/5962 [00:09<00:43, 104.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 991/5962 [00:09<00:55, 89.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1225/5962 [00:09<00:43, 109.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|████████▉                             | 1404/5962 [00:09<00:40, 111.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                              | 1262/5962 [00:09<00:38, 123.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1488/5962 [00:09<00:42, 105.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▋                               | 1174/5962 [00:09<00:51, 93.60it/s]\u001b[A\u001b[A\n",
      " 24%|█████████                             | 1418/5962 [00:09<00:38, 117.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1238/5962 [00:09<00:43, 108.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▏                             | 1281/5962 [00:09<00:33, 137.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 1002/5962 [00:09<00:58, 84.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1502/5962 [00:09<00:39, 113.74it/s]\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▌                             | 1353/5962 [00:09<00:36, 125.69it/s]\u001b[A\n",
      "\n",
      " 24%|█████████                             | 1431/5962 [00:09<00:37, 119.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                | 1014/5962 [00:09<00:53, 92.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1250/5962 [00:09<00:46, 102.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1297/5962 [00:09<00:35, 131.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▋                            | 1516/5962 [00:09<00:37, 118.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1445/5962 [00:10<00:37, 122.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1029/5962 [00:09<00:47, 104.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                              | 1268/5962 [00:09<00:39, 119.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1317/5962 [00:09<00:31, 147.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1536/5962 [00:10<00:31, 138.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▎                            | 1461/5962 [00:10<00:34, 131.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                               | 1041/5962 [00:10<00:45, 107.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▏                             | 1287/5962 [00:10<00:34, 136.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▊                             | 1386/5962 [00:10<00:36, 123.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1333/5962 [00:10<00:31, 146.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1554/5962 [00:10<00:29, 149.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▍                            | 1478/5962 [00:10<00:32, 138.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▋                               | 1054/5962 [00:10<00:43, 112.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1307/5962 [00:10<00:30, 152.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▉                             | 1400/5962 [00:10<00:38, 119.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1349/5962 [00:10<00:33, 136.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████                            | 1570/5962 [00:10<00:30, 143.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▌                            | 1493/5962 [00:10<00:33, 131.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1066/5962 [00:10<00:46, 105.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████                            | 1585/5962 [00:10<00:30, 144.52it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1324/5962 [00:10<00:35, 132.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1364/5962 [00:10<00:34, 134.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████                             | 1413/5962 [00:10<00:41, 109.94it/s]\u001b[A\n",
      "\n",
      " 25%|█████████▌                            | 1507/5962 [00:10<00:33, 132.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1079/5962 [00:10<00:44, 110.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1605/5962 [00:10<00:27, 159.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1387/5962 [00:10<00:28, 158.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████                             | 1425/5962 [00:10<00:40, 111.01it/s]\u001b[A\n",
      "\n",
      " 21%|████████                              | 1263/5962 [00:10<00:35, 130.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1521/5962 [00:10<00:33, 134.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1094/5962 [00:10<00:40, 118.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1622/5962 [00:10<00:27, 155.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|████████▉                             | 1410/5962 [00:10<00:26, 172.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████▏                            | 1439/5962 [00:10<00:38, 117.76it/s]\u001b[A\n",
      "\n",
      " 26%|█████████▊                            | 1544/5962 [00:10<00:27, 160.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1353/5962 [00:10<00:36, 124.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████                               | 1108/5962 [00:10<00:39, 124.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▍                           | 1640/5962 [00:10<00:26, 160.25it/s]\u001b[A\u001b[A\u001b[A\n",
      " 26%|█████████▉                            | 1565/5962 [00:10<00:25, 174.02it/s]\u001b[A\n",
      "\n",
      " 22%|████████▎                             | 1295/5962 [00:10<00:33, 137.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1368/5962 [00:10<00:35, 128.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1121/5962 [00:10<00:38, 124.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1665/5962 [00:10<00:23, 184.94it/s]\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▎                            | 1470/5962 [00:10<00:33, 133.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████                            | 1583/5962 [00:10<00:25, 172.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▎                             | 1310/5962 [00:10<00:33, 139.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1134/5962 [00:10<00:39, 123.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1684/5962 [00:10<00:23, 181.91it/s]\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▍                            | 1484/5962 [00:10<00:33, 132.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1443/5962 [00:10<00:33, 134.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▍                             | 1325/5962 [00:11<00:33, 136.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1382/5962 [00:10<00:45, 101.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1601/5962 [00:11<00:28, 155.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▌                            | 1498/5962 [00:11<00:37, 117.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                            | 1458/5962 [00:10<00:38, 118.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|██████████▊                           | 1703/5962 [00:11<00:33, 125.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▌                             | 1339/5962 [00:11<00:46, 100.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████                              | 1394/5962 [00:11<00:57, 79.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1471/5962 [00:11<00:40, 111.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                               | 1161/5962 [00:11<00:57, 83.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▎                           | 1617/5962 [00:11<00:43, 100.92it/s]\u001b[A\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1719/5962 [00:11<00:34, 124.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1484/5962 [00:11<00:40, 111.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▊                              | 1351/5962 [00:11<00:51, 89.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                               | 1172/5962 [00:11<00:56, 84.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▍                           | 1632/5962 [00:11<00:40, 107.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████                           | 1735/5962 [00:11<00:32, 131.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1504/5962 [00:11<00:33, 132.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▉                              | 1362/5962 [00:11<00:50, 91.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                               | 1185/5962 [00:11<00:50, 94.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1648/5962 [00:11<00:36, 117.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▏                          | 1751/5962 [00:11<00:30, 137.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1521/5962 [00:11<00:31, 141.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                               | 1196/5962 [00:11<00:50, 94.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 26%|█████████▉                            | 1561/5962 [00:11<00:32, 134.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1662/5962 [00:11<00:35, 120.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▎                          | 1766/5962 [00:11<00:30, 139.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1545/5962 [00:11<00:26, 165.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▉                             | 1396/5962 [00:11<00:37, 121.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▉                               | 1208/5962 [00:11<00:50, 94.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1676/5962 [00:11<00:38, 111.26it/s]\u001b[A\u001b[A\u001b[A\n",
      " 26%|██████████                            | 1576/5962 [00:11<00:38, 113.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1563/5962 [00:11<00:31, 137.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▍                             | 1447/5962 [00:11<01:00, 74.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▍                          | 1795/5962 [00:11<00:33, 122.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▏                             | 1410/5962 [00:11<00:47, 96.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 1689/5962 [00:12<00:43, 98.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▍                            | 1589/5962 [00:12<00:45, 96.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████                            | 1578/5962 [00:11<00:34, 127.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▌                          | 1808/5962 [00:12<00:37, 110.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████                            | 1700/5962 [00:12<00:43, 97.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▌                             | 1457/5962 [00:12<01:08, 65.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▍                            | 1600/5962 [00:12<00:45, 96.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1592/5962 [00:12<00:36, 120.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▎                             | 1433/5962 [00:12<00:48, 92.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 1711/5962 [00:12<00:44, 96.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▌                          | 1820/5962 [00:12<00:40, 101.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                             | 1466/5962 [00:12<01:04, 69.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1611/5962 [00:12<00:31, 136.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▌                            | 1611/5962 [00:12<00:47, 92.19it/s]\u001b[A\n",
      "\n",
      " 24%|█████████▏                            | 1450/5962 [00:12<00:40, 110.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████                           | 1728/5962 [00:12<00:37, 113.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1833/5962 [00:12<00:38, 107.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▋                             | 1484/5962 [00:12<00:49, 91.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1627/5962 [00:12<00:30, 140.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▍                           | 1632/5962 [00:12<00:36, 118.66it/s]\u001b[A\n",
      "\n",
      " 29%|███████████▏                          | 1746/5962 [00:12<00:32, 130.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▏                              | 1258/5962 [00:12<00:53, 88.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1846/5962 [00:12<00:36, 112.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▊                             | 1497/5962 [00:12<00:44, 99.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▍                           | 1644/5962 [00:12<00:29, 146.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|██████████▍                           | 1646/5962 [00:12<00:35, 123.05it/s]\u001b[A\n",
      "\n",
      " 30%|███████████▏                          | 1762/5962 [00:12<00:30, 136.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1862/5962 [00:12<00:33, 123.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                              | 1272/5962 [00:12<00:47, 99.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▋                            | 1512/5962 [00:12<00:40, 111.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1661/5962 [00:12<00:28, 151.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▎                          | 1778/5962 [00:12<00:29, 141.31it/s]\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▉                          | 1878/5962 [00:12<00:30, 133.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                              | 1283/5962 [00:12<00:47, 99.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▌                            | 1494/5962 [00:12<00:37, 120.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1525/5962 [00:12<00:39, 113.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1677/5962 [00:12<00:28, 148.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▍                          | 1795/5962 [00:12<00:28, 147.55it/s]\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1893/5962 [00:12<00:29, 136.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▌                            | 1510/5962 [00:12<00:34, 130.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1538/5962 [00:12<00:38, 116.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                              | 1294/5962 [00:12<00:48, 96.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|██████████▊                           | 1699/5962 [00:12<00:29, 146.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1524/5962 [00:12<00:34, 128.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1907/5962 [00:12<00:32, 125.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1310/5962 [00:12<00:42, 110.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                           | 1693/5962 [00:12<00:35, 118.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|██████████▉                           | 1715/5962 [00:12<00:30, 137.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1323/5962 [00:12<00:40, 114.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1920/5962 [00:12<00:33, 121.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1825/5962 [00:13<00:33, 123.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|█████████▊                            | 1538/5962 [00:13<00:39, 112.13it/s]\u001b[A\u001b[A\n",
      " 29%|███████████                           | 1733/5962 [00:13<00:29, 145.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▊                           | 1706/5962 [00:12<00:41, 101.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                             | 1335/5962 [00:13<00:39, 115.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1944/5962 [00:13<00:26, 151.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████                            | 1582/5962 [00:13<00:35, 122.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▋                          | 1839/5962 [00:13<00:32, 125.30it/s]\u001b[A\u001b[A\n",
      " 29%|███████████▏                          | 1749/5962 [00:13<00:28, 147.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1348/5962 [00:13<00:38, 119.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1718/5962 [00:13<00:42, 100.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1853/5962 [00:13<00:32, 128.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|██████████                            | 1578/5962 [00:13<00:30, 146.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1595/5962 [00:13<00:40, 106.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▏                          | 1764/5962 [00:13<00:28, 147.26it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1363/5962 [00:13<00:36, 127.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                          | 1870/5962 [00:13<00:29, 137.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1982/5962 [00:13<00:29, 136.92it/s]\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▎                          | 1779/5962 [00:13<00:29, 143.35it/s]\u001b[A\n",
      "\n",
      " 27%|██████████▏                           | 1594/5962 [00:13<00:32, 133.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1378/5962 [00:13<00:34, 132.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                          | 1753/5962 [00:13<00:32, 130.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1887/5962 [00:13<00:28, 143.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▉                             | 1393/5962 [00:13<00:33, 136.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 27%|██████████▏                           | 1608/5962 [00:13<00:33, 129.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▎                          | 1769/5962 [00:13<00:30, 137.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1904/5962 [00:13<00:27, 148.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1997/5962 [00:13<00:35, 111.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|████████▉                             | 1407/5962 [00:13<00:33, 135.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▍                          | 1802/5962 [00:13<00:22, 186.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▌                          | 1813/5962 [00:13<00:27, 148.49it/s]\u001b[A\n",
      "\n",
      " 27%|██████████▎                           | 1622/5962 [00:13<00:34, 125.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▎                         | 1924/5962 [00:13<00:24, 162.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████                             | 1426/5962 [00:13<00:30, 149.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2010/5962 [00:13<00:36, 107.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1830/5962 [00:13<00:27, 152.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▎                         | 1941/5962 [00:13<00:28, 140.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 27%|██████████▍                           | 1635/5962 [00:13<00:41, 103.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1441/5962 [00:13<00:37, 120.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▉                            | 1665/5962 [00:13<00:43, 97.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1842/5962 [00:13<00:28, 143.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▊                            | 1647/5962 [00:13<00:43, 99.82it/s]\u001b[A\u001b[A\n",
      " 33%|████████████▍                         | 1956/5962 [00:14<00:34, 117.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                            | 1454/5962 [00:13<00:38, 117.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▏                         | 2022/5962 [00:14<00:52, 75.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1682/5962 [00:13<00:38, 112.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▌                           | 1660/5962 [00:14<00:40, 105.83it/s]\u001b[A\u001b[A\n",
      " 33%|████████████▌                         | 1972/5962 [00:14<00:31, 126.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▎                            | 1467/5962 [00:14<00:37, 120.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 2032/5962 [00:14<00:49, 79.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▋                           | 1678/5962 [00:14<00:34, 123.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                           | 1697/5962 [00:14<00:35, 119.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                          | 1878/5962 [00:13<00:26, 153.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▋                         | 1989/5962 [00:14<00:29, 136.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1480/5962 [00:14<00:37, 120.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 2043/5962 [00:14<00:46, 84.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▊                           | 1696/5962 [00:14<00:31, 135.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1710/5962 [00:14<00:36, 115.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2006/5962 [00:14<00:27, 142.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████                          | 1895/5962 [00:14<00:33, 120.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1493/5962 [00:14<00:40, 109.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▍                         | 2053/5962 [00:14<00:48, 81.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1723/5962 [00:14<00:37, 112.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2021/5962 [00:14<00:30, 130.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████                           | 1728/5962 [00:14<00:29, 142.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▍                         | 2062/5962 [00:14<00:47, 82.59it/s]\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▏                         | 1909/5962 [00:14<00:36, 111.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████                           | 1741/5962 [00:14<00:32, 129.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1505/5962 [00:14<00:44, 101.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2037/5962 [00:14<00:28, 136.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████                           | 1744/5962 [00:14<00:28, 146.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▌                         | 2075/5962 [00:14<00:41, 92.94it/s]\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▏                         | 1921/5962 [00:14<00:36, 110.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▏                          | 1763/5962 [00:14<00:27, 151.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▋                            | 1516/5962 [00:14<00:43, 101.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2052/5962 [00:14<00:29, 132.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▏                          | 1761/5962 [00:14<00:27, 151.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2090/5962 [00:14<00:36, 105.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▍                          | 1786/5962 [00:14<00:24, 171.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1527/5962 [00:14<00:43, 101.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▎                         | 1933/5962 [00:14<00:38, 103.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2069/5962 [00:14<00:27, 141.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2105/5962 [00:14<00:33, 116.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▎                          | 1778/5962 [00:14<00:27, 152.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▍                          | 1804/5962 [00:14<00:24, 170.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1538/5962 [00:14<00:42, 103.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▍                         | 1946/5962 [00:14<00:37, 106.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1977/5962 [00:14<00:29, 137.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2084/5962 [00:14<00:28, 135.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▍                          | 1794/5962 [00:14<00:28, 148.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1557/5962 [00:14<00:34, 127.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▍                         | 1957/5962 [00:14<00:37, 106.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▌                          | 1822/5962 [00:14<00:27, 148.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1992/5962 [00:14<00:28, 139.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2142/5962 [00:14<00:25, 150.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▎                        | 2098/5962 [00:15<00:29, 131.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1590/5962 [00:14<00:24, 180.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▌                         | 1975/5962 [00:15<00:31, 125.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1838/5962 [00:14<00:28, 146.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2009/5962 [00:14<00:26, 147.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2112/5962 [00:15<00:28, 133.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▋                          | 1824/5962 [00:15<00:29, 139.59it/s]\u001b[A\u001b[A\n",
      " 33%|████████████▋                         | 1996/5962 [00:15<00:26, 146.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2026/5962 [00:15<00:25, 153.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1854/5962 [00:15<00:28, 146.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2178/5962 [00:15<00:23, 158.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▌                        | 2126/5962 [00:15<00:30, 124.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1609/5962 [00:15<00:32, 134.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|████████████▊                         | 2012/5962 [00:15<00:28, 139.09it/s]\u001b[A\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2195/5962 [00:15<00:24, 156.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▊                          | 1854/5962 [00:15<00:28, 142.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2042/5962 [00:15<00:28, 136.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2141/5962 [00:15<00:29, 129.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|████████████▉                         | 2029/5962 [00:15<00:26, 145.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1625/5962 [00:15<00:34, 124.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2216/5962 [00:15<00:22, 169.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▊                        | 2159/5962 [00:15<00:26, 142.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1883/5962 [00:15<00:34, 118.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|█████████████                         | 2045/5962 [00:15<00:26, 146.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████                         | 2057/5962 [00:15<00:32, 118.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2237/5962 [00:15<00:20, 180.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2174/5962 [00:15<00:26, 144.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|████████████                          | 1885/5962 [00:15<00:29, 136.99it/s]\u001b[A\u001b[A\n",
      " 35%|█████████████▏                        | 2063/5962 [00:15<00:25, 153.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1896/5962 [00:15<00:34, 116.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2070/5962 [00:15<00:35, 110.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2256/5962 [00:15<00:21, 168.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1652/5962 [00:15<00:36, 118.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████▉                        | 2189/5962 [00:15<00:28, 130.99it/s]\u001b[A\u001b[A\n",
      " 35%|█████████████▎                        | 2081/5962 [00:15<00:24, 160.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1915/5962 [00:15<00:30, 133.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|████████████▎                         | 1925/5962 [00:15<00:24, 163.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2274/5962 [00:15<00:23, 157.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1665/5962 [00:15<00:38, 112.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2082/5962 [00:15<00:38, 100.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████                        | 2203/5962 [00:15<00:29, 126.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2216/5962 [00:15<00:29, 126.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1946/5962 [00:15<00:28, 142.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1677/5962 [00:15<00:40, 105.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2291/5962 [00:15<00:25, 146.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████▍                         | 1942/5962 [00:15<00:27, 143.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 2093/5962 [00:15<00:40, 95.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▍                        | 2115/5962 [00:15<00:27, 142.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1961/5962 [00:15<00:28, 140.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2306/5962 [00:16<00:25, 143.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2229/5962 [00:16<00:32, 113.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 2103/5962 [00:15<00:42, 89.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████▍                         | 1957/5962 [00:16<00:31, 127.15it/s]\u001b[A\u001b[A\n",
      " 36%|█████████████▌                        | 2130/5962 [00:16<00:29, 130.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1976/5962 [00:16<00:28, 142.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2321/5962 [00:16<00:26, 135.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 2241/5962 [00:16<00:37, 98.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 2113/5962 [00:16<00:49, 78.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 36%|█████████████▋                        | 2144/5962 [00:16<00:31, 121.74it/s]\u001b[A\n",
      "\n",
      " 33%|████████████▌                         | 1971/5962 [00:16<00:35, 113.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1991/5962 [00:16<00:29, 136.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2335/5962 [00:16<00:31, 114.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████▋                         | 1985/5962 [00:16<00:33, 118.57it/s]\u001b[A\u001b[A\n",
      " 38%|██████████████▋                        | 2252/5962 [00:16<00:38, 95.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2008/5962 [00:16<00:27, 145.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▉                         | 2122/5962 [00:16<00:54, 70.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 2355/5962 [00:16<00:27, 133.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 34%|████████████▊                         | 2003/5962 [00:16<00:29, 133.01it/s]\u001b[A\u001b[A\n",
      " 36%|█████████████▊                        | 2174/5962 [00:16<00:29, 129.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 2262/5962 [00:16<00:40, 91.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 1709/5962 [00:16<01:06, 64.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▉                         | 2130/5962 [00:16<00:53, 72.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2275/5962 [00:16<00:36, 100.47it/s]\u001b[A\u001b[A\u001b[A\n",
      " 37%|█████████████▉                        | 2188/5962 [00:16<00:30, 123.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2038/5962 [00:16<00:29, 134.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 2144/5962 [00:16<00:43, 87.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 34%|████████████▊                         | 2017/5962 [00:16<00:35, 109.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2288/5962 [00:16<00:34, 105.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2384/5962 [00:16<00:28, 124.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2053/5962 [00:16<00:29, 133.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████                        | 2201/5962 [00:16<00:31, 117.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2163/5962 [00:16<00:33, 112.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 34%|█████████████                         | 2041/5962 [00:16<00:28, 137.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2304/5962 [00:16<00:30, 118.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2397/5962 [00:16<00:29, 122.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2078/5962 [00:16<00:23, 165.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████                        | 2215/5962 [00:16<00:30, 122.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2178/5962 [00:16<00:31, 121.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▏                        | 2064/5962 [00:16<00:24, 159.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2320/5962 [00:16<00:28, 129.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2416/5962 [00:16<00:25, 139.33it/s]\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████▏                       | 2228/5962 [00:16<00:30, 121.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2197/5962 [00:16<00:27, 138.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2095/5962 [00:16<00:24, 158.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▍                           | 1743/5962 [00:16<00:56, 74.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▎                        | 2082/5962 [00:17<00:25, 153.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 2436/5962 [00:16<00:22, 154.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2225/5962 [00:16<00:21, 176.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2334/5962 [00:17<00:32, 111.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▍                           | 1752/5962 [00:17<00:53, 78.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 2455/5962 [00:17<00:21, 162.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▍                        | 2099/5962 [00:17<00:27, 140.58it/s]\u001b[A\u001b[A\n",
      " 38%|██████████████▎                       | 2254/5962 [00:17<00:31, 118.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2129/5962 [00:17<00:25, 151.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2244/5962 [00:16<00:22, 164.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2346/5962 [00:17<00:33, 106.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▊                      | 2472/5962 [00:17<00:21, 162.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▍                        | 2114/5962 [00:17<00:27, 138.54it/s]\u001b[A\u001b[A\n",
      " 38%|██████████████▍                       | 2271/5962 [00:17<00:27, 132.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2146/5962 [00:17<00:24, 155.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2264/5962 [00:17<00:21, 171.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 2358/5962 [00:17<00:35, 102.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▌                        | 2130/5962 [00:17<00:26, 143.79it/s]\u001b[A\u001b[A\n",
      " 38%|██████████████▌                       | 2293/5962 [00:17<00:23, 156.64it/s]\u001b[A\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2489/5962 [00:17<00:23, 146.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2164/5962 [00:17<00:23, 160.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2284/5962 [00:17<00:20, 178.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▋                           | 1788/5962 [00:17<00:41, 99.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 39%|██████████████▋                       | 2310/5962 [00:17<00:22, 160.25it/s]\u001b[A\n",
      "\n",
      " 36%|█████████████▋                        | 2145/5962 [00:17<00:27, 141.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2191/5962 [00:17<00:19, 190.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2303/5962 [00:17<00:20, 180.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 1799/5962 [00:17<00:42, 97.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2505/5962 [00:17<00:25, 134.12it/s]\u001b[A\u001b[A\u001b[A\n",
      " 39%|██████████████▊                       | 2331/5962 [00:17<00:20, 174.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▌                       | 2379/5962 [00:17<00:39, 91.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▊                        | 2160/5962 [00:17<00:29, 128.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2322/5962 [00:17<00:21, 166.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                          | 1813/5962 [00:17<00:38, 108.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████                       | 2355/5962 [00:17<00:18, 192.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2236/5962 [00:17<00:19, 193.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▊                        | 2174/5962 [00:17<00:28, 131.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2519/5962 [00:17<00:31, 110.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▋                       | 2389/5962 [00:17<00:41, 86.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2262/5962 [00:17<00:17, 208.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████▉                        | 2188/5962 [00:17<00:28, 130.86it/s]\u001b[A\u001b[A\n",
      " 40%|███████████████▏                      | 2375/5962 [00:17<00:21, 168.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▋                       | 2398/5962 [00:17<00:42, 82.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████▏                     | 2531/5962 [00:17<00:33, 103.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 2360/5962 [00:17<00:23, 155.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████                        | 2204/5962 [00:17<00:27, 138.23it/s]\u001b[A\u001b[A\n",
      " 40%|███████████████▋                       | 2407/5962 [00:18<00:43, 81.60it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▏                     | 2542/5962 [00:17<00:33, 101.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1849/5962 [00:17<00:41, 100.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2377/5962 [00:17<00:25, 143.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████▏                       | 2223/5962 [00:18<00:24, 151.69it/s]\u001b[A\u001b[A\n",
      " 40%|███████████████▎                      | 2412/5962 [00:18<00:21, 162.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2283/5962 [00:17<00:26, 140.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2554/5962 [00:18<00:33, 102.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                       | 2416/5962 [00:18<00:48, 72.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2392/5962 [00:17<00:25, 139.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 41%|███████████████▍                      | 2429/5962 [00:18<00:21, 161.99it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2565/5962 [00:18<00:32, 102.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                       | 2425/5962 [00:18<00:47, 75.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2407/5962 [00:18<00:26, 135.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 41%|███████████████▋                      | 2457/5962 [00:18<00:18, 191.34it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 2580/5962 [00:18<00:29, 114.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1891/5962 [00:18<00:33, 120.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▍                       | 2261/5962 [00:18<00:27, 133.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 2434/5962 [00:18<00:45, 77.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2424/5962 [00:18<00:24, 144.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▊                      | 2477/5962 [00:18<00:18, 188.16it/s]\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2599/5962 [00:18<00:25, 133.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 2445/5962 [00:18<00:41, 85.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▌                       | 2276/5962 [00:18<00:28, 128.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 2442/5962 [00:18<00:23, 152.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2316/5962 [00:18<00:32, 111.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▉                      | 2497/5962 [00:18<00:19, 175.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 2454/5962 [00:18<00:41, 84.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2613/5962 [00:18<00:28, 116.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 2458/5962 [00:18<00:23, 147.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▌                       | 2290/5962 [00:18<00:29, 122.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2334/5962 [00:18<00:29, 124.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 41%|████████████████                       | 2463/5962 [00:18<00:42, 83.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2477/5962 [00:18<00:21, 159.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1948/5962 [00:18<00:28, 139.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▋                       | 2306/5962 [00:18<00:27, 131.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2351/5962 [00:18<00:27, 133.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2626/5962 [00:18<00:31, 107.41it/s]\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▊                      | 2478/5962 [00:18<00:34, 101.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2498/5962 [00:18<00:20, 172.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1963/5962 [00:18<00:28, 140.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▊                       | 2324/5962 [00:18<00:25, 141.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 2367/5962 [00:18<00:28, 124.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2494/5962 [00:18<00:29, 116.10it/s]\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▎                     | 2554/5962 [00:18<00:20, 165.54it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2520/5962 [00:18<00:18, 182.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1979/5962 [00:18<00:27, 142.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▉                       | 2343/5962 [00:18<00:23, 151.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2510/5962 [00:19<00:27, 126.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▏                     | 2542/5962 [00:18<00:17, 192.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▍                     | 2571/5962 [00:18<00:20, 161.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1994/5962 [00:18<00:27, 143.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████                       | 2366/5962 [00:19<00:21, 170.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████▏                     | 2530/5962 [00:19<00:23, 147.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2562/5962 [00:18<00:17, 192.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▌                     | 2597/5962 [00:19<00:18, 186.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2013/5962 [00:19<00:25, 154.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▎                      | 2393/5962 [00:19<00:18, 197.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2551/5962 [00:19<00:20, 164.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2409/5962 [00:19<00:28, 124.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2034/5962 [00:19<00:23, 170.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2682/5962 [00:19<00:28, 116.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▍                      | 2414/5962 [00:19<00:20, 175.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 2582/5962 [00:19<00:21, 158.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▊                     | 2637/5962 [00:19<00:18, 182.44it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2568/5962 [00:19<00:23, 147.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2423/5962 [00:19<00:30, 116.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▋                     | 2695/5962 [00:19<00:33, 98.40it/s]\u001b[A\u001b[A\u001b[A\n",
      " 45%|████████████████▉                     | 2656/5962 [00:19<00:21, 155.83it/s]\u001b[A\n",
      "\n",
      " 43%|████████████████▍                     | 2584/5962 [00:19<00:26, 126.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2599/5962 [00:19<00:28, 117.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2069/5962 [00:19<00:30, 129.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 2436/5962 [00:19<00:35, 98.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 2447/5962 [00:19<00:36, 97.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▋                     | 2706/5962 [00:19<00:41, 78.20it/s]\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▌                     | 2598/5962 [00:19<00:28, 116.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 41%|███████████████▌                      | 2449/5962 [00:19<00:28, 121.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2613/5962 [00:19<00:30, 108.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 41%|███████████████▋                      | 2464/5962 [00:19<00:27, 127.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 2458/5962 [00:19<00:37, 94.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▋                     | 2611/5962 [00:19<00:29, 113.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2098/5962 [00:19<00:31, 121.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▊                     | 2631/5962 [00:19<00:27, 122.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 2715/5962 [00:19<00:43, 74.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|███████████████▊                      | 2485/5962 [00:19<00:24, 144.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████▏                      | 2469/5962 [00:19<00:35, 98.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▏                    | 2705/5962 [00:19<00:23, 139.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2111/5962 [00:19<00:31, 120.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2623/5962 [00:19<00:30, 111.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 2724/5962 [00:19<00:43, 74.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|███████████████▉                      | 2503/5962 [00:19<00:22, 151.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2483/5962 [00:19<00:32, 108.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2127/5962 [00:19<00:29, 129.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▊                     | 2638/5962 [00:20<00:27, 118.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 2732/5962 [00:19<00:44, 73.35it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▎                    | 2720/5962 [00:20<00:27, 116.44it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2680/5962 [00:19<00:24, 135.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|████████████████                      | 2520/5962 [00:20<00:25, 133.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▎                      | 2495/5962 [00:20<00:36, 94.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▉                     | 2740/5962 [00:20<00:45, 70.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▉                     | 2651/5962 [00:20<00:31, 103.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2701/5962 [00:20<00:21, 153.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2514/5962 [00:20<00:29, 117.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 2733/5962 [00:20<00:31, 101.45it/s]\u001b[A\n",
      "\n",
      "\n",
      " 46%|██████████████████                     | 2759/5962 [00:20<00:32, 98.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2159/5962 [00:20<00:29, 127.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|████████████████▉                     | 2663/5962 [00:20<00:31, 106.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▎                    | 2718/5962 [00:20<00:21, 152.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▏                     | 2532/5962 [00:20<00:25, 133.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 2744/5962 [00:20<00:31, 103.09it/s]\u001b[A\n",
      "\n",
      "\n",
      " 47%|█████████████████▋                    | 2779/5962 [00:20<00:25, 124.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2179/5962 [00:20<00:26, 145.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████                     | 2675/5962 [00:20<00:30, 107.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2735/5962 [00:20<00:20, 155.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2553/5962 [00:20<00:22, 149.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2799/5962 [00:20<00:21, 143.97it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▌                    | 2757/5962 [00:20<00:30, 103.71it/s]\u001b[A\n",
      "\n",
      " 45%|█████████████████▏                    | 2687/5962 [00:20<00:31, 104.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2195/5962 [00:20<00:31, 118.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2815/5962 [00:20<00:22, 141.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2569/5962 [00:20<00:24, 137.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2698/5962 [00:20<00:32, 100.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|██████████████████                     | 2768/5962 [00:20<00:34, 93.25it/s]\u001b[A\n",
      "\n",
      " 43%|████████████████▍                     | 2580/5962 [00:20<00:30, 110.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 2586/5962 [00:20<00:23, 146.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████                    | 2830/5962 [00:20<00:23, 134.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 47%|█████████████████▋                    | 2784/5962 [00:20<00:29, 108.76it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                    | 2709/5962 [00:20<00:32, 100.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2765/5962 [00:20<00:25, 126.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2602/5962 [00:20<00:23, 144.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2844/5962 [00:20<00:24, 129.41it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▎                    | 2721/5962 [00:20<00:30, 105.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2221/5962 [00:20<00:34, 107.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▋                    | 2784/5962 [00:20<00:22, 141.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2605/5962 [00:20<00:30, 111.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 2732/5962 [00:20<00:30, 105.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2802/5962 [00:20<00:20, 151.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2858/5962 [00:20<00:25, 123.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2233/5962 [00:20<00:35, 105.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▋                     | 2617/5962 [00:21<00:29, 113.02it/s]\u001b[A\u001b[A\n",
      " 48%|██████████████████                    | 2838/5962 [00:21<00:21, 145.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2818/5962 [00:20<00:21, 146.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▉                     | 2743/5962 [00:21<00:33, 95.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▊                     | 2634/5962 [00:21<00:26, 124.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 2245/5962 [00:21<00:39, 94.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▍                   | 2884/5962 [00:21<00:25, 118.44it/s]\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▏                   | 2854/5962 [00:21<00:23, 133.05it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████                    | 2834/5962 [00:20<00:22, 138.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2760/5962 [00:21<00:28, 111.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 2255/5962 [00:21<00:40, 91.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▊                     | 2647/5962 [00:21<00:29, 111.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▍                   | 2896/5962 [00:21<00:26, 117.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2851/5962 [00:21<00:21, 145.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 47%|█████████████████▋                    | 2782/5962 [00:21<00:22, 138.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2670/5962 [00:21<00:25, 131.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2268/5962 [00:21<00:36, 100.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|████████████████▉                     | 2662/5962 [00:21<00:27, 119.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2798/5962 [00:21<00:21, 144.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▎                   | 2882/5962 [00:21<00:23, 128.91it/s]\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2908/5962 [00:21<00:28, 107.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2686/5962 [00:21<00:24, 135.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2284/5962 [00:21<00:33, 111.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████                     | 2684/5962 [00:21<00:22, 144.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2814/5962 [00:21<00:21, 147.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▋                   | 2925/5962 [00:21<00:24, 122.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▍                   | 2896/5962 [00:21<00:25, 120.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2299/5962 [00:21<00:31, 115.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████▏                    | 2700/5962 [00:21<00:22, 144.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████                    | 2829/5962 [00:21<00:21, 143.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▊                   | 2947/5962 [00:21<00:20, 148.23it/s]\u001b[A\u001b[A\u001b[A\n",
      " 49%|██████████████████▌                   | 2910/5962 [00:21<00:24, 125.44it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▎                    | 2715/5962 [00:21<00:24, 134.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2314/5962 [00:21<00:29, 123.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 46%|█████████████████▎                    | 2725/5962 [00:21<00:18, 172.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2845/5962 [00:21<00:21, 146.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2970/5962 [00:21<00:17, 169.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2729/5962 [00:21<00:24, 133.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|██████████████████▋                   | 2931/5962 [00:21<00:21, 143.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2330/5962 [00:21<00:27, 132.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 46%|█████████████████▌                    | 2754/5962 [00:21<00:15, 203.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2861/5962 [00:21<00:20, 149.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2991/5962 [00:21<00:16, 178.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2744/5962 [00:21<00:23, 136.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|██████████████████▊                   | 2951/5962 [00:21<00:19, 158.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2348/5962 [00:21<00:24, 145.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|█████████████████▋                    | 2775/5962 [00:21<00:16, 193.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2881/5962 [00:21<00:19, 161.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████▏                  | 3010/5962 [00:21<00:16, 178.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2760/5962 [00:21<00:22, 142.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|██████████████████▉                   | 2968/5962 [00:21<00:18, 160.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2374/5962 [00:21<00:20, 176.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▍                   | 2900/5962 [00:22<00:18, 169.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3033/5962 [00:22<00:15, 189.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▋                    | 2781/5962 [00:21<00:19, 159.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|███████████████████                   | 2991/5962 [00:22<00:17, 172.21it/s]\u001b[A\n",
      "\n",
      " 47%|█████████████████▊                    | 2795/5962 [00:22<00:19, 161.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2404/5962 [00:22<00:17, 209.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2918/5962 [00:22<00:18, 166.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 3055/5962 [00:22<00:14, 194.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2798/5962 [00:22<00:19, 161.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|███████████████████▏                  | 3009/5962 [00:22<00:17, 166.95it/s]\u001b[A\n",
      "\n",
      " 47%|█████████████████▉                    | 2813/5962 [00:22<00:20, 156.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▋                   | 2935/5962 [00:22<00:18, 165.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2426/5962 [00:22<00:19, 185.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▌                  | 3075/5962 [00:22<00:15, 182.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 51%|███████████████████▎                  | 3034/5962 [00:22<00:15, 189.55it/s]\u001b[A\n",
      "\n",
      " 48%|██████████████████                    | 2840/5962 [00:22<00:16, 184.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▌                  | 3068/5962 [00:22<00:13, 216.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 2957/5962 [00:22<00:16, 179.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████                    | 2834/5962 [00:22<00:19, 162.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 51%|███████████████████▌                  | 3063/5962 [00:22<00:13, 213.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2860/5962 [00:22<00:17, 179.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 2467/5962 [00:22<00:18, 184.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 3094/5962 [00:22<00:19, 148.43it/s]\u001b[A\u001b[A\u001b[A\n",
      " 52%|███████████████████▋                  | 3085/5962 [00:22<00:13, 208.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2851/5962 [00:22<00:20, 150.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3113/5962 [00:22<00:13, 216.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2486/5962 [00:22<00:19, 179.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|███████████████████                   | 2995/5962 [00:22<00:18, 163.90it/s]\u001b[A\u001b[A\n",
      " 52%|███████████████████▊                  | 3107/5962 [00:22<00:13, 208.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2867/5962 [00:22<00:20, 149.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3110/5962 [00:22<00:22, 129.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|███████████████████▉                  | 3135/5962 [00:22<00:13, 204.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2512/5962 [00:22<00:17, 200.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      " 53%|███████████████████▉                  | 3137/5962 [00:22<00:12, 232.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▍                   | 2883/5962 [00:22<00:21, 146.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▉                  | 3124/5962 [00:22<00:22, 124.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3156/5962 [00:22<00:13, 200.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▏                     | 2533/5962 [00:22<00:17, 201.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▌                   | 2914/5962 [00:22<00:19, 156.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3028/5962 [00:22<00:21, 139.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3139/5962 [00:22<00:21, 128.66it/s]\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▏                 | 3161/5962 [00:22<00:13, 200.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3177/5962 [00:22<00:14, 193.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2554/5962 [00:22<00:18, 179.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2919/5962 [00:22<00:18, 160.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▍                  | 3043/5962 [00:23<00:22, 130.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3153/5962 [00:22<00:23, 120.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3197/5962 [00:22<00:14, 184.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 2576/5962 [00:22<00:17, 189.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▎                 | 3182/5962 [00:23<00:16, 169.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▌                  | 3061/5962 [00:23<00:20, 141.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▊                   | 2946/5962 [00:23<00:23, 128.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3219/5962 [00:22<00:14, 191.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3166/5962 [00:23<00:23, 116.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2596/5962 [00:23<00:17, 189.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 2953/5962 [00:23<00:18, 161.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▎                 | 3178/5962 [00:23<00:23, 116.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|██████████████████▊                   | 2960/5962 [00:23<00:24, 124.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3239/5962 [00:23<00:14, 186.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2616/5962 [00:23<00:17, 189.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 52%|███████████████████▌                  | 3076/5962 [00:23<00:24, 120.07it/s]\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 3190/5962 [00:23<00:24, 115.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2970/5962 [00:23<00:23, 127.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3258/5962 [00:23<00:15, 170.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|██████████████████▉                   | 2973/5962 [00:23<00:26, 113.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 3089/5962 [00:23<00:27, 103.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|███████████████████                   | 2988/5962 [00:23<00:24, 120.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3202/5962 [00:23<00:26, 102.55it/s]\u001b[A\u001b[A\u001b[A\n",
      " 54%|████████████████████▌                 | 3217/5962 [00:23<00:24, 114.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2984/5962 [00:23<00:24, 121.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 2654/5962 [00:23<00:22, 148.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3276/5962 [00:23<00:18, 142.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|███████████████████▏                  | 3004/5962 [00:23<00:23, 128.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|████████████████████▎                  | 3101/5962 [00:23<00:29, 98.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2997/5962 [00:23<00:24, 121.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2670/5962 [00:23<00:21, 150.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 54%|█████████████████████▏                 | 3231/5962 [00:23<00:27, 99.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3292/5962 [00:23<00:19, 134.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▎                  | 3023/5962 [00:23<00:20, 143.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3224/5962 [00:23<00:27, 100.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▏                  | 3010/5962 [00:23<00:24, 120.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▎                  | 3112/5962 [00:23<00:32, 86.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▎                  | 3039/5962 [00:23<00:19, 146.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 3307/5962 [00:23<00:19, 134.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3237/5962 [00:23<00:25, 107.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3023/5962 [00:23<00:24, 119.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 52%|████████████████████▍                  | 3122/5962 [00:23<00:33, 84.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2703/5962 [00:23<00:23, 138.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3321/5962 [00:23<00:19, 134.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▍                  | 3054/5962 [00:23<00:20, 141.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3248/5962 [00:23<00:25, 107.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 3041/5962 [00:23<00:21, 133.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 55%|████████████████████▊                 | 3260/5962 [00:23<00:25, 107.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 3055/5962 [00:23<00:22, 131.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▎                    | 2718/5962 [00:23<00:25, 126.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3335/5962 [00:23<00:21, 119.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▌                  | 3069/5962 [00:24<00:22, 127.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▎                 | 3259/5962 [00:24<00:28, 95.08it/s]\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▍                  | 3131/5962 [00:24<00:39, 71.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2738/5962 [00:24<00:22, 144.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▌                  | 3072/5962 [00:24<00:21, 137.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3352/5962 [00:23<00:19, 132.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▍                 | 3269/5962 [00:24<00:28, 95.99it/s]\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▌                  | 3139/5962 [00:24<00:42, 65.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2759/5962 [00:24<00:19, 160.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 3094/5962 [00:24<00:17, 159.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 3366/5962 [00:24<00:19, 133.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|████████████████████▏                  | 3083/5962 [00:24<00:29, 96.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 3294/5962 [00:24<00:30, 87.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3111/5962 [00:24<00:19, 149.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▍                 | 3279/5962 [00:24<00:36, 72.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▌                  | 3146/5962 [00:24<00:48, 57.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 3394/5962 [00:24<00:19, 132.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2792/5962 [00:24<00:21, 145.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 3288/5962 [00:24<00:39, 67.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|████████████████████▏                  | 3094/5962 [00:24<00:41, 69.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 3409/5962 [00:24<00:20, 124.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▋                  | 3153/5962 [00:24<01:02, 45.30it/s]\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████▋                 | 3313/5962 [00:24<00:35, 73.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2808/5962 [00:24<00:25, 121.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3142/5962 [00:24<00:23, 118.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3428/5962 [00:24<00:18, 138.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▋                 | 3311/5962 [00:24<00:31, 85.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▋                  | 3165/5962 [00:24<00:48, 58.17it/s]\u001b[A\u001b[A\n",
      " 56%|█████████████████████▊                 | 3330/5962 [00:24<00:27, 94.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████                    | 2827/5962 [00:24<00:22, 136.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3155/5962 [00:24<00:23, 118.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 3455/5962 [00:24<00:14, 170.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3329/5962 [00:24<00:24, 108.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 3174/5962 [00:24<00:43, 63.86it/s]\u001b[A\u001b[A\n",
      " 56%|█████████████████████▎                | 3343/5962 [00:24<00:25, 102.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2845/5962 [00:24<00:21, 146.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3168/5962 [00:24<00:23, 120.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3480/5962 [00:24<00:13, 188.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3341/5962 [00:24<00:24, 105.08it/s]\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████▍                | 3357/5962 [00:24<00:23, 110.88it/s]\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 3182/5962 [00:25<00:49, 55.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2861/5962 [00:24<00:25, 123.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3500/5962 [00:24<00:14, 167.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▊                  | 3181/5962 [00:24<00:27, 99.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|█████████████████████▍                | 3369/5962 [00:25<00:23, 109.93it/s]\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▉                 | 3353/5962 [00:25<00:26, 97.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2879/5962 [00:25<00:22, 135.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▍                  | 3133/5962 [00:25<00:43, 64.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3520/5962 [00:24<00:13, 175.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 3193/5962 [00:25<00:26, 103.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▊                  | 3189/5962 [00:25<00:54, 50.44it/s]\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████                 | 3381/5962 [00:25<00:26, 97.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3545/5962 [00:25<00:12, 193.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▍                   | 2894/5962 [00:25<00:22, 134.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3207/5962 [00:25<00:24, 111.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▌                  | 3141/5962 [00:25<00:46, 61.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|██████████████████████                 | 3376/5962 [00:25<00:26, 97.73it/s]\u001b[A\u001b[A\u001b[A\n",
      " 54%|████████████████████▉                  | 3195/5962 [00:25<00:56, 49.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 3572/5962 [00:25<00:11, 214.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2919/5962 [00:25<00:18, 163.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3228/5962 [00:25<00:20, 136.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▌                  | 3150/5962 [00:25<00:42, 66.34it/s]\u001b[A\u001b[A\n",
      " 57%|██████████████████████▎                | 3403/5962 [00:25<00:25, 99.96it/s]\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3388/5962 [00:25<00:25, 100.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▉                  | 3201/5962 [00:25<00:55, 50.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▋                   | 2941/5962 [00:25<00:17, 177.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3247/5962 [00:25<00:18, 149.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▋                  | 3158/5962 [00:25<00:41, 67.41it/s]\u001b[A\u001b[A\n",
      " 57%|█████████████████████▊                | 3421/5962 [00:25<00:21, 119.78it/s]\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▉                  | 3207/5962 [00:25<00:53, 51.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 2960/5962 [00:25<00:21, 142.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3263/5962 [00:25<00:22, 121.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▋                  | 3166/5962 [00:25<00:43, 63.70it/s]\u001b[A\u001b[A\n",
      " 58%|█████████████████████▉                | 3434/5962 [00:25<00:22, 110.52it/s]\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████                  | 3213/5962 [00:25<01:06, 41.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3619/5962 [00:25<00:17, 131.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|█████████████████████▉                | 3446/5962 [00:25<00:23, 107.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3277/5962 [00:25<00:24, 110.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2976/5962 [00:25<00:23, 124.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 3173/5962 [00:25<00:51, 54.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████                  | 3223/5962 [00:25<00:52, 52.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3637/5962 [00:25<00:17, 132.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2997/5962 [00:25<00:20, 143.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████                | 3458/5962 [00:25<00:24, 100.41it/s]\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 3180/5962 [00:26<00:49, 55.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3290/5962 [00:25<00:26, 100.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████▏                 | 3232/5962 [00:26<00:45, 59.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▏                  | 3013/5962 [00:26<00:20, 142.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▋                | 3469/5962 [00:26<00:26, 94.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▏                 | 3240/5962 [00:26<00:42, 64.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 3187/5962 [00:26<00:52, 53.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3654/5962 [00:25<00:19, 116.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 3459/5962 [00:26<00:25, 99.38it/s]\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▊                | 3481/5962 [00:26<00:25, 97.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3029/5962 [00:26<00:22, 130.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3316/5962 [00:26<00:25, 104.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████▏                 | 3247/5962 [00:26<00:44, 60.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3474/5962 [00:26<00:22, 110.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3669/5962 [00:26<00:20, 111.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 3046/5962 [00:26<00:20, 139.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▎               | 3501/5962 [00:26<00:20, 118.88it/s]\u001b[A\n",
      "\n",
      " 54%|████████████████████▉                  | 3200/5962 [00:26<00:50, 55.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3492/5962 [00:26<00:19, 127.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▊                 | 3327/5962 [00:26<00:27, 94.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3682/5962 [00:26<00:20, 112.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▍               | 3515/5962 [00:26<00:19, 123.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▌                  | 3061/5962 [00:26<00:21, 137.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|████████████████████▉                  | 3208/5962 [00:26<00:46, 59.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▍                 | 3269/5962 [00:26<00:32, 82.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3341/5962 [00:26<00:25, 104.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3702/5962 [00:26<00:17, 131.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▍               | 3528/5962 [00:26<00:19, 124.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▌                  | 3079/5962 [00:26<00:19, 146.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3537/5962 [00:26<00:13, 173.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▍                 | 3281/5962 [00:26<00:28, 92.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 3362/5962 [00:26<00:19, 130.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3718/5962 [00:26<00:16, 135.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▌               | 3544/5962 [00:26<00:18, 133.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 3295/5962 [00:26<00:25, 105.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 3556/5962 [00:26<00:13, 173.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3379/5962 [00:26<00:18, 140.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████                  | 3223/5962 [00:26<00:44, 60.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3734/5962 [00:26<00:15, 140.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████                 | 3309/5962 [00:26<00:23, 114.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 3394/5962 [00:26<00:18, 140.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3111/5962 [00:26<00:22, 124.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 3574/5962 [00:26<00:15, 153.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▏                 | 3230/5962 [00:26<00:46, 58.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3321/5962 [00:26<00:24, 109.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|██████████████████████▊               | 3576/5962 [00:26<00:20, 115.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3766/5962 [00:26<00:15, 143.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████▏                 | 3237/5962 [00:26<00:49, 55.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▉                  | 3125/5962 [00:26<00:25, 112.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3335/5962 [00:27<00:22, 115.38it/s]\u001b[A\u001b[A\u001b[A\n",
      " 60%|██████████████████████▉               | 3593/5962 [00:27<00:18, 128.28it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3781/5962 [00:26<00:16, 132.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████▏                 | 3245/5962 [00:27<00:46, 59.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3606/5962 [00:27<00:17, 138.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3350/5962 [00:27<00:20, 124.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3428/5962 [00:27<00:22, 110.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████               | 3614/5962 [00:27<00:16, 144.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 3795/5962 [00:27<00:16, 130.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▎                 | 3255/5962 [00:27<00:39, 68.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3621/5962 [00:27<00:18, 129.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 3363/5962 [00:27<00:23, 109.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▏              | 3630/5962 [00:27<00:16, 140.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 3441/5962 [00:27<00:24, 104.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3809/5962 [00:27<00:16, 132.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▍                 | 3272/5962 [00:27<00:28, 95.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3635/5962 [00:27<00:18, 123.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3375/5962 [00:27<00:24, 106.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▋                  | 3161/5962 [00:27<00:30, 92.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3645/5962 [00:27<00:17, 130.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|████████████████████▉                 | 3293/5962 [00:27<00:21, 123.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3655/5962 [00:27<00:16, 141.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 3838/5962 [00:27<00:15, 133.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▌                | 3386/5962 [00:27<00:25, 100.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▋                  | 3171/5962 [00:27<00:32, 86.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▎              | 3659/5962 [00:27<00:19, 119.99it/s]\u001b[A\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3671/5962 [00:27<00:15, 145.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 3465/5962 [00:27<00:26, 93.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3852/5962 [00:27<00:15, 134.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▏                | 3326/5962 [00:27<00:18, 143.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▏                | 3397/5962 [00:27<00:27, 93.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▍              | 3672/5962 [00:27<00:19, 119.95it/s]\u001b[A\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3693/5962 [00:27<00:13, 165.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 3476/5962 [00:27<00:26, 94.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3870/5962 [00:27<00:14, 147.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▎                | 3341/5962 [00:27<00:19, 136.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▎                | 3407/5962 [00:27<00:26, 95.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▍              | 3686/5962 [00:27<00:18, 122.65it/s]\u001b[A\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3714/5962 [00:27<00:12, 176.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▊                | 3486/5962 [00:27<00:26, 93.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3890/5962 [00:27<00:12, 161.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▍                | 3356/5962 [00:27<00:18, 138.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3217/5962 [00:27<00:22, 119.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3733/5962 [00:27<00:12, 180.24it/s]\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████▎                | 3418/5962 [00:27<00:27, 93.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▊                | 3496/5962 [00:27<00:26, 93.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3907/5962 [00:27<00:13, 156.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3233/5962 [00:27<00:21, 129.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▍                | 3371/5962 [00:27<00:19, 132.09it/s]\u001b[A\u001b[A\n",
      " 57%|██████████████████████▍                | 3428/5962 [00:28<00:27, 92.82it/s]\u001b[A\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3752/5962 [00:27<00:13, 169.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3518/5962 [00:27<00:19, 124.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3923/5962 [00:27<00:13, 148.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▋                 | 3254/5962 [00:27<00:17, 150.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▌                | 3389/5962 [00:28<00:17, 143.32it/s]\u001b[A\u001b[A\n",
      " 58%|█████████████████████▉                | 3445/5962 [00:28<00:22, 111.83it/s]\u001b[A\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3771/5962 [00:28<00:12, 174.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3541/5962 [00:27<00:16, 150.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3939/5962 [00:27<00:13, 148.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3272/5962 [00:28<00:17, 154.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|███████████████████████▉              | 3747/5962 [00:28<00:15, 138.80it/s]\u001b[A\n",
      "\n",
      " 58%|██████████████████████                | 3463/5962 [00:28<00:19, 127.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 3558/5962 [00:28<00:16, 150.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 3789/5962 [00:28<00:13, 163.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 3954/5962 [00:28<00:15, 132.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3288/5962 [00:28<00:18, 142.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|███████████████████████▉              | 3762/5962 [00:28<00:16, 131.36it/s]\u001b[A\n",
      "\n",
      " 57%|█████████████████████▊                | 3418/5962 [00:28<00:19, 129.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3476/5962 [00:28<00:22, 108.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3806/5962 [00:28<00:14, 145.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3968/5962 [00:28<00:15, 128.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 3303/5962 [00:28<00:19, 134.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3594/5962 [00:28<00:15, 156.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▏               | 3488/5962 [00:28<00:22, 109.47it/s]\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3822/5962 [00:28<00:15, 140.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████████████████████▉                | 3451/5962 [00:28<00:17, 140.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3317/5962 [00:28<00:19, 132.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3982/5962 [00:28<00:16, 118.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▏             | 3789/5962 [00:28<00:18, 117.71it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3500/5962 [00:28<00:22, 109.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 3839/5962 [00:28<00:14, 147.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 3467/5962 [00:28<00:17, 143.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▏             | 3802/5962 [00:28<00:18, 119.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3995/5962 [00:28<00:17, 110.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▉                | 3512/5962 [00:28<00:25, 96.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3627/5962 [00:28<00:18, 127.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3350/5962 [00:28<00:18, 143.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|██████████████████████▏               | 3482/5962 [00:28<00:18, 132.84it/s]\u001b[A\u001b[A\n",
      " 64%|████████████████████████▎             | 3815/5962 [00:28<00:18, 115.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4007/5962 [00:28<00:18, 107.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3870/5962 [00:28<00:14, 139.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3527/5962 [00:28<00:23, 103.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▎               | 3496/5962 [00:28<00:19, 129.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 3365/5962 [00:28<00:20, 126.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▍             | 3827/5962 [00:28<00:18, 113.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▋            | 4023/5962 [00:28<00:16, 118.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3889/5962 [00:28<00:13, 153.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3544/5962 [00:29<00:20, 119.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▍               | 3517/5962 [00:29<00:16, 147.98it/s]\u001b[A\u001b[A\n",
      " 65%|████████████████████████▌             | 3847/5962 [00:29<00:15, 133.97it/s]\u001b[A\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3911/5962 [00:29<00:11, 171.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3379/5962 [00:28<00:21, 119.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4048/5962 [00:28<00:13, 146.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 3570/5962 [00:29<00:15, 152.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▌               | 3535/5962 [00:29<00:15, 156.13it/s]\u001b[A\u001b[A\n",
      " 65%|████████████████████████▌             | 3863/5962 [00:29<00:15, 138.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 3393/5962 [00:29<00:20, 123.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3929/5962 [00:29<00:12, 168.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4064/5962 [00:28<00:12, 147.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3589/5962 [00:29<00:14, 161.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▋               | 3553/5962 [00:29<00:14, 161.36it/s]\u001b[A\u001b[A\n",
      " 65%|████████████████████████▋             | 3881/5962 [00:29<00:14, 148.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3420/5962 [00:29<00:15, 159.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████            | 4081/5962 [00:29<00:12, 153.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3706/5962 [00:29<00:16, 134.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▉               | 3606/5962 [00:29<00:17, 137.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 3441/5962 [00:29<00:14, 173.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▊             | 3897/5962 [00:29<00:14, 141.86it/s]\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3967/5962 [00:29<00:11, 173.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████            | 4097/5962 [00:29<00:13, 143.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3720/5962 [00:29<00:17, 129.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 3459/5962 [00:29<00:14, 167.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3985/5962 [00:29<00:11, 171.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▊               | 3588/5962 [00:29<00:16, 141.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3621/5962 [00:29<00:19, 120.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3737/5962 [00:29<00:15, 139.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|████████████████████████▉             | 3912/5962 [00:29<00:17, 117.41it/s]\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4007/5962 [00:29<00:10, 184.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3479/5962 [00:29<00:14, 170.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▉               | 3603/5962 [00:29<00:17, 134.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4130/5962 [00:29<00:12, 147.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3752/5962 [00:29<00:16, 135.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▋            | 4026/5962 [00:29<00:10, 179.75it/s]\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▏              | 3634/5962 [00:29<00:22, 103.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 4146/5962 [00:29<00:12, 148.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████               | 3617/5962 [00:29<00:19, 118.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3646/5962 [00:29<00:22, 104.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4045/5962 [00:29<00:11, 167.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3497/5962 [00:29<00:19, 123.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4162/5962 [00:29<00:12, 144.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████▏              | 3630/5962 [00:29<00:20, 113.39it/s]\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▊             | 3937/5962 [00:29<00:22, 88.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3659/5962 [00:29<00:20, 110.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4063/5962 [00:29<00:12, 157.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4177/5962 [00:29<00:12, 137.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████▏              | 3642/5962 [00:30<00:20, 112.73it/s]\u001b[A\u001b[A\n",
      " 62%|███████████████████████▍              | 3673/5962 [00:30<00:19, 115.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3512/5962 [00:29<00:23, 105.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4079/5962 [00:30<00:11, 157.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 4192/5962 [00:29<00:12, 138.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▊              | 3792/5962 [00:29<00:21, 99.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▉             | 3960/5962 [00:30<00:20, 96.70it/s]\u001b[A\n",
      "\n",
      " 62%|███████████████████████▍              | 3686/5962 [00:30<00:19, 118.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4100/5962 [00:30<00:10, 171.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 4206/5962 [00:29<00:12, 136.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▉              | 3803/5962 [00:30<00:21, 99.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|█████████████████████████▎            | 3974/5962 [00:30<00:18, 106.74it/s]\u001b[A\n",
      "\n",
      " 62%|███████████████████████▌              | 3702/5962 [00:30<00:17, 129.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████                | 3525/5962 [00:30<00:26, 92.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4130/5962 [00:30<00:08, 205.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▉           | 4224/5962 [00:30<00:11, 148.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3814/5962 [00:30<00:21, 100.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▋              | 3721/5962 [00:30<00:15, 144.24it/s]\u001b[A\n",
      "\n",
      " 62%|███████████████████████▌              | 3689/5962 [00:30<00:16, 136.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 4151/5962 [00:30<00:09, 200.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4239/5962 [00:30<00:12, 143.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████▏               | 3536/5962 [00:30<00:28, 85.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████              | 3825/5962 [00:30<00:21, 98.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|███████████████████████▊              | 3736/5962 [00:30<00:15, 145.23it/s]\u001b[A\n",
      "\n",
      " 62%|███████████████████████▋              | 3709/5962 [00:30<00:14, 153.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4172/5962 [00:30<00:08, 198.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▏          | 4259/5962 [00:30<00:10, 158.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████▏               | 3546/5962 [00:30<00:28, 84.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▋            | 4032/5962 [00:30<00:12, 151.18it/s]\u001b[A\n",
      "\n",
      " 62%|███████████████████████▋              | 3726/5962 [00:30<00:14, 155.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3751/5962 [00:30<00:15, 139.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4284/5962 [00:30<00:09, 184.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 4193/5962 [00:30<00:09, 193.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 3564/5962 [00:30<00:23, 103.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▊            | 4053/5962 [00:30<00:11, 167.11it/s]\u001b[A\n",
      "\n",
      " 63%|███████████████████████▉              | 3751/5962 [00:30<00:12, 181.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3766/5962 [00:30<00:15, 138.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4306/5962 [00:30<00:08, 191.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 4214/5962 [00:30<00:09, 193.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 3586/5962 [00:30<00:18, 127.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|████████████████████████              | 3777/5962 [00:30<00:10, 203.71it/s]\u001b[A\u001b[A\n",
      " 64%|████████████████████████▏             | 3786/5962 [00:30<00:14, 153.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3871/5962 [00:30<00:17, 119.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▉           | 4235/5962 [00:30<00:08, 193.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3607/5962 [00:30<00:16, 144.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▏             | 3800/5962 [00:30<00:10, 206.70it/s]\u001b[A\u001b[A\n",
      " 64%|████████████████████████▎             | 3806/5962 [00:30<00:13, 159.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▌          | 4326/5962 [00:30<00:10, 153.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3884/5962 [00:30<00:18, 112.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4255/5962 [00:30<00:08, 193.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3623/5962 [00:30<00:16, 138.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 4343/5962 [00:30<00:10, 148.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4279/5962 [00:30<00:08, 205.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▎             | 3821/5962 [00:31<00:12, 170.16it/s]\u001b[A\u001b[A\n",
      " 69%|██████████████████████████▎           | 4119/5962 [00:31<00:11, 159.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3896/5962 [00:30<00:20, 103.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3823/5962 [00:31<00:19, 112.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3907/5962 [00:31<00:19, 103.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4300/5962 [00:31<00:09, 182.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▍             | 3840/5962 [00:31<00:13, 158.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 4359/5962 [00:30<00:12, 128.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3653/5962 [00:31<00:17, 134.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▍             | 3837/5962 [00:31<00:18, 113.26it/s]\u001b[A\n",
      "\n",
      " 65%|████████████████████████▌             | 3857/5962 [00:31<00:14, 150.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 4373/5962 [00:31<00:12, 125.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3669/5962 [00:31<00:16, 140.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▋             | 3918/5962 [00:31<00:22, 91.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3850/5962 [00:31<00:18, 114.95it/s]\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▍           | 4152/5962 [00:31<00:14, 126.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████▉          | 4387/5962 [00:31<00:12, 126.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 4337/5962 [00:31<00:09, 163.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3684/5962 [00:31<00:16, 135.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|████████████████████████▋             | 3873/5962 [00:31<00:14, 141.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▋             | 3928/5962 [00:31<00:23, 87.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▌           | 4166/5962 [00:31<00:13, 129.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 4401/5962 [00:31<00:12, 127.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3863/5962 [00:31<00:20, 104.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|████████████████████████▊             | 3888/5962 [00:31<00:14, 141.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3705/5962 [00:31<00:14, 150.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▊             | 3939/5962 [00:31<00:22, 91.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▋           | 4184/5962 [00:31<00:12, 140.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4422/5962 [00:31<00:10, 148.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3876/5962 [00:31<00:19, 107.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|████████████████████████▉             | 3905/5962 [00:31<00:14, 146.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3722/5962 [00:31<00:14, 153.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 3955/5962 [00:31<00:18, 108.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▊           | 4201/5962 [00:31<00:11, 147.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 4446/5962 [00:31<00:08, 172.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3892/5962 [00:31<00:17, 120.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3971/5962 [00:31<00:16, 120.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3738/5962 [00:31<00:16, 138.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|██████████████████████████▉           | 4217/5962 [00:31<00:11, 147.86it/s]\u001b[A\n",
      "\n",
      " 66%|████████████████████████▉             | 3920/5962 [00:31<00:16, 126.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3907/5962 [00:31<00:17, 119.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4464/5962 [00:31<00:09, 153.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4415/5962 [00:31<00:09, 159.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████             | 3934/5962 [00:31<00:17, 118.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3753/5962 [00:31<00:18, 121.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4001/5962 [00:31<00:14, 132.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|██████████████████████████▉           | 4233/5962 [00:31<00:14, 119.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4481/5962 [00:31<00:11, 131.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▋             | 3920/5962 [00:32<00:24, 82.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4432/5962 [00:32<00:13, 113.02it/s]\u001b[A\u001b[A\u001b[A\n",
      " 71%|███████████████████████████▊           | 4247/5962 [00:32<00:17, 99.34it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████▋              | 3766/5962 [00:32<00:24, 90.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▊             | 3947/5962 [00:32<00:23, 87.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▋            | 4028/5962 [00:32<00:16, 120.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 4496/5962 [00:32<00:12, 115.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 4446/5962 [00:32<00:13, 116.15it/s]\u001b[A\u001b[A\u001b[A\n",
      " 71%|███████████████████████████▏          | 4259/5962 [00:32<00:16, 100.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████▋              | 3779/5962 [00:32<00:22, 96.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▉             | 3958/5962 [00:32<00:22, 88.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▋             | 3931/5962 [00:32<00:26, 75.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▍            | 4041/5962 [00:32<00:19, 96.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4285/5962 [00:32<00:12, 135.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 3803/5962 [00:32<00:17, 126.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▊             | 3943/5962 [00:32<00:24, 83.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4528/5962 [00:32<00:11, 126.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3823/5962 [00:32<00:14, 143.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4475/5962 [00:32<00:12, 117.79it/s]\u001b[A\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▊             | 3953/5962 [00:32<00:23, 87.07it/s]\u001b[A\n",
      "\n",
      " 67%|█████████████████████████▍            | 3985/5962 [00:32<00:19, 100.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████         | 4551/5962 [00:32<00:09, 150.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▌            | 4052/5962 [00:32<00:23, 82.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 3843/5962 [00:32<00:13, 157.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 4492/5962 [00:32<00:11, 126.82it/s]\u001b[A\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▉             | 3963/5962 [00:32<00:22, 88.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4571/5962 [00:32<00:08, 163.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▏            | 3996/5962 [00:32<00:21, 91.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 4510/5962 [00:32<00:10, 139.28it/s]\u001b[A\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▋          | 4336/5962 [00:32<00:10, 150.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3861/5962 [00:32<00:13, 153.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▉             | 3973/5962 [00:32<00:22, 88.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4590/5962 [00:32<00:08, 169.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▏            | 4006/5962 [00:32<00:24, 81.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4525/5962 [00:32<00:11, 128.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████             | 3983/5962 [00:32<00:24, 79.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▋          | 4352/5962 [00:32<00:12, 125.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4608/5962 [00:32<00:09, 143.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▋            | 4071/5962 [00:32<00:28, 67.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▎            | 4019/5962 [00:32<00:21, 89.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4548/5962 [00:32<00:09, 152.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▏            | 3995/5962 [00:33<00:22, 88.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▍        | 4627/5962 [00:32<00:08, 151.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▋            | 4079/5962 [00:32<00:27, 68.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▊          | 4366/5962 [00:33<00:13, 115.84it/s]\u001b[A\n",
      "\n",
      " 68%|██████████████████████████▎            | 4031/5962 [00:33<00:20, 96.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 4565/5962 [00:33<00:09, 153.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4010/5962 [00:33<00:18, 103.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4661/5962 [00:32<00:06, 197.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 4090/5962 [00:33<00:24, 77.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|███████████████████████████▉          | 4390/5962 [00:33<00:10, 144.20it/s]\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▊            | 4047/5962 [00:33<00:17, 112.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▋            | 4022/5962 [00:33<00:18, 104.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▊        | 4683/5962 [00:33<00:06, 200.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 4100/5962 [00:33<00:22, 81.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 3945/5962 [00:33<00:11, 168.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████          | 4409/5962 [00:33<00:10, 152.71it/s]\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▋            | 4035/5962 [00:33<00:17, 110.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4117/5962 [00:33<00:18, 101.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 4704/5962 [00:33<00:06, 194.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4604/5962 [00:33<00:10, 135.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▊            | 4047/5962 [00:33<00:17, 109.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 4725/5962 [00:33<00:06, 195.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▏         | 4426/5962 [00:33<00:12, 124.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████            | 4128/5962 [00:33<00:18, 98.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 4619/5962 [00:33<00:09, 136.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3980/5962 [00:33<00:12, 158.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████            | 4084/5962 [00:33<00:17, 110.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4750/5962 [00:33<00:05, 210.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4059/5962 [00:33<00:18, 101.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▎         | 4440/5962 [00:33<00:12, 122.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3998/5962 [00:33<00:12, 157.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▏           | 4100/5962 [00:33<00:15, 120.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4634/5962 [00:33<00:10, 123.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▌            | 4070/5962 [00:33<00:19, 98.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4015/5962 [00:33<00:12, 154.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▍         | 4454/5962 [00:33<00:12, 118.75it/s]\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▏           | 4114/5962 [00:33<00:14, 124.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4772/5962 [00:33<00:06, 171.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4648/5962 [00:33<00:12, 105.44it/s]\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▍         | 4467/5962 [00:33<00:12, 117.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▎           | 4166/5962 [00:33<00:18, 97.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▎           | 4127/5962 [00:33<00:15, 118.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▋            | 4081/5962 [00:33<00:21, 88.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4791/5962 [00:33<00:07, 166.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▌         | 4480/5962 [00:33<00:13, 113.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4046/5962 [00:33<00:13, 139.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▍           | 4139/5962 [00:33<00:16, 110.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 4660/5962 [00:33<00:13, 93.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4809/5962 [00:33<00:07, 157.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 4091/5962 [00:34<00:24, 75.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▋         | 4495/5962 [00:34<00:11, 122.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4070/5962 [00:34<00:11, 162.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████▍           | 4151/5962 [00:34<00:17, 105.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4827/5962 [00:33<00:07, 162.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▌        | 4671/5962 [00:34<00:14, 88.05it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▊         | 4511/5962 [00:34<00:11, 130.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 4099/5962 [00:34<00:26, 69.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████            | 4087/5962 [00:34<00:11, 157.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4844/5962 [00:34<00:06, 163.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▏           | 4162/5962 [00:34<00:19, 92.80it/s]\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▊         | 4527/5962 [00:34<00:10, 136.98it/s]\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▌        | 4681/5962 [00:34<00:15, 80.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4103/5962 [00:34<00:12, 153.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 4107/5962 [00:34<00:27, 67.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▍           | 4195/5962 [00:34<00:25, 69.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▉         | 4541/5962 [00:34<00:10, 135.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4119/5962 [00:34<00:12, 151.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▉            | 4114/5962 [00:34<00:27, 66.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4690/5962 [00:34<00:16, 77.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▎           | 4172/5962 [00:34<00:23, 74.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▉            | 4121/5962 [00:34<00:27, 67.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4698/5962 [00:34<00:16, 76.37it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|█████████████████████████████         | 4555/5962 [00:34<00:12, 109.26it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4135/5962 [00:34<00:14, 127.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 4895/5962 [00:34<00:08, 131.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▎           | 4181/5962 [00:34<00:25, 69.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|███████████████████████████            | 4131/5962 [00:34<00:25, 70.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 4210/5962 [00:34<00:32, 53.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▎      | 4916/5962 [00:34<00:06, 150.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▊         | 4567/5962 [00:34<00:14, 99.37it/s]\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▍           | 4194/5962 [00:34<00:21, 81.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 4149/5962 [00:34<00:15, 118.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|███████████████████████████            | 4141/5962 [00:34<00:23, 77.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 4224/5962 [00:34<00:24, 70.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4938/5962 [00:34<00:06, 167.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████████████████████████▌           | 4210/5962 [00:34<00:18, 96.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4162/5962 [00:34<00:15, 116.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▉        | 4732/5962 [00:34<00:12, 97.68it/s]\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▉         | 4578/5962 [00:34<00:15, 89.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 4241/5962 [00:34<00:18, 92.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4956/5962 [00:34<00:06, 164.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|██████████████████████████▉           | 4224/5962 [00:34<00:16, 106.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4168/5962 [00:35<00:17, 105.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 4745/5962 [00:34<00:11, 105.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▏          | 4257/5962 [00:34<00:15, 108.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████████████████████████           | 4238/5962 [00:35<00:15, 113.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 4183/5962 [00:35<00:15, 117.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4758/5962 [00:35<00:10, 110.02it/s]\u001b[A\u001b[A\u001b[A\n",
      " 77%|██████████████████████████████         | 4588/5962 [00:35<00:18, 75.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4974/5962 [00:34<00:07, 138.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▏          | 4270/5962 [00:34<00:15, 110.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████████████████████████▏          | 4261/5962 [00:35<00:12, 139.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▊           | 4197/5962 [00:35<00:14, 121.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4774/5962 [00:35<00:09, 120.68it/s]\u001b[A\u001b[A\u001b[A\n",
      " 77%|██████████████████████████████         | 4602/5962 [00:35<00:15, 86.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4283/5962 [00:35<00:16, 101.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4243/5962 [00:35<00:10, 160.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4787/5962 [00:35<00:09, 117.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4990/5962 [00:35<00:09, 103.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|███████████████████████████▌           | 4210/5962 [00:35<00:19, 92.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4276/5962 [00:35<00:16, 101.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████           | 4294/5962 [00:35<00:18, 90.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▏          | 4260/5962 [00:35<00:11, 143.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4813/5962 [00:35<00:09, 120.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 5003/5962 [00:35<00:09, 97.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 4304/5962 [00:35<00:18, 91.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 4221/5962 [00:35<00:20, 84.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4829/5962 [00:35<00:08, 130.88it/s]\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▎        | 4629/5962 [00:35<00:18, 72.34it/s]\u001b[A\n",
      "\n",
      " 72%|███████████████████████████▍          | 4300/5962 [00:35<00:16, 102.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 4232/5962 [00:35<00:19, 88.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4295/5962 [00:35<00:11, 140.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 5015/5962 [00:35<00:10, 89.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4848/5962 [00:35<00:07, 147.38it/s]\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▎        | 4637/5962 [00:35<00:17, 74.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 4242/5962 [00:35<00:19, 88.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 5025/5962 [00:35<00:10, 90.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|████████████████████████████▏          | 4312/5962 [00:35<00:17, 92.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████▉       | 4863/5962 [00:35<00:07, 147.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4310/5962 [00:35<00:13, 126.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▍        | 4645/5962 [00:35<00:17, 74.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 4334/5962 [00:35<00:18, 89.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▉      | 5036/5962 [00:35<00:10, 92.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 4335/5962 [00:35<00:10, 156.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▊           | 4252/5962 [00:35<00:21, 78.88it/s]\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▍        | 4657/5962 [00:35<00:15, 83.82it/s]\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▎          | 4323/5962 [00:35<00:19, 84.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▍          | 4344/5962 [00:35<00:18, 86.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5049/5962 [00:35<00:09, 101.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 4897/5962 [00:36<00:06, 154.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▊           | 4261/5962 [00:36<00:22, 74.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▌        | 4666/5962 [00:36<00:16, 78.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▍          | 4356/5962 [00:35<00:16, 95.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▎          | 4332/5962 [00:36<00:20, 78.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 5060/5962 [00:35<00:08, 102.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▎      | 4913/5962 [00:36<00:07, 131.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▌          | 4367/5962 [00:36<00:16, 96.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▉           | 4269/5962 [00:36<00:25, 66.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5071/5962 [00:36<00:09, 98.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▌        | 4675/5962 [00:36<00:18, 69.06it/s]\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▍          | 4341/5962 [00:36<00:22, 70.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4927/5962 [00:36<00:07, 130.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▉           | 4279/5962 [00:36<00:23, 72.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████▉          | 4384/5962 [00:36<00:12, 121.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5082/5962 [00:36<00:09, 90.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▍          | 4350/5962 [00:36<00:22, 72.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4941/5962 [00:36<00:08, 120.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 72%|████████████████████████████           | 4288/5962 [00:36<00:22, 75.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▋          | 4386/5962 [00:36<00:19, 80.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▌          | 4359/5962 [00:36<00:21, 76.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5092/5962 [00:36<00:10, 84.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 4397/5962 [00:36<00:15, 99.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|████████████████████████████           | 4296/5962 [00:36<00:26, 62.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▎     | 5101/5962 [00:36<00:10, 80.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 4305/5962 [00:36<00:24, 68.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▋          | 4376/5962 [00:36<00:22, 70.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 4409/5962 [00:36<00:18, 84.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▋          | 4395/5962 [00:36<00:28, 55.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 79%|██████████████████████████████▋        | 4690/5962 [00:36<00:31, 39.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 5110/5962 [00:36<00:13, 65.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▋          | 4387/5962 [00:36<00:21, 73.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▍      | 4965/5962 [00:36<00:13, 73.78it/s]\u001b[A\u001b[A\u001b[A\n",
      " 79%|██████████████████████████████▋        | 4698/5962 [00:36<00:28, 44.54it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 4313/5962 [00:37<00:28, 57.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 4402/5962 [00:36<00:31, 50.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▌     | 5126/5962 [00:36<00:09, 85.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▌      | 4983/5962 [00:36<00:10, 93.11it/s]\u001b[A\u001b[A\u001b[A\n",
      " 79%|██████████████████████████████▊        | 4709/5962 [00:37<00:22, 55.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▉          | 4429/5962 [00:36<00:18, 82.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▋          | 4395/5962 [00:37<00:23, 66.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 4408/5962 [00:36<00:29, 51.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▎          | 4320/5962 [00:37<00:28, 56.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████          | 4444/5962 [00:37<00:15, 97.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 79%|██████████████████████████████▉        | 4724/5962 [00:37<00:17, 72.81it/s]\u001b[A\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 4327/5962 [00:37<00:27, 59.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▉          | 4416/5962 [00:37<00:27, 56.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5153/5962 [00:37<00:07, 103.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▊          | 4402/5962 [00:37<00:28, 55.69it/s]\u001b[A\u001b[A\n",
      " 80%|███████████████████████████████        | 4741/5962 [00:37<00:13, 93.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▍          | 4344/5962 [00:37<00:18, 86.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▉          | 4424/5962 [00:37<00:26, 59.12it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5165/5962 [00:37<00:07, 101.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 5006/5962 [00:37<00:11, 84.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4478/5962 [00:37<00:11, 126.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▊          | 4408/5962 [00:37<00:29, 53.34it/s]\u001b[A\u001b[A\n",
      " 73%|████████████████████████████▌          | 4357/5962 [00:37<00:17, 94.34it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████          | 4436/5962 [00:37<00:20, 73.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████     | 5183/5962 [00:37<00:06, 121.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 5016/5962 [00:37<00:11, 80.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 4494/5962 [00:37<00:10, 133.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▉          | 4422/5962 [00:37<00:21, 71.65it/s]\u001b[A\u001b[A\n",
      " 80%|███████████████████████████████▏       | 4763/5962 [00:37<00:13, 91.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████          | 4449/5962 [00:37<00:17, 87.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▌          | 4368/5962 [00:37<00:17, 91.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 5025/5962 [00:37<00:11, 80.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|████████████████████████████▎         | 4444/5962 [00:37<00:14, 107.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 4509/5962 [00:37<00:11, 123.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4466/5962 [00:37<00:13, 107.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▍       | 4779/5962 [00:37<00:11, 105.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5225/5962 [00:37<00:05, 141.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▉      | 5036/5962 [00:37<00:10, 86.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▋          | 4378/5962 [00:37<00:20, 76.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4478/5962 [00:37<00:13, 108.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|███████████████████████████████▎       | 4791/5962 [00:37<00:12, 95.81it/s]\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████      | 5046/5962 [00:37<00:10, 88.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|████████████████████████████▌         | 4483/5962 [00:37<00:10, 143.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▋          | 4387/5962 [00:37<00:20, 78.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4490/5962 [00:37<00:13, 110.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5240/5962 [00:37<00:05, 120.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████      | 5056/5962 [00:37<00:10, 88.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|████████████████████████████▋         | 4499/5962 [00:37<00:10, 142.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 4397/5962 [00:37<00:19, 81.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|███████████████████████████████▍       | 4802/5962 [00:37<00:13, 84.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 4502/5962 [00:37<00:14, 104.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5254/5962 [00:37<00:06, 108.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████▊         | 4517/5962 [00:38<00:09, 152.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4547/5962 [00:37<00:13, 104.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 4406/5962 [00:38<00:19, 81.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4514/5962 [00:37<00:13, 105.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|███████████████████████████████▍       | 4812/5962 [00:38<00:13, 82.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5266/5962 [00:37<00:06, 109.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████▉         | 4535/5962 [00:38<00:08, 159.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5076/5962 [00:38<00:10, 88.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▊         | 4558/5962 [00:38<00:14, 96.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4538/5962 [00:38<00:10, 141.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▉          | 4415/5962 [00:38<00:20, 76.43it/s]\u001b[A\n",
      "\n",
      " 76%|█████████████████████████████         | 4559/5962 [00:38<00:07, 179.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5281/5962 [00:38<00:05, 116.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5087/5962 [00:38<00:09, 93.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████         | 4558/5962 [00:38<00:08, 157.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▉          | 4424/5962 [00:38<00:19, 78.79it/s]\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▉         | 4569/5962 [00:38<00:14, 94.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5294/5962 [00:38<00:05, 116.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4578/5962 [00:38<00:08, 170.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5097/5962 [00:38<00:09, 93.72it/s]\u001b[A\u001b[A\u001b[A\n",
      " 81%|███████████████████████████████▋       | 4842/5962 [00:38<00:12, 91.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4588/5962 [00:38<00:11, 116.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4575/5962 [00:38<00:10, 138.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5307/5962 [00:38<00:05, 117.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 5108/5962 [00:38<00:08, 98.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4596/5962 [00:38<00:08, 164.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████          | 4444/5962 [00:38<00:21, 69.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 5118/5962 [00:38<00:09, 87.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 5319/5962 [00:38<00:06, 93.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▍        | 4613/5962 [00:38<00:09, 136.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 4612/5962 [00:38<00:13, 101.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|███████████████████████████████▋       | 4852/5962 [00:38<00:18, 60.66it/s]\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▌     | 5128/5962 [00:38<00:09, 84.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████         | 4590/5962 [00:38<00:14, 94.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 5334/5962 [00:38<00:05, 106.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▍        | 4628/5962 [00:38<00:09, 137.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▏         | 4460/5962 [00:38<00:20, 71.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 5142/5962 [00:38<00:08, 98.53it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▊       | 4860/5962 [00:38<00:18, 59.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████         | 4602/5962 [00:38<00:14, 96.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████    | 5350/5962 [00:38<00:05, 118.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4643/5962 [00:38<00:09, 134.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▏         | 4468/5962 [00:38<00:20, 71.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 5153/5962 [00:38<00:08, 93.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4657/5962 [00:38<00:09, 134.45it/s]\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▊       | 4867/5962 [00:38<00:19, 55.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 5363/5962 [00:38<00:05, 108.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▎         | 4476/5962 [00:39<00:21, 67.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████▏        | 4614/5962 [00:38<00:16, 81.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▊     | 5163/5962 [00:39<00:08, 90.15it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▉       | 4874/5962 [00:39<00:19, 57.24it/s]\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▊        | 4671/5962 [00:39<00:10, 119.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▎         | 4485/5962 [00:39<00:20, 73.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▊        | 4672/5962 [00:39<00:10, 126.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▏        | 4624/5962 [00:39<00:16, 79.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▊     | 5173/5962 [00:39<00:09, 84.73it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▉       | 4882/5962 [00:39<00:17, 61.14it/s]\u001b[A\n",
      "\n",
      " 79%|█████████████████████████████▊        | 4684/5962 [00:39<00:11, 113.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▍         | 4495/5962 [00:39<00:19, 77.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▊        | 4686/5962 [00:39<00:10, 123.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 5182/5962 [00:39<00:09, 84.53it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|████████████████████████████████       | 4894/5962 [00:39<00:14, 73.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 4633/5962 [00:39<00:17, 75.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5403/5962 [00:39<00:04, 113.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|█████████████████████████████▍         | 4504/5962 [00:39<00:19, 76.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 4699/5962 [00:39<00:10, 115.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 5191/5962 [00:39<00:09, 85.09it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|████████████████████████████████       | 4904/5962 [00:39<00:13, 79.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 4642/5962 [00:39<00:16, 78.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▌         | 4513/5962 [00:39<00:18, 79.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 4712/5962 [00:39<00:10, 119.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████     | 5202/5962 [00:39<00:08, 90.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 4651/5962 [00:39<00:16, 77.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████        | 4722/5962 [00:39<00:10, 118.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4534/5962 [00:39<00:12, 114.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 4729/5962 [00:39<00:09, 130.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▍      | 4933/5962 [00:39<00:09, 110.82it/s]\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5218/5962 [00:39<00:06, 108.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▌        | 4668/5962 [00:39<00:12, 99.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▏       | 4740/5962 [00:39<00:09, 135.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 4566/5962 [00:39<00:08, 169.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 4745/5962 [00:39<00:08, 136.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▌      | 4945/5962 [00:39<00:09, 108.15it/s]\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5229/5962 [00:39<00:07, 103.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4757/5962 [00:39<00:08, 142.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▌        | 4679/5962 [00:39<00:13, 94.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 5461/5962 [00:39<00:03, 131.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4762/5962 [00:39<00:08, 141.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4783/5962 [00:39<00:06, 175.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4689/5962 [00:39<00:14, 90.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 5240/5962 [00:39<00:08, 90.24it/s]\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▏        | 4584/5962 [00:39<00:11, 123.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4777/5962 [00:39<00:08, 133.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5475/5962 [00:39<00:04, 107.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▌       | 4801/5962 [00:40<00:07, 155.96it/s]\u001b[A\u001b[A\n",
      " 83%|████████████████████████████████▌      | 4969/5962 [00:40<00:10, 95.98it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4699/5962 [00:39<00:15, 82.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4793/5962 [00:39<00:08, 140.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 5250/5962 [00:40<00:08, 80.66it/s]\u001b[A\u001b[A\u001b[A\n",
      " 84%|███████████████████████████████▊      | 4982/5962 [00:40<00:09, 101.16it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4708/5962 [00:40<00:15, 81.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5259/5962 [00:40<00:09, 75.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████         | 4599/5962 [00:40<00:15, 89.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4808/5962 [00:40<00:10, 114.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4818/5962 [00:40<00:09, 115.36it/s]\u001b[A\u001b[A\n",
      " 84%|████████████████████████████████▋      | 4993/5962 [00:40<00:10, 90.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4717/5962 [00:40<00:16, 75.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5268/5962 [00:40<00:09, 76.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▉        | 4725/5962 [00:40<00:16, 76.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▉   | 5497/5962 [00:40<00:06, 70.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 5278/5962 [00:40<00:08, 80.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4832/5962 [00:40<00:10, 103.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 4821/5962 [00:40<00:12, 92.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|██████████████████████████████▏        | 4611/5962 [00:40<00:17, 75.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▉        | 4734/5962 [00:40<00:15, 77.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 5287/5962 [00:40<00:08, 80.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████   | 5506/5962 [00:40<00:06, 71.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4844/5962 [00:40<00:10, 105.93it/s]\u001b[A\u001b[A\n",
      " 84%|████████████████████████████████▊      | 5012/5962 [00:40<00:12, 78.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▏        | 4621/5962 [00:40<00:18, 73.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████        | 4743/5962 [00:40<00:15, 78.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4859/5962 [00:40<00:09, 115.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 5296/5962 [00:40<00:08, 81.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 4842/5962 [00:40<00:12, 89.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▎        | 4634/5962 [00:40<00:15, 83.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████        | 4753/5962 [00:40<00:14, 83.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████       | 4875/5962 [00:40<00:08, 126.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5543/5962 [00:40<00:03, 115.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 5305/5962 [00:40<00:08, 80.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 4852/5962 [00:40<00:12, 91.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 84%|████████████████████████████████▉      | 5033/5962 [00:40<00:10, 84.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▏       | 4762/5962 [00:40<00:14, 83.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5557/5962 [00:40<00:03, 119.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|██████████████████████████████▍        | 4644/5962 [00:40<00:17, 75.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▊       | 4862/5962 [00:40<00:11, 92.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▏     | 5050/5962 [00:40<00:08, 105.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▏       | 4773/5962 [00:40<00:13, 90.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 5314/5962 [00:40<00:09, 68.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 4653/5962 [00:41<00:17, 73.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▊       | 4872/5962 [00:40<00:12, 87.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▎       | 4783/5962 [00:40<00:12, 91.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 5322/5962 [00:41<00:09, 67.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▎      | 4921/5962 [00:41<00:07, 137.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5587/5962 [00:40<00:02, 128.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▍        | 4662/5962 [00:41<00:17, 72.54it/s]\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4939/5962 [00:41<00:06, 148.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 4882/5962 [00:41<00:13, 77.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▎       | 4793/5962 [00:41<00:14, 79.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5601/5962 [00:41<00:03, 118.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 5330/5962 [00:41<00:10, 58.13it/s]\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▌        | 4672/5962 [00:41<00:16, 76.87it/s]\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4956/5962 [00:41<00:06, 153.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5614/5962 [00:41<00:02, 117.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 4802/5962 [00:41<00:15, 74.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|█████████████████████████████████▎     | 5083/5962 [00:41<00:10, 84.87it/s]\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4977/5962 [00:41<00:05, 169.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 4891/5962 [00:41<00:15, 69.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▌        | 4681/5962 [00:41<00:17, 74.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 4811/5962 [00:41<00:15, 76.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5627/5962 [00:41<00:03, 109.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4995/5962 [00:41<00:05, 169.75it/s]\u001b[A\u001b[A\n",
      " 85%|█████████████████████████████████▎     | 5093/5962 [00:41<00:10, 86.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 4899/5962 [00:41<00:15, 70.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4689/5962 [00:41<00:17, 72.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 4824/5962 [00:41<00:12, 89.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5644/5962 [00:41<00:02, 122.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5013/5962 [00:41<00:05, 162.67it/s]\u001b[A\u001b[A\n",
      " 86%|█████████████████████████████████▍     | 5103/5962 [00:41<00:10, 85.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 4907/5962 [00:41<00:15, 69.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4697/5962 [00:41<00:18, 70.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 4836/5962 [00:41<00:11, 96.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 5657/5962 [00:41<00:02, 108.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4705/5962 [00:41<00:17, 69.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4850/5962 [00:41<00:10, 108.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████████████████████████████      | 5030/5962 [00:41<00:07, 128.20it/s]\u001b[A\u001b[A\n",
      " 86%|█████████████████████████████████▌     | 5123/5962 [00:41<00:09, 86.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▏      | 4922/5962 [00:41<00:15, 65.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4718/5962 [00:41<00:15, 81.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4866/5962 [00:41<00:09, 120.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 5669/5962 [00:41<00:03, 94.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▎      | 4933/5962 [00:41<00:13, 76.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 86%|█████████████████████████████████▌     | 5133/5962 [00:41<00:09, 88.23it/s]\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5372/5962 [00:41<00:09, 62.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4882/5962 [00:41<00:08, 131.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▉        | 4730/5962 [00:42<00:13, 88.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5680/5962 [00:41<00:03, 90.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 86%|█████████████████████████████████▋     | 5144/5962 [00:42<00:08, 93.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4952/5962 [00:41<00:09, 105.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5380/5962 [00:42<00:08, 66.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 4746/5962 [00:42<00:11, 106.39it/s]\n",
      " 87%|████████████████████████████████▉     | 5160/5962 [00:42<00:07, 112.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4970/5962 [00:42<00:07, 125.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████      | 5058/5962 [00:42<00:09, 98.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5690/5962 [00:41<00:03, 87.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4757/5962 [00:42<00:11, 107.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▎      | 4918/5962 [00:42<00:07, 136.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|████████████████████████████████▉     | 5173/5962 [00:42<00:06, 116.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4984/5962 [00:42<00:07, 125.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▎   | 5395/5962 [00:42<00:08, 64.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5699/5962 [00:42<00:03, 80.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5069/5962 [00:42<00:09, 93.03it/s]\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████     | 5189/5962 [00:42<00:06, 127.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4933/5962 [00:42<00:08, 125.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4781/5962 [00:42<00:11, 102.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5079/5962 [00:42<00:10, 83.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5708/5962 [00:42<00:03, 71.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████▏    | 5202/5962 [00:42<00:06, 120.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5010/5962 [00:42<00:08, 116.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4947/5962 [00:42<00:09, 112.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4792/5962 [00:42<00:11, 103.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5090/5962 [00:42<00:09, 88.67it/s]\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▎    | 5218/5962 [00:42<00:05, 129.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5716/5962 [00:42<00:03, 68.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 5025/5962 [00:42<00:07, 125.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4807/5962 [00:42<00:10, 112.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4959/5962 [00:42<00:09, 104.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▎     | 5100/5962 [00:42<00:09, 88.93it/s]\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▍    | 5240/5962 [00:42<00:04, 151.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5726/5962 [00:42<00:03, 74.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5428/5962 [00:42<00:07, 75.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4819/5962 [00:42<00:10, 112.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4975/5962 [00:42<00:08, 117.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5120/5962 [00:42<00:07, 115.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5735/5962 [00:42<00:02, 78.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5051/5962 [00:42<00:07, 118.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4831/5962 [00:42<00:10, 110.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5436/5962 [00:42<00:07, 68.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5138/5962 [00:42<00:06, 132.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5748/5962 [00:42<00:02, 90.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 5073/5962 [00:42<00:06, 143.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▌    | 5256/5962 [00:42<00:06, 104.53it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5003/5962 [00:42<00:07, 125.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5445/5962 [00:42<00:07, 73.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5156/5962 [00:43<00:05, 144.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4851/5962 [00:43<00:09, 115.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 5022/5962 [00:42<00:06, 139.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▋   | 5453/5962 [00:43<00:07, 66.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████▉       | 4863/5962 [00:43<00:09, 114.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5777/5962 [00:42<00:01, 103.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5172/5962 [00:43<00:06, 121.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████      | 5039/5962 [00:43<00:06, 146.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4878/5962 [00:43<00:08, 122.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5788/5962 [00:43<00:01, 102.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|██████████████████████████████████▍    | 5269/5962 [00:43<00:09, 76.53it/s]\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████     | 5188/5962 [00:43<00:05, 130.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 5101/5962 [00:43<00:07, 107.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5055/5962 [00:43<00:06, 144.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 4891/5962 [00:43<00:08, 119.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5799/5962 [00:43<00:01, 101.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5203/5962 [00:43<00:05, 129.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 5113/5962 [00:43<00:08, 103.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 5070/5962 [00:43<00:06, 129.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▎      | 4909/5962 [00:43<00:07, 132.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5217/5962 [00:43<00:05, 126.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5127/5962 [00:43<00:07, 110.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|██████████████████████████████████████ | 5810/5962 [00:43<00:01, 89.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 5280/5962 [00:43<00:10, 63.26it/s]\u001b[A\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▉   | 5497/5962 [00:43<00:04, 96.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 5084/5962 [00:43<00:07, 124.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5231/5962 [00:43<00:06, 120.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4923/5962 [00:43<00:09, 111.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▏  | 5514/5962 [00:43<00:03, 117.12it/s]\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 5289/5962 [00:43<00:10, 64.71it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 5097/5962 [00:43<00:06, 124.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5159/5962 [00:43<00:06, 131.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5250/5962 [00:43<00:05, 135.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4935/5962 [00:43<00:09, 110.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5533/5962 [00:43<00:03, 135.03it/s]\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▋    | 5302/5962 [00:43<00:08, 76.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 5111/5962 [00:43<00:06, 126.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4951/5962 [00:43<00:08, 122.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5846/5962 [00:43<00:01, 100.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▊    | 5317/5962 [00:43<00:07, 90.80it/s]\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5547/5962 [00:43<00:03, 128.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5127/5962 [00:43<00:06, 135.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4971/5962 [00:44<00:06, 142.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5283/5962 [00:43<00:04, 144.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5859/5962 [00:43<00:00, 108.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|█████████████████████████████████▉    | 5333/5962 [00:43<00:05, 106.26it/s]\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5561/5962 [00:43<00:03, 130.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5142/5962 [00:43<00:06, 135.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4986/5962 [00:44<00:06, 142.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5575/5962 [00:44<00:02, 131.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5298/5962 [00:44<00:05, 132.18it/s]\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▉    | 5346/5962 [00:44<00:06, 99.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▍| 5871/5962 [00:43<00:01, 91.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5198/5962 [00:44<00:07, 103.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5002/5962 [00:44<00:06, 144.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5591/5962 [00:44<00:02, 138.49it/s]\u001b[A\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▏   | 5359/5962 [00:44<00:05, 103.61it/s]\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5017/5962 [00:44<00:06, 142.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5605/5962 [00:44<00:02, 138.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5168/5962 [00:44<00:07, 107.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▍| 5881/5962 [00:44<00:00, 81.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▏   | 5371/5962 [00:44<00:05, 103.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 5033/5962 [00:44<00:06, 145.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 5325/5962 [00:44<00:05, 111.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5624/5962 [00:44<00:02, 153.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 5180/5962 [00:44<00:08, 96.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▎   | 5387/5962 [00:44<00:04, 116.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5053/5962 [00:44<00:05, 160.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5644/5962 [00:44<00:01, 165.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▏    | 5219/5962 [00:44<00:09, 81.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████    | 5337/5962 [00:44<00:05, 108.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████     | 5195/5962 [00:44<00:07, 108.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▎     | 5072/5962 [00:44<00:05, 168.38it/s]\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 5664/5962 [00:44<00:01, 174.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▏    | 5228/5962 [00:44<00:08, 83.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████    | 5349/5962 [00:44<00:05, 108.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 5898/5962 [00:44<00:00, 65.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5210/5962 [00:44<00:06, 116.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▍     | 5091/5962 [00:44<00:04, 174.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 5237/5962 [00:44<00:08, 84.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 5912/5962 [00:44<00:00, 81.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████████    | 5360/5962 [00:44<00:06, 95.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5682/5962 [00:44<00:01, 141.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 5109/5962 [00:44<00:05, 162.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5223/5962 [00:44<00:07, 103.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▊| 5928/5962 [00:44<00:00, 99.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|██████████████████████████████████▌   | 5428/5962 [00:44<00:05, 105.04it/s]\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5370/5962 [00:44<00:06, 90.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 5698/5962 [00:44<00:02, 131.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5255/5962 [00:44<00:08, 80.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5126/5962 [00:45<00:05, 149.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▏    | 5234/5962 [00:44<00:08, 88.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▉| 5957/5962 [00:44<00:00, 116.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5380/5962 [00:45<00:06, 83.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5265/5962 [00:44<00:08, 82.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:44<00:00, 132.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5440/5962 [00:45<00:06, 82.23it/s]\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████████▎   | 5390/5962 [00:45<00:06, 87.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5285/5962 [00:45<00:06, 111.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5167/5962 [00:45<00:04, 174.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▋   | 5450/5962 [00:45<00:06, 81.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 5244/5962 [00:45<00:10, 70.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 5401/5962 [00:45<00:06, 92.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5297/5962 [00:45<00:06, 107.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████     | 5185/5962 [00:45<00:05, 135.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5309/5962 [00:45<00:05, 110.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 5411/5962 [00:45<00:06, 87.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 5252/5962 [00:45<00:10, 65.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5773/5962 [00:45<00:01, 152.44it/s]\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▊   | 5470/5962 [00:45<00:06, 81.80it/s]\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5429/5962 [00:45<00:04, 111.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 5332/5962 [00:45<00:04, 141.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5201/5962 [00:45<00:05, 132.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5789/5962 [00:45<00:01, 132.93it/s]\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▊   | 5482/5962 [00:45<00:05, 89.80it/s]\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 5441/5962 [00:45<00:04, 113.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████    | 5347/5962 [00:45<00:04, 143.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5268/5962 [00:45<00:09, 69.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 5504/5962 [00:45<00:03, 122.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 5466/5962 [00:45<00:03, 151.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5232/5962 [00:45<00:05, 141.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 5284/5962 [00:45<00:07, 90.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▏  | 5519/5962 [00:45<00:03, 128.94it/s]\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5825/5962 [00:45<00:00, 151.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5383/5962 [00:45<00:03, 159.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5491/5962 [00:45<00:02, 174.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5248/5962 [00:45<00:04, 143.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▎  | 5535/5962 [00:45<00:03, 135.79it/s]\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5841/5962 [00:45<00:00, 146.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5402/5962 [00:45<00:03, 168.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|███████████████████████████████████   | 5509/5962 [00:45<00:02, 175.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5263/5962 [00:45<00:04, 140.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▍  | 5561/5962 [00:45<00:02, 166.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5432/5962 [00:45<00:02, 206.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5861/5962 [00:45<00:00, 158.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5534/5962 [00:46<00:02, 194.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5279/5962 [00:46<00:04, 145.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5294/5962 [00:46<00:04, 141.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▊   | 5453/5962 [00:46<00:02, 182.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████    | 5345/5962 [00:46<00:04, 125.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▌  | 5579/5962 [00:46<00:02, 135.44it/s]\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5554/5962 [00:46<00:02, 149.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 5896/5962 [00:46<00:00, 159.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5309/5962 [00:46<00:04, 132.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5472/5962 [00:46<00:02, 167.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 5913/5962 [00:46<00:00, 155.02it/s]\u001b[A\u001b[A\u001b[A\n",
      " 89%|█████████████████████████████████▉    | 5323/5962 [00:46<00:05, 126.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5374/5962 [00:46<00:05, 112.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5490/5962 [00:46<00:03, 152.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▌  | 5571/5962 [00:46<00:03, 117.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▊| 5929/5962 [00:46<00:00, 145.71it/s]\u001b[A\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████    | 5339/5962 [00:46<00:04, 131.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5386/5962 [00:46<00:05, 113.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 5356/5962 [00:46<00:04, 141.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5585/5962 [00:46<00:03, 107.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 5506/5962 [00:46<00:03, 124.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5398/5962 [00:46<00:05, 102.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|████████████████████████████████████▊  | 5620/5962 [00:46<00:03, 97.39it/s]\u001b[A\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5383/5962 [00:46<00:03, 175.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:46<00:00, 127.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5526/5962 [00:46<00:03, 140.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5409/5962 [00:46<00:05, 101.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|██████████████████████████████████▍   | 5403/5962 [00:46<00:03, 182.04it/s]\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5614/5962 [00:46<00:02, 120.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5543/5962 [00:46<00:02, 146.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 5420/5962 [00:46<00:05, 96.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▉  | 5644/5962 [00:46<00:03, 94.07it/s]\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5422/5962 [00:47<00:03, 153.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5559/5962 [00:46<00:03, 128.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5430/5962 [00:46<00:06, 86.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 5439/5962 [00:47<00:03, 145.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▉  | 5654/5962 [00:47<00:03, 78.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 5640/5962 [00:47<00:03, 93.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5590/5962 [00:47<00:03, 120.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|█████████████████████████████████████  | 5663/5962 [00:47<00:04, 74.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▊   | 5455/5962 [00:47<00:04, 118.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5603/5962 [00:47<00:03, 114.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▋   | 5465/5962 [00:47<00:05, 98.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 92%|██████████████████████████████████▊   | 5469/5962 [00:47<00:04, 119.79it/s]\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5486/5962 [00:47<00:03, 130.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▊   | 5476/5962 [00:47<00:05, 93.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 5615/5962 [00:47<00:03, 98.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████████  | 5673/5962 [00:47<00:03, 86.38it/s]\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████   | 5500/5962 [00:47<00:03, 129.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5489/5962 [00:47<00:04, 100.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▉  | 5629/5962 [00:47<00:03, 106.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|█████████████████████████████████████▏ | 5688/5962 [00:47<00:03, 69.48it/s]\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5684/5962 [00:47<00:03, 91.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▏  | 5512/5962 [00:47<00:03, 133.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5695/5962 [00:47<00:02, 95.53it/s]\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▏  | 5514/5962 [00:47<00:03, 124.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 5641/5962 [00:47<00:03, 94.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|█████████████████████████████████████▎ | 5707/5962 [00:47<00:03, 79.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5526/5962 [00:47<00:03, 128.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5527/5962 [00:47<00:03, 111.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 5652/5962 [00:47<00:03, 91.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5545/5962 [00:47<00:02, 142.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5542/5962 [00:48<00:03, 119.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 5662/5962 [00:47<00:03, 93.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5566/5962 [00:47<00:02, 160.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▍  | 5557/5962 [00:48<00:03, 126.68it/s]\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5731/5962 [00:48<00:02, 97.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 5674/5962 [00:48<00:02, 98.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5587/5962 [00:48<00:02, 171.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|████████████████████████████████████▋ | 5757/5962 [00:48<00:01, 130.64it/s]\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5743/5962 [00:48<00:02, 102.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▎ | 5689/5962 [00:48<00:02, 109.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5607/5962 [00:48<00:02, 177.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▋  | 5590/5962 [00:48<00:02, 142.75it/s]\u001b[A\n",
      "\n",
      " 97%|████████████████████████████████████▋ | 5758/5962 [00:48<00:01, 114.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5626/5962 [00:48<00:01, 174.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|████████████████████████████████████▉ | 5790/5962 [00:48<00:01, 142.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5701/5962 [00:48<00:02, 89.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5605/5962 [00:48<00:03, 114.18it/s]\u001b[A\u001b[A\n",
      " 97%|████████████████████████████████████▉ | 5805/5962 [00:48<00:01, 132.40it/s]\u001b[A\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5784/5962 [00:48<00:01, 107.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5622/5962 [00:48<00:02, 126.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5711/5962 [00:48<00:03, 80.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████ | 5819/5962 [00:48<00:01, 124.71it/s]\u001b[A\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5636/5962 [00:48<00:02, 121.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 5659/5962 [00:48<00:02, 123.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5720/5962 [00:48<00:03, 71.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████  | 5649/5962 [00:48<00:02, 109.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5673/5962 [00:48<00:02, 105.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 5807/5962 [00:48<00:01, 78.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5728/5962 [00:48<00:03, 60.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████  | 5661/5962 [00:49<00:02, 102.19it/s]\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████████ | 5816/5962 [00:49<00:01, 75.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5735/5962 [00:49<00:04, 56.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5685/5962 [00:49<00:03, 88.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|█████████████████████████████████████  | 5672/5962 [00:49<00:03, 90.53it/s]\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████████ | 5825/5962 [00:49<00:01, 74.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5742/5962 [00:49<00:03, 57.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5698/5962 [00:49<00:02, 94.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|██████████████████████████████████████▎| 5863/5962 [00:49<00:01, 86.77it/s]\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5682/5962 [00:49<00:03, 81.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5749/5962 [00:49<00:03, 58.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5709/5962 [00:49<00:02, 95.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 99%|██████████████████████████████████████▍| 5873/5962 [00:49<00:01, 80.30it/s]\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████████▏| 5847/5962 [00:49<00:01, 85.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5691/5962 [00:49<00:03, 78.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 5756/5962 [00:49<00:03, 53.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 99%|██████████████████████████████████████▍| 5884/5962 [00:49<00:00, 85.45it/s]\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5700/5962 [00:49<00:03, 79.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5741/5962 [00:49<00:02, 104.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 99%|██████████████████████████████████████▌| 5895/5962 [00:49<00:00, 89.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5713/5962 [00:49<00:02, 90.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|██████████████████████████████████████▍| 5867/5962 [00:49<00:01, 76.37it/s]\u001b[A\u001b[A\n",
      " 99%|██████████████████████████████████████▋| 5906/5962 [00:49<00:00, 94.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 5778/5962 [00:49<00:02, 66.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▋ | 5753/5962 [00:49<00:02, 89.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5723/5962 [00:49<00:02, 82.15it/s]\u001b[A\u001b[A\n",
      " 99%|██████████████████████████████████████▋| 5918/5962 [00:49<00:00, 98.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 5794/5962 [00:49<00:01, 85.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 5765/5962 [00:49<00:02, 93.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5737/5962 [00:50<00:02, 94.26it/s]\u001b[A\u001b[A\n",
      " 99%|█████████████████████████████████████▊| 5932/5962 [00:49<00:00, 106.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 5803/5962 [00:49<00:01, 82.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5747/5962 [00:50<00:02, 91.09it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████▉| 5943/5962 [00:50<00:00, 96.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████ | 5814/5962 [00:50<00:01, 87.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 5776/5962 [00:50<00:02, 79.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|████████████████████████████████████▋ | 5760/5962 [00:50<00:02, 100.93it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████▉| 5953/5962 [00:50<00:00, 91.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 5785/5962 [00:50<00:02, 77.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████ | 5823/5962 [00:50<00:01, 81.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:50<00:00, 118.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 5795/5962 [00:50<00:02, 82.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 5784/5962 [00:50<00:01, 95.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▏| 5832/5962 [00:50<00:01, 70.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████ | 5811/5962 [00:50<00:01, 100.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 5795/5962 [00:50<00:01, 96.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▏| 5841/5962 [00:50<00:01, 74.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████ | 5822/5962 [00:50<00:01, 101.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 5806/5962 [00:50<00:01, 96.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▎| 5849/5962 [00:50<00:01, 73.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:50<00:00, 117.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|██████████████████████████████████████ | 5816/5962 [00:50<00:01, 83.03it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▏| 5844/5962 [00:50<00:01, 69.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████ | 5825/5962 [00:51<00:02, 67.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▎| 5856/5962 [00:50<00:01, 77.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▏| 5838/5962 [00:51<00:01, 79.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 5874/5962 [00:51<00:00, 100.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▍| 5872/5962 [00:51<00:01, 55.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▍| 5879/5962 [00:51<00:01, 51.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 5886/5962 [00:51<00:01, 74.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▍| 5885/5962 [00:51<00:01, 48.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▎| 5861/5962 [00:51<00:01, 67.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▍| 5872/5962 [00:51<00:01, 76.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 5908/5962 [00:51<00:00, 84.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▍| 5884/5962 [00:51<00:00, 85.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 5918/5962 [00:51<00:00, 81.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 5897/5962 [00:51<00:00, 94.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▊| 5928/5962 [00:51<00:00, 83.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 5909/5962 [00:52<00:00, 99.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████▊| 5938/5962 [00:51<00:00, 86.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████▉| 5944/5962 [00:51<00:00, 96.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 5920/5962 [00:52<00:00, 84.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:52<00:00, 114.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:52<00:00, 114.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:52<00:00, 112.97it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_train.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa.tsv\n",
      "Processing Started...\n",
      "Data Size:  9202\n",
      "number of threads:  7\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  1%|▎                                         | 9/1314 [00:00<00:16, 77.32it/s]\n",
      "  1%|▎                                       | 12/1314 [00:00<00:12, 106.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  1%|▏                                         | 7/1314 [00:00<00:21, 62.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▎                                        | 11/1314 [00:00<00:15, 81.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  2%|▋                                        | 23/1314 [00:00<00:13, 95.66it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 11/1314 [00:00<00:15, 86.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▍                                        | 16/1314 [00:00<00:18, 71.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▋                                        | 21/1314 [00:00<00:14, 90.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                        | 28/1314 [00:00<00:16, 77.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                         | 6/1314 [00:00<00:24, 54.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  3%|█▏                                      | 37/1314 [00:00<00:11, 109.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▌                                        | 20/1314 [00:00<00:15, 82.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▉                                        | 31/1314 [00:00<00:13, 92.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                        | 17/1314 [00:00<00:16, 79.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                        | 36/1314 [00:00<00:19, 65.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                        | 29/1314 [00:00<00:16, 76.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▎                                       | 41/1314 [00:00<00:14, 88.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▌                                        | 20/1314 [00:00<00:20, 63.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▉                                        | 31/1314 [00:00<00:21, 58.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                        | 26/1314 [00:00<00:19, 67.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                       | 43/1314 [00:00<00:20, 60.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▌                                       | 49/1314 [00:00<00:18, 69.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▌                                       | 50/1314 [00:00<00:16, 76.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▏                                       | 40/1314 [00:00<00:19, 65.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                        | 27/1314 [00:00<00:22, 56.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                        | 35/1314 [00:00<00:17, 72.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                       | 50/1314 [00:00<00:21, 59.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▊                                       | 59/1314 [00:00<00:15, 80.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▌                                       | 49/1314 [00:00<00:17, 70.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                        | 33/1314 [00:00<00:22, 56.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                       | 44/1314 [00:00<00:16, 76.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▊                                       | 58/1314 [00:00<00:21, 59.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                       | 57/1314 [00:00<00:20, 60.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                       | 42/1314 [00:00<00:19, 66.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▊                                       | 57/1314 [00:00<00:17, 69.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                       | 68/1314 [00:00<00:16, 75.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                       | 66/1314 [00:00<00:18, 66.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|██                                       | 65/1314 [00:00<00:21, 56.85it/s]\u001b[A\n",
      "\n",
      "  5%|██                                       | 66/1314 [00:00<00:16, 73.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                       | 50/1314 [00:00<00:18, 67.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                       | 67/1314 [00:00<00:13, 90.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▎                                      | 76/1314 [00:00<00:16, 73.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                      | 76/1314 [00:00<00:14, 84.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▎                                      | 73/1314 [00:01<00:20, 60.39it/s]\u001b[A\n",
      "\n",
      "  6%|██▍                                      | 78/1314 [00:01<00:14, 86.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                     | 82/1314 [00:00<00:11, 104.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▋                                      | 85/1314 [00:01<00:15, 77.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                       | 58/1314 [00:00<00:18, 66.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▍                                      | 80/1314 [00:01<00:20, 61.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▋                                      | 85/1314 [00:01<00:15, 79.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                     | 97/1314 [00:01<00:10, 117.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                      | 80/1314 [00:01<00:20, 60.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▋                                      | 87/1314 [00:01<00:15, 81.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                      | 72/1314 [00:01<00:14, 85.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▋                                      | 87/1314 [00:01<00:19, 61.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▌                                     | 86/1314 [00:01<00:12, 100.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                      | 93/1314 [00:01<00:18, 66.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 109/1314 [00:01<00:11, 103.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▉                                      | 94/1314 [00:01<00:19, 62.81it/s]\u001b[A\u001b[A\n",
      "  7%|██▉                                      | 96/1314 [00:01<00:19, 61.51it/s]\u001b[A\n",
      "\n",
      "  8%|███▏                                    | 106/1314 [00:01<00:14, 81.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                     | 100/1314 [00:01<00:18, 66.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|███                                      | 97/1314 [00:01<00:13, 91.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▎                                    | 108/1314 [00:01<00:14, 82.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "  8%|███▏                                    | 105/1314 [00:01<00:18, 66.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                    | 108/1314 [00:01<00:17, 69.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▌                                    | 119/1314 [00:01<00:13, 91.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                    | 108/1314 [00:01<00:12, 95.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▋                                   | 126/1314 [00:01<00:10, 108.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▍                                    | 113/1314 [00:01<00:17, 68.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                    | 119/1314 [00:01<00:15, 78.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▏                                   | 137/1314 [00:01<00:12, 97.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                    | 120/1314 [00:01<00:12, 98.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▎                                   | 142/1314 [00:01<00:13, 90.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████                                   | 138/1314 [00:01<00:11, 102.68it/s]\u001b[A\u001b[A\n",
      "  9%|███▊                                    | 124/1314 [00:01<00:15, 76.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 150/1314 [00:01<00:11, 104.14it/s]\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                    | 128/1314 [00:01<00:15, 77.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 139/1314 [00:01<00:09, 119.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████▎                                   | 142/1314 [00:01<00:12, 96.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 156/1314 [00:01<00:09, 120.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▏                                   | 137/1314 [00:01<00:14, 79.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 12%|████▋                                  | 156/1314 [00:01<00:10, 106.81it/s]\u001b[A\u001b[A\n",
      " 10%|████                                    | 132/1314 [00:01<00:17, 68.80it/s]\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▉                                   | 162/1314 [00:01<00:12, 89.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 152/1314 [00:01<00:10, 113.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 169/1314 [00:02<00:09, 116.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▌                                   | 148/1314 [00:01<00:13, 83.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|████▉                                  | 167/1314 [00:02<00:11, 102.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▎                                  | 173/1314 [00:01<00:12, 93.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████▏                                  | 172/1314 [00:02<00:14, 80.77it/s]\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▎                                   | 140/1314 [00:02<00:19, 61.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▉                                   | 164/1314 [00:01<00:11, 99.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                   | 159/1314 [00:02<00:13, 86.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▌                                  | 181/1314 [00:02<00:11, 95.62it/s]\u001b[A\u001b[A\n",
      " 11%|████▍                                   | 147/1314 [00:02<00:18, 62.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                  | 183/1314 [00:02<00:12, 88.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▎                                  | 175/1314 [00:02<00:11, 94.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                  | 169/1314 [00:02<00:13, 87.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                  | 193/1314 [00:02<00:12, 86.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▋                                  | 185/1314 [00:02<00:12, 93.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▊                                  | 192/1314 [00:02<00:13, 80.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                  | 178/1314 [00:02<00:14, 79.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                 | 204/1314 [00:02<00:12, 90.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▉                                   | 163/1314 [00:02<00:17, 64.25it/s]\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▏                                 | 204/1314 [00:02<00:12, 89.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                  | 195/1314 [00:02<00:13, 84.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▋                                  | 188/1314 [00:02<00:18, 61.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▋                                  | 187/1314 [00:02<00:15, 72.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████▎                                  | 173/1314 [00:02<00:15, 71.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                 | 214/1314 [00:02<00:13, 83.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▏                                 | 205/1314 [00:02<00:18, 61.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                 | 214/1314 [00:02<00:15, 72.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                  | 195/1314 [00:02<00:16, 69.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▌                                  | 181/1314 [00:02<00:16, 69.09it/s]\u001b[A\n",
      "\n",
      " 15%|█████▉                                  | 196/1314 [00:02<00:20, 53.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                 | 213/1314 [00:02<00:13, 81.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                 | 224/1314 [00:02<00:13, 79.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▍                                 | 212/1314 [00:02<00:19, 55.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▏                                 | 204/1314 [00:02<00:19, 57.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████▏                                 | 203/1314 [00:02<00:17, 64.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                 | 222/1314 [00:02<00:13, 78.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 218/1314 [00:02<00:19, 55.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▌                                 | 214/1314 [00:02<00:17, 64.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                 | 213/1314 [00:02<00:16, 68.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▊                                  | 189/1314 [00:02<00:23, 48.28it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▏                                | 235/1314 [00:03<00:15, 67.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▊                                 | 224/1314 [00:02<00:20, 52.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                                | 247/1314 [00:03<00:13, 77.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                                | 246/1314 [00:02<00:14, 74.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▊                                 | 222/1314 [00:03<00:18, 59.87it/s]\u001b[A\u001b[A\n",
      " 15%|█████▉                                  | 195/1314 [00:03<00:24, 46.48it/s]\u001b[A\n",
      "\n",
      "\n",
      " 18%|███████                                 | 230/1314 [00:03<00:21, 50.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▉                                | 259/1314 [00:03<00:12, 86.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                                | 258/1314 [00:03<00:12, 84.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▉                                 | 229/1314 [00:03<00:18, 58.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 220/1314 [00:03<00:22, 48.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|██████▏                                 | 202/1314 [00:03<00:21, 50.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                                | 246/1314 [00:03<00:15, 67.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|████████▏                               | 269/1314 [00:03<00:12, 85.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▏                               | 268/1314 [00:03<00:12, 84.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████▎                                 | 209/1314 [00:03<00:20, 54.54it/s]\u001b[A\n",
      "\n",
      " 18%|███████▎                                | 239/1314 [00:03<00:17, 62.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▉                                 | 226/1314 [00:03<00:23, 46.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▌                               | 281/1314 [00:03<00:11, 93.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▍                               | 279/1314 [00:03<00:11, 90.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|███████▎                                | 241/1314 [00:03<00:22, 46.69it/s]\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▌                                 | 217/1314 [00:03<00:18, 60.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                                 | 232/1314 [00:03<00:22, 48.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▌                                | 250/1314 [00:03<00:15, 70.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▊                              | 295/1314 [00:03<00:09, 105.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▊                              | 295/1314 [00:03<00:09, 107.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▌                                | 248/1314 [00:03<00:20, 52.46it/s]\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▊                                 | 224/1314 [00:03<00:18, 58.36it/s]\u001b[A\n",
      "\n",
      " 20%|███████▉                                | 261/1314 [00:03<00:13, 79.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▏                                | 238/1314 [00:03<00:21, 50.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                              | 285/1314 [00:03<00:09, 103.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████                              | 307/1314 [00:03<00:09, 108.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▎                             | 312/1314 [00:03<00:08, 117.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████▏                               | 271/1314 [00:03<00:12, 83.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                                | 250/1314 [00:03<00:15, 66.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                             | 310/1314 [00:03<00:07, 141.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|███████                                 | 231/1314 [00:03<00:20, 53.62it/s]\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▊                             | 330/1314 [00:03<00:07, 133.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▋                               | 285/1314 [00:03<00:10, 97.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                                | 258/1314 [00:03<00:15, 67.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▋                              | 319/1314 [00:03<00:10, 93.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▊                             | 331/1314 [00:03<00:06, 156.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|███████▏                                | 237/1314 [00:03<00:20, 52.37it/s]\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▏                            | 344/1314 [00:03<00:07, 127.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▊                              | 297/1314 [00:03<00:09, 102.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▏                               | 269/1314 [00:03<00:13, 78.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████                              | 329/1314 [00:03<00:10, 94.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▎                            | 347/1314 [00:03<00:06, 145.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▉                               | 292/1314 [00:03<00:11, 90.64it/s]\u001b[A\u001b[A\u001b[A\n",
      " 18%|███████▍                                | 243/1314 [00:03<00:20, 51.97it/s]\u001b[A\n",
      "\n",
      " 27%|██████████▋                            | 358/1314 [00:04<00:08, 118.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▍                               | 279/1314 [00:03<00:12, 82.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▍                             | 341/1314 [00:03<00:09, 99.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 365/1314 [00:03<00:06, 153.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▋                                | 251/1314 [00:04<00:18, 58.67it/s]\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████▏                              | 303/1314 [00:04<00:11, 91.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▋                             | 328/1314 [00:04<00:07, 127.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 372/1314 [00:04<00:07, 122.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 355/1314 [00:03<00:08, 107.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 383/1314 [00:03<00:05, 159.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▉                                | 259/1314 [00:04<00:17, 62.04it/s]\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▌                              | 313/1314 [00:04<00:11, 88.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|██████████                             | 341/1314 [00:04<00:07, 123.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▍                           | 385/1314 [00:04<00:07, 121.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 372/1314 [00:04<00:07, 124.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 400/1314 [00:04<00:06, 151.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|████████                                | 266/1314 [00:04<00:16, 63.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▋                            | 360/1314 [00:04<00:06, 142.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▊                              | 323/1314 [00:04<00:11, 87.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 398/1314 [00:04<00:07, 117.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▍                          | 417/1314 [00:04<00:05, 153.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▎                               | 273/1314 [00:04<00:16, 62.07it/s]\u001b[A\n",
      "\n",
      " 29%|███████████▏                           | 377/1314 [00:04<00:06, 149.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▉                             | 333/1314 [00:04<00:07, 122.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 412/1314 [00:04<00:07, 121.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                           | 402/1314 [00:04<00:07, 129.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 433/1314 [00:04<00:06, 143.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▌                               | 280/1314 [00:04<00:16, 61.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▎                            | 346/1314 [00:04<00:08, 110.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▍                          | 419/1314 [00:04<00:06, 130.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|████████████▌                          | 425/1314 [00:04<00:08, 105.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▌                             | 345/1314 [00:04<00:12, 76.79it/s]\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▊                               | 288/1314 [00:04<00:15, 64.54it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 448/1314 [00:04<00:06, 129.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▋                            | 358/1314 [00:04<00:09, 103.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▉                          | 436/1314 [00:04<00:08, 101.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▉                               | 295/1314 [00:04<00:15, 64.00it/s]\u001b[A\n",
      "\n",
      " 31%|████████████                           | 407/1314 [00:04<00:08, 111.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 462/1314 [00:04<00:06, 123.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▊                             | 354/1314 [00:04<00:14, 68.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 375/1314 [00:04<00:08, 117.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 449/1314 [00:04<00:08, 106.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|████████████▌                          | 422/1314 [00:04<00:07, 120.48it/s]\u001b[A\u001b[A\n",
      " 23%|█████████▎                              | 304/1314 [00:04<00:15, 66.18it/s]\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████                             | 362/1314 [00:04<00:13, 70.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 461/1314 [00:04<00:07, 107.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|█████████████                          | 440/1314 [00:04<00:06, 134.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 461/1314 [00:04<00:07, 117.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████▍                              | 312/1314 [00:04<00:14, 68.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                            | 388/1314 [00:04<00:09, 99.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████▎                            | 370/1314 [00:04<00:13, 68.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 472/1314 [00:05<00:07, 106.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 473/1314 [00:04<00:07, 117.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▌                         | 455/1314 [00:05<00:06, 135.86it/s]\u001b[A\u001b[A\n",
      " 24%|█████████▋                              | 319/1314 [00:05<00:14, 68.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████▏                           | 399/1314 [00:04<00:09, 99.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▌                            | 378/1314 [00:05<00:13, 70.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▌                        | 489/1314 [00:04<00:06, 126.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████▋                         | 483/1314 [00:05<00:08, 98.33it/s]\u001b[A\u001b[A\n",
      " 25%|█████████▉                              | 327/1314 [00:05<00:13, 70.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▊                            | 387/1314 [00:05<00:12, 75.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▍                           | 410/1314 [00:05<00:09, 97.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▉                        | 504/1314 [00:05<00:06, 132.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▌                        | 511/1314 [00:05<00:08, 97.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|████████████                            | 395/1314 [00:05<00:12, 75.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 425/1314 [00:05<00:08, 107.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|██████████▏                             | 335/1314 [00:05<00:15, 63.93it/s]\u001b[A\n",
      "\n",
      " 38%|███████████████                         | 494/1314 [00:05<00:10, 79.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▎                       | 518/1314 [00:05<00:06, 116.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████▎                           | 403/1314 [00:05<00:12, 73.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▉                        | 522/1314 [00:05<00:08, 90.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████▎                          | 436/1314 [00:05<00:08, 98.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|███████████████▏                        | 497/1314 [00:05<00:08, 98.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▎                        | 503/1314 [00:05<00:11, 71.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▏                       | 532/1314 [00:05<00:08, 91.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▍                         | 452/1314 [00:05<00:07, 109.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████▌                           | 411/1314 [00:05<00:14, 63.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|███████████████                        | 509/1314 [00:05<00:07, 101.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████▍                       | 542/1314 [00:05<00:08, 90.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 543/1314 [00:05<00:07, 101.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 39%|███████████████▌                        | 511/1314 [00:05<00:12, 64.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 464/1314 [00:05<00:08, 101.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▍                       | 521/1314 [00:05<00:07, 103.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▋                           | 418/1314 [00:05<00:15, 59.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▊                       | 553/1314 [00:05<00:08, 93.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████▊                        | 520/1314 [00:05<00:11, 67.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 475/1314 [00:05<00:08, 101.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▊                       | 554/1314 [00:05<00:08, 90.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▉                           | 426/1314 [00:05<00:14, 62.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|████████████████▏                       | 532/1314 [00:05<00:08, 93.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▏                       | 530/1314 [00:05<00:10, 73.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▊                         | 486/1314 [00:05<00:08, 99.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|█████████████▏                          | 433/1314 [00:05<00:14, 60.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 41%|████████████████▍                       | 542/1314 [00:05<00:08, 87.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|█████████████████▏                      | 564/1314 [00:05<00:09, 76.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████▍                       | 542/1314 [00:06<00:09, 83.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▌                            | 380/1314 [00:06<00:15, 60.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▏                        | 497/1314 [00:05<00:08, 93.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|████████████████▊                       | 554/1314 [00:06<00:08, 94.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|█████████████▍                          | 440/1314 [00:06<00:16, 54.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▊                       | 552/1314 [00:06<00:08, 87.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▊                            | 387/1314 [00:06<00:14, 62.77it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▍                      | 573/1314 [00:05<00:10, 71.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▍                        | 507/1314 [00:06<00:08, 91.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|█████████████████                       | 562/1314 [00:06<00:08, 90.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▋                          | 449/1314 [00:06<00:13, 62.34it/s]\u001b[A\u001b[A\u001b[A\n",
      " 30%|████████████                            | 395/1314 [00:06<00:13, 66.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████                      | 592/1314 [00:06<00:08, 83.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▋                      | 581/1314 [00:06<00:10, 68.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▋                        | 517/1314 [00:06<00:09, 83.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▉                          | 456/1314 [00:06<00:13, 64.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|█████████████████▌                      | 578/1314 [00:06<00:07, 96.59it/s]\u001b[A\u001b[A\n",
      " 31%|████████████▎                           | 403/1314 [00:06<00:13, 68.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▍                      | 572/1314 [00:06<00:09, 79.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████▏                     | 596/1314 [00:06<00:08, 86.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                       | 534/1314 [00:06<00:07, 101.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████▉                      | 588/1314 [00:06<00:07, 97.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|██████████████                          | 463/1314 [00:06<00:15, 54.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▋                      | 581/1314 [00:06<00:09, 78.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▌                     | 610/1314 [00:06<00:09, 72.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 31%|████████████▍                           | 410/1314 [00:06<00:16, 54.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▏                     | 598/1314 [00:06<00:07, 93.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▉                      | 590/1314 [00:06<00:09, 79.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▊                     | 620/1314 [00:06<00:07, 96.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▊                     | 618/1314 [00:06<00:09, 71.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▋                           | 418/1314 [00:06<00:14, 60.18it/s]\u001b[A\n",
      "\n",
      " 46%|██████████████████▌                     | 610/1314 [00:06<00:07, 99.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▉                       | 556/1314 [00:06<00:07, 96.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|██████████████▌                         | 478/1314 [00:06<00:13, 59.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▏                     | 599/1314 [00:06<00:09, 75.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|███████████████████                     | 627/1314 [00:06<00:09, 75.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▉                           | 425/1314 [00:06<00:14, 61.70it/s]\u001b[A\n",
      "\n",
      " 47%|██████████████████▍                    | 623/1314 [00:06<00:06, 104.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▉                      | 569/1314 [00:06<00:07, 104.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████▊                         | 485/1314 [00:06<00:13, 59.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|███████████████████▎                    | 636/1314 [00:06<00:08, 78.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████▌                    | 644/1314 [00:06<00:06, 95.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 46%|██████████████████▍                     | 607/1314 [00:06<00:10, 67.63it/s]\u001b[A\u001b[A\n",
      " 33%|█████████████▏                          | 432/1314 [00:06<00:16, 54.88it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▋                      | 580/1314 [00:06<00:08, 90.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████▋                    | 647/1314 [00:06<00:07, 87.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███████████████                         | 493/1314 [00:06<00:13, 62.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▌                   | 658/1314 [00:06<00:06, 106.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|██████████████████▊                     | 617/1314 [00:07<00:09, 73.99it/s]\u001b[A\u001b[A\n",
      " 33%|█████████████▎                          | 439/1314 [00:07<00:15, 57.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|████████████████████                    | 657/1314 [00:06<00:07, 89.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|███████████████▌                        | 512/1314 [00:07<00:08, 95.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████                   | 678/1314 [00:06<00:04, 130.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|███████████████████▏                    | 631/1314 [00:07<00:07, 90.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▉                      | 590/1314 [00:07<00:09, 76.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|█████████████▌                          | 446/1314 [00:07<00:14, 58.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|████████████████████▎                   | 667/1314 [00:06<00:07, 91.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▉                        | 523/1314 [00:07<00:08, 98.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▋                  | 698/1314 [00:07<00:04, 148.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|███████████████████▌                    | 643/1314 [00:07<00:07, 93.05it/s]\u001b[A\u001b[A\n",
      " 35%|█████████████▊                          | 454/1314 [00:07<00:13, 63.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▌                   | 677/1314 [00:07<00:06, 93.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▏                     | 599/1314 [00:07<00:10, 68.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████████████████▎                       | 534/1314 [00:07<00:08, 87.89it/s]\u001b[A\u001b[A\u001b[A\n",
      " 35%|██████████████                          | 464/1314 [00:07<00:11, 73.29it/s]\u001b[A\n",
      "\n",
      " 53%|████████████████████▍                  | 690/1314 [00:07<00:05, 107.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▏                 | 714/1314 [00:07<00:05, 117.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▌                     | 608/1314 [00:07<00:09, 72.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▉                   | 687/1314 [00:07<00:07, 82.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████████████████▌                       | 544/1314 [00:07<00:08, 85.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 702/1314 [00:07<00:05, 110.16it/s]\u001b[A\u001b[A\n",
      " 50%|████████████████████▏                   | 663/1314 [00:07<00:07, 86.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 728/1314 [00:07<00:04, 119.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▊                     | 620/1314 [00:07<00:08, 82.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████████████████████▏                  | 696/1314 [00:07<00:07, 84.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████▊                       | 553/1314 [00:07<00:08, 85.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▎                 | 718/1314 [00:07<00:04, 122.24it/s]\u001b[A\u001b[A\n",
      " 51%|████████████████████▌                   | 675/1314 [00:07<00:06, 94.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|██████████████████████                 | 742/1314 [00:07<00:04, 123.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▍                  | 705/1314 [00:07<00:07, 85.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|███████████████████▏                    | 630/1314 [00:07<00:08, 83.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▊                      | 568/1314 [00:07<00:07, 102.25it/s]\u001b[A\u001b[A\u001b[A\n",
      " 52%|████████████████████▊                   | 685/1314 [00:07<00:06, 90.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▍                | 756/1314 [00:07<00:04, 125.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▊                  | 716/1314 [00:07<00:06, 91.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████▍                    | 640/1314 [00:07<00:07, 86.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|██████████████████████▎                 | 731/1314 [00:07<00:05, 99.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████████████████████▏                  | 695/1314 [00:07<00:06, 91.72it/s]\u001b[A\u001b[A\u001b[A\n",
      " 39%|███████████████▍                        | 507/1314 [00:07<00:09, 82.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████▊                    | 650/1314 [00:07<00:07, 88.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████                  | 726/1314 [00:07<00:06, 84.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|██████████████████████▌                 | 742/1314 [00:07<00:05, 97.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████▍                  | 705/1314 [00:08<00:07, 85.91it/s]\u001b[A\u001b[A\u001b[A\n",
      " 39%|███████████████▋                        | 517/1314 [00:07<00:09, 83.89it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|██████████████████████▎                 | 735/1314 [00:07<00:06, 85.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|████████████████████                    | 660/1314 [00:07<00:07, 86.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|██████████████████████▉                 | 753/1314 [00:07<00:05, 94.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▊                | 782/1314 [00:07<00:05, 94.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████▋                  | 714/1314 [00:08<00:07, 82.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▋                 | 744/1314 [00:07<00:06, 83.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|████████████████                        | 526/1314 [00:08<00:10, 78.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|████████████████████▎                   | 669/1314 [00:07<00:07, 83.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|███████████████████████▏                | 763/1314 [00:08<00:05, 93.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|████████████████████████▏               | 793/1314 [00:07<00:05, 95.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▋                     | 612/1314 [00:08<00:08, 84.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▉                 | 754/1314 [00:07<00:06, 86.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████                  | 723/1314 [00:08<00:07, 79.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 41%|████████████████▎                       | 535/1314 [00:08<00:09, 78.33it/s]\u001b[A\n",
      "\n",
      " 59%|███████████████████████▌                | 773/1314 [00:08<00:05, 93.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|██████████████████████▎                 | 732/1314 [00:08<00:07, 81.57it/s]\u001b[A\u001b[A\u001b[A\n",
      " 42%|████████████████▌                       | 546/1314 [00:08<00:08, 86.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████▍               | 804/1314 [00:08<00:05, 87.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████▎                | 764/1314 [00:08<00:06, 84.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|███████████████████████▊                | 783/1314 [00:08<00:05, 89.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|██████████████████████▌                 | 741/1314 [00:08<00:06, 82.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|███████████████████▎                    | 634/1314 [00:08<00:07, 91.76it/s]\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▋                      | 562/1314 [00:08<00:07, 104.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▊               | 814/1314 [00:08<00:05, 86.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████▌                | 773/1314 [00:08<00:06, 80.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|████████████████████████▏               | 793/1314 [00:08<00:06, 86.71it/s]\u001b[A\u001b[A\n",
      " 57%|██████████████████████▊                 | 750/1314 [00:08<00:07, 76.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|█████████████████████████               | 823/1314 [00:08<00:05, 84.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▊                | 782/1314 [00:08<00:06, 79.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|████████████████████████▍               | 802/1314 [00:08<00:06, 82.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|█████████████████████▎                  | 701/1314 [00:08<00:09, 62.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████▌                    | 644/1314 [00:08<00:09, 71.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████                 | 758/1314 [00:08<00:07, 70.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|█████████████████████████▎              | 832/1314 [00:08<00:06, 76.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▌                  | 709/1314 [00:08<00:10, 59.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|████████████████████████▋               | 811/1314 [00:08<00:06, 73.12it/s]\u001b[A\u001b[A\n",
      " 45%|█████████████████▉                      | 591/1314 [00:08<00:08, 82.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████▎                | 766/1314 [00:08<00:07, 70.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▌              | 840/1314 [00:08<00:06, 75.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|█████████████████████████▏              | 826/1314 [00:08<00:05, 91.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▊                  | 716/1314 [00:08<00:09, 60.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|███████████████████████▌                | 774/1314 [00:08<00:07, 70.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▋               | 812/1314 [00:08<00:06, 81.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▊              | 848/1314 [00:08<00:06, 71.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|█████████████████████████▍              | 836/1314 [00:08<00:05, 90.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|████████████████████▎                   | 668/1314 [00:08<00:09, 67.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▊                | 782/1314 [00:09<00:07, 71.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|██████████████████▎                     | 602/1314 [00:09<00:11, 63.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████████████████████████              | 856/1314 [00:08<00:06, 68.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▉               | 821/1314 [00:08<00:06, 70.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|████████████████████████                | 790/1314 [00:09<00:07, 71.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|█████████████████████████▊              | 846/1314 [00:09<00:05, 80.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|████████████████████▌                   | 676/1314 [00:09<00:10, 63.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▎             | 864/1314 [00:08<00:06, 69.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|█████████████████████████▏              | 829/1314 [00:08<00:06, 71.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▋                 | 745/1314 [00:09<00:07, 73.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|████████████████████▊                   | 683/1314 [00:09<00:09, 64.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|████████████████████████▎               | 798/1314 [00:09<00:07, 66.00it/s]\u001b[A\u001b[A\n",
      " 46%|██████████████████▌                     | 611/1314 [00:09<00:12, 56.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▌             | 872/1314 [00:09<00:06, 70.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▌              | 838/1314 [00:09<00:06, 68.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████                 | 756/1314 [00:09<00:06, 80.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████▌               | 805/1314 [00:09<00:07, 64.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▊             | 880/1314 [00:09<00:06, 64.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▊              | 848/1314 [00:09<00:06, 72.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████▎                | 765/1314 [00:09<00:07, 77.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|█████████████████████▏                  | 698/1314 [00:09<00:09, 65.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|████████████████████████▋               | 812/1314 [00:09<00:07, 63.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|███████████████████████████             | 887/1314 [00:09<00:06, 64.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|██████████████████████████              | 856/1314 [00:09<00:06, 70.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▉             | 885/1314 [00:09<00:05, 77.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████▍                  | 706/1314 [00:09<00:09, 60.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|███████████████████████████▏            | 895/1314 [00:09<00:06, 67.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████▌                | 774/1314 [00:09<00:08, 65.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|████████████████████████▉               | 819/1314 [00:09<00:08, 57.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▎             | 864/1314 [00:09<00:06, 68.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|█████████████████████████               | 825/1314 [00:09<00:08, 58.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|███████████████████████████▏            | 893/1314 [00:09<00:05, 71.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▍            | 902/1314 [00:09<00:06, 65.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|███████████████████▏                    | 630/1314 [00:09<00:14, 45.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▌             | 871/1314 [00:09<00:06, 67.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▊                | 782/1314 [00:09<00:08, 59.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|█████████████████████████▎              | 831/1314 [00:09<00:08, 57.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|███████████████████████████▍            | 901/1314 [00:09<00:05, 69.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▋            | 909/1314 [00:09<00:06, 61.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|███████████████████▎                    | 636/1314 [00:09<00:14, 45.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▊             | 879/1314 [00:09<00:06, 68.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▌              | 838/1314 [00:10<00:08, 58.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|███████████████████████████▋            | 909/1314 [00:09<00:06, 67.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▉            | 918/1314 [00:09<00:06, 65.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|███████████████████▌                    | 641/1314 [00:10<00:14, 45.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▉             | 886/1314 [00:09<00:06, 68.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▋              | 845/1314 [00:10<00:07, 60.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▉            | 918/1314 [00:10<00:05, 71.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|████████████████████████████▏           | 926/1314 [00:09<00:05, 68.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|██████████████████████▎                 | 734/1314 [00:10<00:10, 57.42it/s]\u001b[A\u001b[A\u001b[A\n",
      " 49%|███████████████████▋                    | 648/1314 [00:10<00:13, 49.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|███████████████████████████▏            | 895/1314 [00:09<00:05, 70.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▉              | 852/1314 [00:10<00:07, 61.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|██████████████████████▌                 | 742/1314 [00:10<00:09, 61.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|████████████████████████████▌           | 937/1314 [00:10<00:04, 76.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|████████████████████████████▏           | 926/1314 [00:10<00:05, 68.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▌            | 904/1314 [00:10<00:05, 75.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▊               | 815/1314 [00:10<00:06, 73.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|██████████████████████████▏             | 860/1314 [00:10<00:07, 63.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▊           | 946/1314 [00:10<00:04, 79.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|██████████████████████▊                 | 751/1314 [00:10<00:08, 67.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|████████████████████████████▍           | 935/1314 [00:10<00:05, 72.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|█████████████████████████               | 824/1314 [00:10<00:06, 76.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▊            | 912/1314 [00:10<00:05, 73.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|████████████████████                    | 660/1314 [00:10<00:13, 48.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|█████████████████████████████           | 955/1314 [00:10<00:04, 80.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|███████████████████████▎                | 765/1314 [00:10<00:06, 85.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|█████████████████████████▎              | 833/1314 [00:10<00:06, 79.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▍             | 867/1314 [00:10<00:08, 55.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|████████████████████████████▋           | 943/1314 [00:10<00:05, 69.19it/s]\u001b[A\u001b[A\n",
      " 51%|████████████████████▎                   | 666/1314 [00:10<00:13, 49.07it/s]\u001b[A\n",
      "\n",
      "\n",
      " 59%|███████████████████████▏               | 781/1314 [00:10<00:05, 103.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▋              | 845/1314 [00:10<00:05, 90.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|████████████████████████████▎           | 932/1314 [00:10<00:04, 85.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|████████████████████████████▉           | 951/1314 [00:10<00:05, 71.68it/s]\u001b[A\u001b[A\n",
      " 66%|██████████████████████████▌             | 873/1314 [00:10<00:08, 51.43it/s]\u001b[A\n",
      "\n",
      "\n",
      " 60%|███████████████████████▌               | 793/1314 [00:10<00:04, 108.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▋             | 864/1314 [00:10<00:03, 115.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████▋          | 974/1314 [00:10<00:04, 82.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▋           | 942/1314 [00:10<00:04, 86.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|█████████████████████████████▎          | 963/1314 [00:10<00:04, 83.82it/s]\u001b[A\u001b[A\n",
      " 67%|██████████████████████████▊             | 880/1314 [00:10<00:07, 55.14it/s]\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▉               | 808/1314 [00:10<00:04, 118.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▏            | 883/1314 [00:10<00:03, 136.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▎         | 989/1314 [00:10<00:03, 101.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 956/1314 [00:10<00:03, 101.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████          | 981/1314 [00:10<00:03, 109.79it/s]\u001b[A\u001b[A\n",
      " 68%|███████████████████████████             | 887/1314 [00:10<00:07, 58.02it/s]\u001b[A\n",
      "\n",
      "\n",
      " 63%|████████████████████████▍              | 823/1314 [00:10<00:03, 123.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 1000/1314 [00:10<00:03, 103.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 969/1314 [00:10<00:03, 105.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▌            | 897/1314 [00:10<00:03, 125.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|███████████████████████████▏            | 894/1314 [00:10<00:06, 60.61it/s]\u001b[A\u001b[A\n",
      " 54%|█████████████████████▌                  | 708/1314 [00:10<00:07, 81.45it/s]\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▉              | 842/1314 [00:10<00:03, 141.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 1017/1314 [00:10<00:02, 121.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▏         | 985/1314 [00:10<00:02, 120.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████            | 912/1314 [00:10<00:03, 127.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|███████████████████████████▍            | 901/1314 [00:11<00:06, 62.52it/s]\u001b[A\u001b[A\n",
      " 55%|█████████████████████▊                  | 717/1314 [00:11<00:07, 80.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▊        | 1032/1314 [00:10<00:02, 128.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▌         | 998/1314 [00:10<00:02, 121.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|███████████████████████████▊            | 912/1314 [00:11<00:05, 75.27it/s]\u001b[A\u001b[A\n",
      " 55%|██████████████████████                  | 726/1314 [00:11<00:07, 81.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▍           | 925/1314 [00:11<00:03, 110.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▍             | 857/1314 [00:11<00:04, 104.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 1013/1314 [00:11<00:02, 126.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|████████████████████████████            | 923/1314 [00:11<00:04, 84.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 1075/1314 [00:11<00:01, 171.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▊           | 937/1314 [00:11<00:03, 103.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|██████████████████████▎                 | 735/1314 [00:11<00:07, 74.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|████████████████████████████▍           | 936/1314 [00:11<00:03, 94.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▍             | 869/1314 [00:11<00:04, 96.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████        | 1041/1314 [00:11<00:02, 100.92it/s]\u001b[A\u001b[A\n",
      " 57%|██████████████████████▌                 | 743/1314 [00:11<00:07, 73.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 948/1314 [00:11<00:03, 101.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▊           | 948/1314 [00:11<00:04, 89.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 1039/1314 [00:11<00:02, 105.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████████████████████████████▏       | 1052/1314 [00:11<00:02, 98.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▊             | 880/1314 [00:11<00:04, 88.70it/s]\u001b[A\u001b[A\u001b[A\n",
      " 73%|████████████████████████████▌          | 963/1314 [00:11<00:03, 114.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|█████████████████████████████▏          | 960/1314 [00:11<00:03, 94.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 1051/1314 [00:11<00:02, 107.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▊       | 1065/1314 [00:11<00:02, 105.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|███████████████████████████             | 891/1314 [00:11<00:04, 92.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 1109/1314 [00:11<00:01, 123.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▉          | 975/1314 [00:11<00:02, 113.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████▌          | 970/1314 [00:11<00:03, 92.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 1062/1314 [00:11<00:02, 99.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▍            | 901/1314 [00:11<00:04, 88.54it/s]\u001b[A\u001b[A\u001b[A\n",
      " 75%|█████████████████████████████▎         | 987/1314 [00:11<00:03, 107.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 1123/1314 [00:11<00:01, 109.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▊          | 980/1314 [00:11<00:03, 89.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▌      | 1091/1314 [00:11<00:02, 105.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▋            | 911/1314 [00:11<00:04, 85.73it/s]\u001b[A\u001b[A\u001b[A\n",
      " 59%|███████████████████████▋                | 779/1314 [00:11<00:06, 77.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 1135/1314 [00:11<00:01, 109.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████▍         | 998/1314 [00:12<00:03, 91.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|██████████████████████████████▏         | 990/1314 [00:11<00:03, 81.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████████████████████████████▋      | 1102/1314 [00:11<00:02, 90.85it/s]\u001b[A\u001b[A\n",
      " 60%|███████████████████████▉                | 787/1314 [00:12<00:07, 72.64it/s]\u001b[A\n",
      "\n",
      "\n",
      " 70%|████████████████████████████            | 920/1314 [00:11<00:05, 76.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 1082/1314 [00:11<00:02, 79.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████     | 1147/1314 [00:11<00:01, 99.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▉         | 1008/1314 [00:12<00:03, 82.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████      | 1112/1314 [00:12<00:02, 86.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 1158/1314 [00:11<00:01, 99.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▍      | 1092/1314 [00:11<00:02, 80.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|████████████████████████████▏           | 928/1314 [00:12<00:05, 67.03it/s]\u001b[A\u001b[A\u001b[A\n",
      " 61%|████████████████████████▏               | 795/1314 [00:12<00:08, 59.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████▏        | 1017/1314 [00:12<00:03, 79.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 1122/1314 [00:12<00:02, 89.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|████████████████████████████▍           | 936/1314 [00:12<00:05, 69.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 1101/1314 [00:12<00:02, 78.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 1169/1314 [00:12<00:01, 92.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|████████████████████████▌               | 806/1314 [00:12<00:07, 69.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 1020/1314 [00:12<00:03, 85.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|██████████████████████████████▍        | 1026/1314 [00:12<00:03, 79.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▉      | 1111/1314 [00:12<00:02, 83.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▉    | 1179/1314 [00:12<00:01, 90.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|████████████████████████▊               | 814/1314 [00:12<00:07, 69.68it/s]\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▋        | 1035/1314 [00:12<00:03, 77.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 1123/1314 [00:12<00:02, 91.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▌        | 1029/1314 [00:12<00:03, 73.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|█████████████████████████████           | 954/1314 [00:12<00:04, 75.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 1190/1314 [00:12<00:01, 93.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|█████████████████████████               | 822/1314 [00:12<00:07, 69.38it/s]\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▉        | 1043/1314 [00:12<00:03, 77.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 1133/1314 [00:12<00:02, 89.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|█████████████████████████████▎          | 964/1314 [00:12<00:04, 79.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 1200/1314 [00:12<00:01, 93.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████    | 1178/1314 [00:12<00:01, 124.13it/s]\u001b[A\u001b[A\n",
      " 80%|███████████████████████████████▏       | 1052/1314 [00:12<00:03, 78.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 1037/1314 [00:12<00:04, 62.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 1212/1314 [00:12<00:01, 100.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 1143/1314 [00:12<00:01, 86.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████▌          | 973/1314 [00:12<00:04, 76.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▌              | 838/1314 [00:12<00:06, 70.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 1061/1314 [00:12<00:03, 79.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 1224/1314 [00:12<00:00, 102.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▉          | 982/1314 [00:12<00:04, 79.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▏    | 1152/1314 [00:12<00:01, 87.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|█████████████████████████▊              | 846/1314 [00:12<00:06, 71.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▊       | 1070/1314 [00:12<00:03, 75.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 1205/1314 [00:12<00:00, 109.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 1163/1314 [00:12<00:01, 89.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|██████████████████████████████▏         | 991/1314 [00:12<00:04, 74.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 1235/1314 [00:12<00:00, 91.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|█████████████████████████▉              | 854/1314 [00:13<00:06, 69.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 1078/1314 [00:13<00:03, 74.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████▍         | 999/1314 [00:13<00:04, 74.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 1074/1314 [00:13<00:03, 79.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|██████████████████████████▏             | 862/1314 [00:13<00:06, 68.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 1173/1314 [00:12<00:01, 77.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 1245/1314 [00:12<00:00, 84.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████████████████████████████▏      | 1086/1314 [00:13<00:03, 68.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████         | 1011/1314 [00:13<00:03, 86.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████▏      | 1083/1314 [00:13<00:02, 81.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████    | 1182/1314 [00:13<00:01, 80.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|██████████████████████████▍             | 869/1314 [00:13<00:06, 66.02it/s]\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████████▍  | 1227/1314 [00:13<00:00, 87.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▍      | 1093/1314 [00:13<00:03, 69.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 1024/1314 [00:13<00:03, 96.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▌      | 1095/1314 [00:13<00:02, 91.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 1191/1314 [00:13<00:01, 80.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|██████████████████████████▋             | 876/1314 [00:13<00:06, 62.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 1263/1314 [00:13<00:00, 81.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 1237/1314 [00:13<00:00, 85.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 1035/1314 [00:13<00:02, 98.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 1114/1314 [00:13<00:01, 117.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 1200/1314 [00:13<00:01, 80.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▉      | 1111/1314 [00:13<00:02, 78.26it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 1273/1314 [00:13<00:00, 83.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 1047/1314 [00:13<00:02, 104.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████████  | 1247/1314 [00:13<00:00, 82.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 1127/1314 [00:13<00:01, 119.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▉   | 1209/1314 [00:13<00:01, 82.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|█████████████████████████████████▎     | 1123/1314 [00:13<00:02, 89.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████ | 1284/1314 [00:13<00:00, 88.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 1260/1314 [00:13<00:00, 91.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 1058/1314 [00:13<00:02, 98.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 1134/1314 [00:13<00:01, 94.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▍| 1294/1314 [00:13<00:00, 90.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▏  | 1218/1314 [00:13<00:01, 69.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 1270/1314 [00:13<00:00, 89.15it/s]\u001b[A\u001b[A\n",
      " 69%|███████████████████████████▋            | 911/1314 [00:13<00:05, 77.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 1153/1314 [00:13<00:01, 115.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 1145/1314 [00:13<00:01, 95.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 1304/1314 [00:13<00:00, 91.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 1280/1314 [00:13<00:00, 91.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▍  | 1226/1314 [00:13<00:01, 67.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|██████████████████████████████████▎    | 1155/1314 [00:13<00:01, 92.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:13<00:00, 95.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▎| 1290/1314 [00:13<00:00, 88.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 1079/1314 [00:13<00:03, 74.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 1165/1314 [00:13<00:01, 87.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 1236/1314 [00:13<00:01, 70.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 1165/1314 [00:14<00:01, 88.10it/s]\u001b[A\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 1300/1314 [00:14<00:00, 89.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 1246/1314 [00:13<00:00, 77.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▎      | 1087/1314 [00:14<00:03, 70.48it/s]\u001b[A\u001b[A\u001b[A\n",
      " 72%|████████████████████████████▋           | 941/1314 [00:14<00:05, 69.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 1174/1314 [00:14<00:01, 75.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████▉| 1310/1314 [00:14<00:00, 84.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 1175/1314 [00:14<00:02, 67.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:14<00:00, 92.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|███████████████████████████████████    | 1182/1314 [00:14<00:01, 70.75it/s]\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 1102/1314 [00:14<00:03, 63.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 1270/1314 [00:14<00:00, 77.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 1184/1314 [00:14<00:01, 65.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▍   | 1195/1314 [00:14<00:01, 85.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████      | 1113/1314 [00:14<00:02, 74.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████ | 1283/1314 [00:14<00:00, 87.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 1192/1314 [00:14<00:01, 66.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▊   | 1208/1314 [00:14<00:01, 94.30it/s]\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▎     | 1124/1314 [00:14<00:02, 80.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▋   | 1202/1314 [00:14<00:01, 73.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▍| 1297/1314 [00:14<00:00, 97.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|████████████████████████████████████▏  | 1220/1314 [00:14<00:00, 99.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████   | 1213/1314 [00:14<00:01, 81.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▋     | 1137/1314 [00:14<00:01, 90.78it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|█████████████████████████████         | 1004/1314 [00:14<00:02, 111.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:14<00:00, 90.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▍  | 1228/1314 [00:14<00:00, 96.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████     | 1148/1314 [00:14<00:01, 92.80it/s]\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▊  | 1242/1314 [00:14<00:00, 96.68it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▊  | 1239/1314 [00:14<00:00, 96.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 1159/1314 [00:14<00:01, 94.48it/s]\u001b[A\u001b[A\u001b[A\n",
      " 95%|█████████████████████████████████████▏ | 1253/1314 [00:15<00:00, 98.68it/s]\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 1170/1314 [00:15<00:01, 98.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 1250/1314 [00:14<00:00, 92.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▌ | 1266/1314 [00:15<00:00, 107.00it/s]\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████    | 1181/1314 [00:15<00:01, 98.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████ | 1280/1314 [00:15<00:00, 115.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▍       | 1054/1314 [00:15<00:02, 104.52it/s]\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 1195/1314 [00:15<00:01, 110.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 1296/1314 [00:15<00:00, 126.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▉       | 1070/1314 [00:15<00:02, 118.12it/s]\u001b[A\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▏  | 1215/1314 [00:15<00:00, 134.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▊| 1309/1314 [00:15<00:00, 117.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 1303/1314 [00:15<00:00, 118.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:15<00:00, 84.47it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:15<00:00, 85.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████████████████████████████▍      | 1094/1314 [00:15<00:02, 98.45it/s]\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▊  | 1242/1314 [00:15<00:00, 99.72it/s]\u001b[A\u001b[A\u001b[A\n",
      " 84%|████████████████████████████████      | 1109/1314 [00:15<00:01, 111.11it/s]\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▎ | 1254/1314 [00:15<00:00, 104.01it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▌     | 1125/1314 [00:15<00:01, 123.16it/s]\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 1266/1314 [00:15<00:00, 106.72it/s]\u001b[A\u001b[A\u001b[A\n",
      " 87%|████████████████████████████████▉     | 1138/1314 [00:15<00:01, 124.23it/s]\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████ | 1283/1314 [00:15<00:00, 123.09it/s]\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▍    | 1155/1314 [00:16<00:01, 136.10it/s]\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▊| 1306/1314 [00:16<00:00, 148.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:16<00:00, 81.64it/s]\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 1193/1314 [00:16<00:00, 158.11it/s]\u001b[A\n",
      " 92%|██████████████████████████████████▉   | 1210/1314 [00:16<00:00, 161.23it/s]\u001b[A\n",
      " 93%|███████████████████████████████████▍  | 1227/1314 [00:16<00:00, 161.87it/s]\u001b[A\n",
      " 95%|███████████████████████████████████▉  | 1244/1314 [00:16<00:00, 148.56it/s]\u001b[A\n",
      " 96%|████████████████████████████████████▍ | 1260/1314 [00:16<00:00, 144.86it/s]\u001b[A\n",
      " 97%|████████████████████████████████████▊ | 1275/1314 [00:16<00:00, 134.76it/s]\u001b[A\n",
      "100%|███████████████████████████████████████| 1314/1314 [00:17<00:00, 77.08it/s]\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb.tsv\n",
      "Processing Started...\n",
      "Data Size:  18406\n",
      "number of threads:  7\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 21/2629 [00:00<00:12, 202.02it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  1%|▎                                       | 20/2629 [00:00<00:13, 196.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  1%|▎                                       | 21/2629 [00:00<00:12, 201.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|▏                                       | 12/2629 [00:00<00:22, 116.72it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                        | 10/2629 [00:00<00:32, 81.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 42/2629 [00:00<00:15, 165.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                          | 5/2629 [00:00<00:53, 48.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▋                                       | 42/2629 [00:00<00:15, 171.65it/s]\u001b[A\u001b[A\n",
      "  2%|▌                                       | 40/2629 [00:00<00:17, 145.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "  1%|▎                                        | 24/2629 [00:00<00:30, 85.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                        | 10/2629 [00:00<00:54, 48.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 19/2629 [00:00<00:38, 68.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                        | 12/2629 [00:00<00:58, 44.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▉                                       | 59/2629 [00:00<00:20, 123.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▉                                       | 60/2629 [00:00<00:19, 133.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 20/2629 [00:00<00:37, 70.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  2%|▊                                       | 56/2629 [00:00<00:23, 109.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 17/2629 [00:00<00:56, 46.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                        | 29/2629 [00:00<00:34, 75.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                        | 28/2629 [00:00<00:37, 68.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▋                                        | 47/2629 [00:00<00:29, 86.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 68/2629 [00:00<00:23, 110.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                       | 73/2629 [00:00<00:27, 94.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▏                                      | 75/2629 [00:00<00:24, 102.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                        | 42/2629 [00:00<00:28, 91.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                        | 58/2629 [00:00<00:27, 91.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                        | 42/2629 [00:00<00:27, 94.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 87/2629 [00:00<00:24, 103.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▎                                      | 89/2629 [00:00<00:22, 111.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                       | 55/2629 [00:00<00:24, 103.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█                                       | 72/2629 [00:00<00:24, 105.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                       | 54/2629 [00:00<00:25, 100.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▍                                     | 101/2629 [00:00<00:19, 132.44it/s]\u001b[A\n",
      "\n",
      "  4%|█▌                                      | 99/2629 [00:00<00:24, 105.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 69/2629 [00:00<00:22, 113.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 83/2629 [00:00<00:24, 105.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                      | 78/2629 [00:00<00:21, 120.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▊                                     | 122/2629 [00:00<00:16, 153.58it/s]\u001b[A\n",
      "\n",
      "  4%|█▋                                     | 111/2629 [00:00<00:23, 105.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 83/2629 [00:00<00:21, 121.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 110/2629 [00:00<00:16, 152.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 95/2629 [00:00<00:16, 155.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|██                                     | 140/2629 [00:01<00:16, 155.31it/s]\u001b[A\n",
      "\n",
      "  5%|█▊                                     | 126/2629 [00:01<00:21, 116.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 96/2629 [00:00<00:22, 114.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 114/2629 [00:01<00:17, 141.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|█▊                                     | 126/2629 [00:01<00:17, 141.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 111/2629 [00:01<00:17, 142.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|██                                     | 141/2629 [00:01<00:19, 125.59it/s]\u001b[A\n",
      "\n",
      "  6%|██▎                                    | 155/2629 [00:01<00:17, 140.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 129/2629 [00:01<00:17, 141.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 115/2629 [00:01<00:18, 132.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|██                                     | 142/2629 [00:01<00:17, 146.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▌                                    | 173/2629 [00:01<00:16, 146.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 161/2629 [00:01<00:16, 145.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▌                                    | 170/2629 [00:01<00:17, 137.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 134/2629 [00:01<00:16, 149.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 165/2629 [00:01<00:14, 167.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                    | 144/2629 [00:01<00:18, 136.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 152/2629 [00:01<00:14, 167.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▋                                    | 180/2629 [00:01<00:16, 151.85it/s]\u001b[A\n",
      "\n",
      "  7%|██▋                                    | 185/2629 [00:01<00:17, 136.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 184/2629 [00:01<00:14, 172.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 162/2629 [00:01<00:16, 148.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 150/2629 [00:01<00:18, 133.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  8%|███▏                                   | 212/2629 [00:01<00:14, 163.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▌                                    | 170/2629 [00:01<00:15, 163.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                    | 196/2629 [00:01<00:18, 129.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▍                                   | 235/2629 [00:01<00:13, 179.50it/s]\u001b[A\n",
      "\n",
      "  8%|██▉                                    | 199/2629 [00:01<00:21, 114.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 164/2629 [00:01<00:19, 124.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▊                                    | 187/2629 [00:01<00:15, 155.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 212/2629 [00:01<00:17, 137.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 212/2629 [00:01<00:13, 178.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                    | 196/2629 [00:01<00:18, 131.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 180/2629 [00:01<00:18, 129.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▊                                   | 254/2629 [00:01<00:14, 161.79it/s]\u001b[A\n",
      "\n",
      "  9%|███▍                                   | 231/2629 [00:01<00:16, 148.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 217/2629 [00:01<00:18, 127.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|██▉                                    | 200/2629 [00:01<00:16, 145.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▏                                  | 279/2629 [00:01<00:12, 182.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 210/2629 [00:01<00:18, 127.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 231/2629 [00:01<00:14, 171.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▎                                   | 224/2629 [00:01<00:22, 104.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 247/2629 [00:01<00:17, 133.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 249/2629 [00:01<00:13, 170.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▎                                   | 224/2629 [00:01<00:19, 120.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▍                                  | 298/2629 [00:01<00:15, 154.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 246/2629 [00:01<00:18, 125.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▌                                    | 235/2629 [00:01<00:25, 93.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 261/2629 [00:02<00:18, 126.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 237/2629 [00:01<00:19, 122.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 267/2629 [00:01<00:16, 142.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▋                                   | 249/2629 [00:02<00:22, 104.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 260/2629 [00:02<00:19, 123.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 275/2629 [00:02<00:18, 127.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 253/2629 [00:02<00:18, 130.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▋                                  | 315/2629 [00:02<00:18, 123.84it/s]\u001b[A\n",
      "\n",
      " 10%|███▉                                   | 265/2629 [00:02<00:20, 116.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|████                                   | 273/2629 [00:02<00:18, 124.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 296/2629 [00:02<00:15, 148.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 268/2629 [00:02<00:17, 134.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 283/2629 [00:02<00:18, 126.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|████▉                                  | 332/2629 [00:02<00:17, 133.39it/s]\u001b[A\n",
      "\n",
      " 11%|████▏                                  | 281/2629 [00:02<00:18, 127.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 287/2629 [00:02<00:18, 127.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 323/2629 [00:02<00:13, 175.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 285/2629 [00:02<00:16, 143.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 298/2629 [00:02<00:18, 126.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▎                                 | 357/2629 [00:02<00:14, 159.77it/s]\u001b[A\n",
      "\n",
      " 11%|████▍                                  | 297/2629 [00:02<00:17, 134.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 300/2629 [00:02<00:18, 123.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 271/2629 [00:02<00:20, 116.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 312/2629 [00:02<00:18, 127.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████                                  | 341/2629 [00:02<00:14, 156.00it/s]\u001b[A\n",
      "\n",
      " 12%|████▋                                  | 314/2629 [00:02<00:16, 143.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 318/2629 [00:02<00:16, 139.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 316/2629 [00:02<00:16, 144.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 363/2629 [00:02<00:13, 171.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▉                                 | 404/2629 [00:02<00:12, 183.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 326/2629 [00:02<00:19, 121.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████                                  | 342/2629 [00:02<00:13, 166.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 334/2629 [00:02<00:14, 153.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▋                                 | 381/2629 [00:02<00:13, 162.03it/s]\u001b[A\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 364/2629 [00:02<00:12, 180.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████                                  | 344/2629 [00:02<00:17, 134.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 302/2629 [00:02<00:21, 109.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 351/2629 [00:02<00:14, 157.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 339/2629 [00:02<00:21, 104.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▋                                | 448/2629 [00:02<00:10, 199.52it/s]\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 403/2629 [00:02<00:12, 174.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 318/2629 [00:02<00:19, 120.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▎                                 | 358/2629 [00:02<00:18, 125.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 367/2629 [00:02<00:14, 151.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 353/2629 [00:02<00:20, 110.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▉                                | 469/2629 [00:02<00:10, 199.63it/s]\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 431/2629 [00:02<00:10, 201.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 338/2629 [00:02<00:16, 140.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▌                                 | 372/2629 [00:02<00:17, 127.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 385/2629 [00:02<00:14, 158.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                | 459/2629 [00:03<00:09, 221.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▎                               | 490/2629 [00:03<00:11, 189.44it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 358/2629 [00:02<00:14, 152.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 427/2629 [00:03<00:12, 176.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▋                                 | 385/2629 [00:03<00:17, 125.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 401/2629 [00:03<00:15, 144.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▏                               | 486/2629 [00:03<00:09, 233.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▋                               | 518/2629 [00:03<00:09, 213.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 377/2629 [00:03<00:13, 162.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 446/2629 [00:03<00:12, 171.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▉                                 | 398/2629 [00:03<00:19, 113.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                               | 522/2629 [00:03<00:07, 268.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████                               | 540/2629 [00:03<00:09, 215.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 394/2629 [00:03<00:21, 104.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 394/2629 [00:03<00:16, 137.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▎                              | 562/2629 [00:03<00:09, 215.89it/s]\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 464/2629 [00:03<00:14, 148.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 411/2629 [00:03<00:18, 120.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▏                              | 550/2629 [00:03<00:08, 237.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▎                                | 422/2629 [00:03<00:19, 112.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|███████▏                               | 483/2629 [00:03<00:13, 158.35it/s]\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▋                              | 584/2629 [00:03<00:09, 207.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 409/2629 [00:03<00:17, 129.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 427/2629 [00:03<00:17, 128.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                              | 575/2629 [00:03<00:08, 237.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▌                                | 439/2629 [00:03<00:17, 127.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 423/2629 [00:03<00:17, 129.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                | 449/2629 [00:03<00:14, 152.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▉                              | 606/2629 [00:03<00:10, 193.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                | 459/2629 [00:03<00:17, 126.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▍                               | 500/2629 [00:03<00:14, 143.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▉                              | 600/2629 [00:03<00:10, 201.03it/s]\u001b[A\u001b[A\n",
      " 24%|█████████▎                             | 626/2629 [00:03<00:10, 183.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                               | 516/2629 [00:03<00:17, 121.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 437/2629 [00:03<00:22, 98.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 465/2629 [00:03<00:18, 116.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▉                                | 468/2629 [00:03<00:20, 104.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                | 450/2629 [00:03<00:20, 105.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▌                             | 645/2629 [00:03<00:15, 129.68it/s]\u001b[A\n",
      "\n",
      " 18%|███████▎                                | 480/2629 [00:03<00:21, 97.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                             | 622/2629 [00:04<00:15, 130.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|████████                                | 530/2629 [00:03<00:21, 97.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▎                                | 479/2629 [00:03<00:22, 95.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                                | 462/2629 [00:03<00:20, 105.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▍                             | 639/2629 [00:04<00:15, 127.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                                | 474/2629 [00:04<00:20, 103.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                                | 494/2629 [00:04<00:27, 78.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▍                                | 491/2629 [00:04<00:24, 87.29it/s]\u001b[A\u001b[A\n",
      " 25%|█████████▊                             | 661/2629 [00:04<00:17, 112.48it/s]\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▏                               | 541/2629 [00:04<00:23, 87.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▊                             | 659/2629 [00:04<00:14, 136.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▋                                | 507/2629 [00:04<00:24, 87.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 26%|██████████                             | 678/2629 [00:04<00:15, 123.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▋                                | 502/2629 [00:04<00:23, 92.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▍                               | 554/2629 [00:04<00:22, 93.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▋                               | 518/2629 [00:04<00:19, 107.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████                             | 680/2629 [00:04<00:13, 148.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▎                            | 697/2629 [00:04<00:14, 136.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▍                                | 485/2629 [00:04<00:27, 78.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▌                               | 565/2629 [00:04<00:21, 95.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                                | 513/2629 [00:04<00:25, 83.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▊                               | 530/2629 [00:04<00:19, 110.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████                                | 532/2629 [00:04<00:21, 95.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                                | 494/2629 [00:04<00:28, 76.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▎                            | 697/2629 [00:04<00:15, 128.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████                               | 544/2629 [00:04<00:18, 113.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                               | 543/2629 [00:04<00:21, 96.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▌                            | 713/2629 [00:04<00:18, 106.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▋                                | 507/2629 [00:04<00:24, 85.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 712/2629 [00:04<00:14, 132.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▉                               | 587/2629 [00:04<00:22, 91.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████▎                              | 559/2629 [00:04<00:16, 123.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                              | 560/2629 [00:04<00:18, 113.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|██████████▊                            | 730/2629 [00:04<00:16, 118.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                                | 517/2629 [00:04<00:24, 86.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 729/2629 [00:04<00:13, 140.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████                               | 597/2629 [00:04<00:22, 91.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▌                              | 577/2629 [00:04<00:14, 138.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                              | 573/2629 [00:04<00:17, 114.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|███████████                            | 745/2629 [00:04<00:15, 123.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 750/2629 [00:04<00:12, 154.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                               | 547/2629 [00:04<00:24, 85.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████                              | 612/2629 [00:04<00:19, 103.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▊                              | 592/2629 [00:04<00:15, 135.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▋                              | 585/2629 [00:04<00:17, 113.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▎                           | 761/2629 [00:04<00:14, 132.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▍                           | 767/2629 [00:05<00:11, 155.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▎                             | 625/2629 [00:04<00:18, 110.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|█████████                              | 611/2629 [00:04<00:13, 150.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▉                              | 600/2629 [00:04<00:16, 122.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▋                           | 785/2629 [00:05<00:11, 157.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                               | 546/2629 [00:04<00:24, 83.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▍                               | 557/2629 [00:05<00:29, 69.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▎                             | 630/2629 [00:05<00:12, 161.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▍                             | 637/2629 [00:05<00:19, 101.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                             | 619/2629 [00:05<00:14, 141.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 31%|███████████▉                           | 802/2629 [00:05<00:11, 154.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                           | 808/2629 [00:05<00:10, 176.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▌                               | 565/2629 [00:05<00:29, 70.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▌                             | 647/2629 [00:05<00:12, 157.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▌                             | 648/2629 [00:05<00:19, 103.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▍                             | 638/2629 [00:05<00:12, 153.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▎                          | 829/2629 [00:05<00:09, 183.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▋                               | 569/2629 [00:05<00:21, 94.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▋                               | 575/2629 [00:05<00:27, 74.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▊                             | 663/2629 [00:05<00:12, 152.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██████████                              | 659/2629 [00:05<00:19, 99.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▋                             | 654/2629 [00:05<00:13, 146.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▍                          | 842/2629 [00:05<00:11, 157.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 848/2629 [00:05<00:09, 179.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▉                               | 587/2629 [00:05<00:24, 84.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|██████████                             | 679/2629 [00:05<00:13, 143.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▉                             | 669/2629 [00:05<00:13, 143.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▏                             | 671/2629 [00:05<00:19, 99.50it/s]\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▉                          | 870/2629 [00:05<00:09, 187.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                              | 594/2629 [00:05<00:18, 110.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|██████████▎                            | 694/2629 [00:05<00:14, 136.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▏                            | 684/2629 [00:05<00:13, 140.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▍                             | 682/2629 [00:05<00:20, 94.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████                               | 597/2629 [00:05<00:28, 71.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▏                         | 886/2629 [00:05<00:10, 166.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 714/2629 [00:05<00:10, 182.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 27%|██████████▌                            | 714/2629 [00:05<00:12, 149.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▌                             | 692/2629 [00:05<00:20, 93.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▏                              | 606/2629 [00:05<00:27, 74.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▉                            | 734/2629 [00:05<00:11, 160.57it/s]\u001b[A\u001b[A\n",
      " 34%|█████████████▍                         | 903/2629 [00:05<00:12, 141.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▍                              | 618/2629 [00:05<00:23, 87.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▎                              | 615/2629 [00:05<00:26, 77.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▋                             | 702/2629 [00:05<00:21, 89.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 733/2629 [00:05<00:12, 148.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████▏                           | 751/2629 [00:05<00:11, 162.42it/s]\u001b[A\u001b[A\n",
      " 35%|█████████████▌                         | 918/2629 [00:05<00:12, 138.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▍                              | 624/2629 [00:05<00:25, 78.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▊                             | 713/2629 [00:05<00:20, 93.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▌                              | 628/2629 [00:05<00:24, 82.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████▍                           | 769/2629 [00:05<00:11, 167.06it/s]\u001b[A\u001b[A\n",
      " 35%|█████████████▊                         | 933/2629 [00:06<00:12, 138.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▋                              | 633/2629 [00:05<00:25, 78.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████                             | 723/2629 [00:06<00:21, 86.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 750/2629 [00:06<00:15, 120.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▋                           | 786/2629 [00:06<00:11, 167.41it/s]\u001b[A\u001b[A\n",
      " 37%|██████████████▎                        | 965/2629 [00:06<00:09, 175.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 948/2629 [00:06<00:12, 135.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 764/2629 [00:06<00:15, 120.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▊                              | 642/2629 [00:06<00:27, 71.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▉                           | 803/2629 [00:06<00:11, 161.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████▏                            | 732/2629 [00:06<00:24, 78.78it/s]\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████▌                        | 984/2629 [00:06<00:10, 163.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▉                              | 650/2629 [00:06<00:27, 73.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▎                        | 962/2629 [00:06<00:14, 112.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████▎                            | 741/2629 [00:06<00:23, 79.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                           | 778/2629 [00:06<00:16, 111.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 38%|██████████████▍                       | 1001/2629 [00:06<00:10, 152.00it/s]\u001b[A\n",
      "\n",
      " 31%|████████████▏                          | 820/2629 [00:06<00:14, 123.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▉                              | 652/2629 [00:06<00:31, 62.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▍                        | 974/2629 [00:06<00:14, 112.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▍                            | 750/2629 [00:06<00:23, 79.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 796/2629 [00:06<00:14, 125.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 39%|██████████████▋                       | 1017/2629 [00:06<00:10, 152.49it/s]\u001b[A\n",
      "\n",
      " 32%|████████████▎                          | 834/2629 [00:06<00:14, 126.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████                              | 663/2629 [00:06<00:27, 72.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▏                             | 671/2629 [00:06<00:23, 82.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 986/2629 [00:06<00:14, 110.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████                           | 816/2629 [00:06<00:12, 141.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 39%|██████████████▉                       | 1034/2629 [00:06<00:10, 156.01it/s]\u001b[A\n",
      "\n",
      " 33%|████████████▋                          | 858/2629 [00:06<00:11, 154.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▎                             | 675/2629 [00:06<00:23, 82.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▍                             | 685/2629 [00:06<00:19, 97.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▊                            | 774/2629 [00:06<00:19, 94.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 998/2629 [00:06<00:14, 109.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████▏                      | 1050/2629 [00:06<00:10, 152.78it/s]\u001b[A\n",
      "\n",
      " 33%|████████████▉                          | 875/2629 [00:06<00:11, 157.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▎                            | 693/2629 [00:06<00:18, 104.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                            | 699/2629 [00:06<00:17, 107.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 1010/2629 [00:06<00:14, 110.92it/s]\u001b[A\u001b[A\u001b[A\n",
      " 41%|███████████████▍                      | 1068/2629 [00:06<00:09, 160.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 849/2629 [00:06<00:12, 137.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 711/2629 [00:06<00:17, 110.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 709/2629 [00:06<00:16, 115.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 34%|█████████████▏                         | 892/2629 [00:06<00:12, 144.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 1022/2629 [00:06<00:14, 111.60it/s]\u001b[A\u001b[A\u001b[A\n",
      " 41%|███████████████▋                      | 1087/2629 [00:06<00:09, 168.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 864/2629 [00:06<00:14, 124.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▍                         | 908/2629 [00:06<00:11, 147.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 1037/2629 [00:07<00:13, 116.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                            | 723/2629 [00:06<00:18, 101.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▉                      | 1104/2629 [00:07<00:09, 162.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▋                            | 722/2629 [00:06<00:18, 100.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████                          | 880/2629 [00:06<00:13, 129.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▊                         | 928/2629 [00:07<00:10, 158.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 1049/2629 [00:07<00:13, 116.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████▎                          | 828/2629 [00:07<00:16, 107.75it/s]\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▏                     | 1122/2629 [00:07<00:09, 165.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▉                            | 736/2629 [00:07<00:17, 109.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 1061/2629 [00:07<00:13, 116.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 846/2629 [00:07<00:14, 125.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|██████████████                         | 945/2629 [00:07<00:11, 148.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 749/2629 [00:07<00:16, 112.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 752/2629 [00:07<00:18, 102.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▍                     | 1139/2629 [00:07<00:10, 147.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 1077/2629 [00:07<00:12, 127.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████▎                        | 968/2629 [00:07<00:09, 169.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 863/2629 [00:07<00:13, 134.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 766/2629 [00:07<00:14, 126.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▊                      | 1095/2629 [00:07<00:10, 140.88it/s]\u001b[A\n",
      "\n",
      " 38%|██████████████▋                        | 991/2629 [00:07<00:08, 183.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▌                            | 763/2629 [00:07<00:20, 89.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|█████████████                          | 879/2629 [00:07<00:12, 139.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 922/2629 [00:07<00:14, 116.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                           | 780/2629 [00:07<00:15, 123.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▉                     | 1169/2629 [00:07<00:11, 132.56it/s]\u001b[A\n",
      "\n",
      " 42%|████████████████                      | 1110/2629 [00:07<00:11, 136.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▉                         | 937/2629 [00:07<00:13, 123.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                            | 776/2629 [00:07<00:19, 97.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 894/2629 [00:07<00:12, 134.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 796/2629 [00:07<00:13, 131.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▏                    | 1192/2629 [00:07<00:09, 154.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▏                     | 1124/2629 [00:07<00:11, 127.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▉                       | 1031/2629 [00:07<00:09, 175.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▉                            | 787/2629 [00:07<00:19, 93.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▍                         | 908/2629 [00:07<00:14, 118.59it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 1208/2629 [00:07<00:09, 156.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████                           | 810/2629 [00:07<00:16, 111.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▍                        | 970/2629 [00:07<00:12, 135.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 1137/2629 [00:07<00:13, 111.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 921/2629 [00:07<00:15, 108.52it/s]\u001b[A\u001b[A\u001b[A\n",
      " 47%|█████████████████▋                    | 1224/2629 [00:07<00:11, 124.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▌                           | 822/2629 [00:07<00:18, 95.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▏                      | 1049/2629 [00:07<00:13, 120.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▌                        | 984/2629 [00:07<00:14, 110.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████                      | 1149/2629 [00:08<00:15, 94.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▍                          | 838/2629 [00:07<00:16, 108.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 47%|█████████████████▉                    | 1238/2629 [00:08<00:11, 119.66it/s]\u001b[A\n",
      "\n",
      "\n",
      " 35%|██████████████▏                         | 933/2629 [00:08<00:19, 88.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 996/2629 [00:08<00:15, 105.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▍                      | 1064/2629 [00:08<00:13, 115.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▏                     | 1160/2629 [00:08<00:15, 93.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 850/2629 [00:08<00:16, 110.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|██████████████▍                         | 946/2629 [00:08<00:17, 96.12it/s]\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████                    | 1251/2629 [00:08<00:11, 116.57it/s]\u001b[A\n",
      "\n",
      " 41%|███████████████▌                      | 1080/2629 [00:08<00:12, 124.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                     | 1170/2629 [00:08<00:15, 93.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▌                           | 823/2629 [00:08<00:25, 69.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 862/2629 [00:08<00:16, 104.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▎                   | 1264/2629 [00:08<00:11, 116.68it/s]\u001b[A\n",
      "\n",
      "\n",
      " 36%|██████████████▌                         | 957/2629 [00:08<00:17, 95.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▌                     | 1180/2629 [00:08<00:15, 93.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▋                           | 832/2629 [00:08<00:24, 71.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▉                          | 873/2629 [00:08<00:16, 104.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|███████████████▊                      | 1095/2629 [00:08<00:14, 106.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████▋                         | 968/2629 [00:08<00:17, 96.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 1035/2629 [00:08<00:14, 113.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▋                     | 1191/2629 [00:08<00:14, 97.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▊                           | 844/2629 [00:08<00:21, 82.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 894/2629 [00:08<00:13, 130.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|████████████████                      | 1112/2629 [00:08<00:12, 119.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 1048/2629 [00:08<00:13, 116.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 988/2629 [00:08<00:13, 120.28it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 1205/2629 [00:08<00:13, 107.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████                           | 856/2629 [00:08<00:19, 90.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▍                         | 908/2629 [00:08<00:13, 128.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|████████████████▎                     | 1126/2629 [00:08<00:12, 121.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 1062/2629 [00:08<00:12, 122.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 1007/2629 [00:08<00:11, 135.77it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▌                    | 1216/2629 [00:08<00:13, 102.76it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████▏                          | 867/2629 [00:08<00:18, 94.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 923/2629 [00:08<00:12, 133.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 1080/2629 [00:08<00:11, 137.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 1230/2629 [00:08<00:12, 111.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▏                         | 886/2629 [00:08<00:14, 118.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 945/2629 [00:08<00:10, 154.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 1097/2629 [00:08<00:10, 146.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|███████████████████                   | 1323/2629 [00:08<00:12, 104.75it/s]\u001b[A\n",
      "\n",
      " 44%|████████████████▋                     | 1154/2629 [00:08<00:11, 123.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████                    | 1247/2629 [00:08<00:11, 124.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▍                         | 906/2629 [00:08<00:12, 140.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▎                        | 964/2629 [00:08<00:10, 164.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▏                     | 1117/2629 [00:08<00:09, 161.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|████████████████▉                     | 1176/2629 [00:08<00:09, 148.19it/s]\u001b[A\u001b[A\n",
      " 51%|███████████████████▎                  | 1335/2629 [00:08<00:12, 105.55it/s]\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 1266/2629 [00:08<00:09, 142.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 925/2629 [00:08<00:11, 154.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▌                        | 982/2629 [00:08<00:09, 167.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 1137/2629 [00:08<00:08, 172.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████▎                    | 1196/2629 [00:09<00:08, 162.09it/s]\u001b[A\u001b[A\n",
      " 52%|███████████████████▌                  | 1354/2629 [00:09<00:10, 124.41it/s]\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 1076/2629 [00:09<00:11, 130.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 999/2629 [00:08<00:09, 166.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▉                         | 941/2629 [00:09<00:12, 139.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 1155/2629 [00:09<00:08, 170.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▌                   | 1281/2629 [00:09<00:10, 126.23it/s]\u001b[A\u001b[A\n",
      " 52%|███████████████████▊                  | 1368/2629 [00:09<00:11, 109.00it/s]\u001b[A\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 1092/2629 [00:09<00:11, 137.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 1019/2629 [00:09<00:09, 174.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 1173/2629 [00:09<00:08, 171.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████▏                        | 957/2629 [00:09<00:11, 143.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▋                   | 1295/2629 [00:09<00:11, 116.82it/s]\u001b[A\u001b[A\n",
      " 53%|███████████████████▉                  | 1381/2629 [00:09<00:11, 112.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 1046/2629 [00:09<00:07, 201.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 1192/2629 [00:09<00:08, 177.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▎                   | 1265/2629 [00:09<00:07, 191.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 1107/2629 [00:09<00:12, 118.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▍                   | 1308/2629 [00:09<00:13, 96.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▋                  | 1393/2629 [00:09<00:13, 94.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 1067/2629 [00:09<00:09, 159.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 1210/2629 [00:09<00:10, 141.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▌                      | 1120/2629 [00:09<00:15, 95.73it/s]\u001b[A\u001b[A\u001b[A\n",
      " 54%|████████████████████▎                 | 1408/2629 [00:09<00:11, 104.98it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 1086/2629 [00:09<00:09, 166.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▌                   | 1319/2629 [00:09<00:14, 87.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▌                   | 1285/2629 [00:09<00:10, 124.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▉                         | 985/2629 [00:09<00:19, 84.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 54%|████████████████████▌                 | 1420/2629 [00:09<00:11, 107.55it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▊                      | 1131/2629 [00:09<00:15, 94.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▋                   | 1330/2629 [00:09<00:14, 91.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 1242/2629 [00:09<00:10, 134.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▊                   | 1301/2629 [00:09<00:10, 121.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▏                        | 996/2629 [00:09<00:18, 88.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▉                   | 1343/2629 [00:09<00:12, 99.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 1257/2629 [00:09<00:10, 135.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 1125/2629 [00:09<00:09, 150.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|███████████████████                   | 1316/2629 [00:09<00:11, 117.17it/s]\u001b[A\u001b[A\n",
      " 55%|████████████████████▉                 | 1446/2629 [00:09<00:10, 107.76it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▉                        | 1007/2629 [00:09<00:19, 82.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▍                   | 1272/2629 [00:09<00:09, 138.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▌                     | 1142/2629 [00:09<00:10, 140.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▏                  | 1330/2629 [00:10<00:11, 116.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|████████████████████                   | 1354/2629 [00:10<00:16, 78.77it/s]\u001b[A\u001b[A\u001b[A\n",
      " 55%|█████████████████████                 | 1458/2629 [00:10<00:11, 105.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████                        | 1017/2629 [00:09<00:18, 85.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 1287/2629 [00:10<00:10, 129.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▍                  | 1343/2629 [00:10<00:11, 116.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 1157/2629 [00:10<00:11, 131.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 52%|████████████████████▏                  | 1363/2629 [00:10<00:16, 77.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▏                       | 1027/2629 [00:10<00:18, 86.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|█████████████████▎                     | 1168/2629 [00:10<00:19, 76.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▊                   | 1301/2629 [00:10<00:10, 129.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|███████████████████▌                  | 1356/2629 [00:10<00:10, 118.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 1171/2629 [00:10<00:11, 131.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████▉                 | 1480/2629 [00:10<00:11, 97.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 1317/2629 [00:10<00:09, 136.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▍                     | 1178/2629 [00:10<00:18, 80.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▎                  | 1372/2629 [00:10<00:17, 70.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|███████████████████▊                  | 1369/2629 [00:10<00:10, 119.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 1186/2629 [00:10<00:10, 132.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▍                  | 1381/2629 [00:10<00:16, 74.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▌                       | 1046/2629 [00:10<00:20, 76.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████                 | 1490/2629 [00:10<00:13, 84.96it/s]\u001b[A\n",
      "\n",
      " 53%|███████████████████▉                  | 1382/2629 [00:10<00:10, 121.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 1203/2629 [00:10<00:10, 141.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▌                  | 1389/2629 [00:10<00:17, 69.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▋                       | 1054/2629 [00:10<00:22, 69.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 1349/2629 [00:10<00:11, 111.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████▏                | 1499/2629 [00:10<00:15, 73.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▊                  | 1401/2629 [00:10<00:15, 81.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▋                  | 1395/2629 [00:10<00:13, 94.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▊                       | 1063/2629 [00:10<00:21, 72.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 1363/2629 [00:10<00:10, 117.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████▎                | 1508/2629 [00:10<00:14, 76.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▉                  | 1412/2629 [00:10<00:13, 88.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 1202/2629 [00:10<00:23, 61.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▊                  | 1406/2629 [00:10<00:12, 95.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 1071/2629 [00:10<00:20, 74.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▉                  | 1376/2629 [00:10<00:10, 116.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▌                | 1521/2629 [00:10<00:12, 87.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 1256/2629 [00:10<00:09, 141.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████                  | 1422/2629 [00:10<00:14, 82.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▉                     | 1209/2629 [00:10<00:24, 58.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 1081/2629 [00:10<00:19, 80.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 1391/2629 [00:10<00:10, 122.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▋                | 1532/2629 [00:10<00:11, 92.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 1271/2629 [00:10<00:09, 142.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████▏                 | 1432/2629 [00:11<00:13, 86.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████                     | 1216/2629 [00:10<00:23, 60.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▊                | 1542/2629 [00:11<00:11, 93.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 1286/2629 [00:10<00:09, 143.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▍                 | 1443/2629 [00:11<00:12, 92.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 1432/2629 [00:11<00:07, 160.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▍                      | 1104/2629 [00:11<00:17, 86.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|███████████████████████                | 1553/2629 [00:11<00:11, 95.65it/s]\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 1223/2629 [00:11<00:25, 55.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 1304/2629 [00:11<00:08, 149.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▍                | 1479/2629 [00:11<00:07, 160.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 1453/2629 [00:11<00:06, 171.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▌                      | 1114/2629 [00:11<00:17, 87.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|███████████████████████▏               | 1563/2629 [00:11<00:11, 92.34it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 1323/2629 [00:11<00:08, 160.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 1453/2629 [00:11<00:15, 78.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▊                | 1510/2629 [00:11<00:05, 199.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▋                      | 1123/2629 [00:11<00:17, 84.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 1341/2629 [00:11<00:07, 161.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|███████████████████████▎               | 1573/2629 [00:11<00:12, 87.73it/s]\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▎                    | 1237/2629 [00:11<00:24, 57.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▋                 | 1462/2629 [00:11<00:16, 72.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▊                      | 1133/2629 [00:11<00:17, 87.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 1358/2629 [00:11<00:08, 158.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▌                    | 1248/2629 [00:11<00:20, 68.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▍                | 1487/2629 [00:11<00:08, 141.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████▉                 | 1479/2629 [00:11<00:12, 93.08it/s]\u001b[A\n",
      "\n",
      " 58%|██████████████████████▏               | 1531/2629 [00:11<00:07, 139.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▉                      | 1144/2629 [00:11<00:15, 93.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|██████████████████████                 | 1490/2629 [00:11<00:12, 93.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 1502/2629 [00:11<00:08, 130.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 1375/2629 [00:11<00:09, 128.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████                      | 1154/2629 [00:11<00:16, 91.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▌               | 1591/2629 [00:11<00:15, 65.54it/s]\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▊                    | 1270/2629 [00:11<00:17, 79.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▍               | 1548/2629 [00:11<00:08, 122.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 1518/2629 [00:11<00:08, 137.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▎                     | 1164/2629 [00:11<00:16, 91.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 1389/2629 [00:11<00:09, 125.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████▎                | 1500/2629 [00:11<00:14, 76.65it/s]\u001b[A\n",
      "\n",
      " 60%|██████████████████████▌               | 1565/2629 [00:11<00:08, 128.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▉                    | 1279/2629 [00:11<00:18, 74.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 1533/2629 [00:11<00:08, 127.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▍                     | 1175/2629 [00:11<00:15, 93.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▊               | 1608/2629 [00:11<00:14, 71.65it/s]\u001b[A\n",
      "\n",
      " 60%|██████████████████████▊               | 1580/2629 [00:11<00:07, 132.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████                    | 1289/2629 [00:11<00:17, 78.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 1558/2629 [00:11<00:06, 157.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▍                | 1509/2629 [00:12<00:16, 66.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      " 61%|███████████████████████▉               | 1616/2629 [00:12<00:14, 69.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▌                     | 1185/2629 [00:11<00:17, 82.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▌                | 1517/2629 [00:12<00:19, 58.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 1451/2629 [00:12<00:08, 133.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████▎                   | 1298/2629 [00:12<00:22, 59.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▋                     | 1194/2629 [00:12<00:20, 68.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 1575/2629 [00:12<00:10, 102.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 1202/2629 [00:12<00:20, 69.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████▎                   | 1305/2629 [00:12<00:23, 56.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|██████████████████████▌                | 1524/2629 [00:12<00:20, 53.44it/s]\u001b[A\u001b[A\n",
      " 62%|████████████████████████▏              | 1632/2629 [00:12<00:18, 55.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 1592/2629 [00:12<00:09, 114.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 1467/2629 [00:12<00:10, 108.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████                     | 1215/2629 [00:12<00:16, 83.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 1530/2629 [00:12<00:20, 53.61it/s]\u001b[A\u001b[A\u001b[A\n",
      " 62%|████████████████████████▎              | 1639/2629 [00:12<00:17, 56.60it/s]\u001b[A\n",
      "\n",
      " 62%|████████████████████████▏              | 1629/2629 [00:12<00:10, 95.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 1607/2629 [00:12<00:08, 115.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▊                   | 1332/2629 [00:12<00:15, 85.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 1227/2629 [00:12<00:15, 91.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▊                | 1536/2629 [00:12<00:20, 53.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▍              | 1646/2629 [00:12<00:18, 53.24it/s]\u001b[A\n",
      "\n",
      " 62%|████████████████████████▎              | 1641/2629 [00:12<00:11, 89.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 1240/2629 [00:12<00:13, 100.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▉                | 1544/2629 [00:12<00:20, 54.12it/s]\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▌              | 1653/2629 [00:12<00:17, 56.44it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▏                | 1492/2629 [00:12<00:12, 93.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|████████████████████████▌              | 1653/2629 [00:12<00:10, 94.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████                    | 1251/2629 [00:12<00:13, 100.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|████████████████████                   | 1353/2629 [00:12<00:14, 90.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████                | 1554/2629 [00:12<00:16, 63.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▋              | 1660/2629 [00:12<00:16, 59.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 1264/2629 [00:12<00:12, 106.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|██████████████████████▎                | 1503/2629 [00:12<00:12, 93.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▏              | 1633/2629 [00:12<00:10, 93.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|███████████████████████▏               | 1562/2629 [00:13<00:16, 66.52it/s]\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▊              | 1672/2629 [00:13<00:12, 74.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▍                   | 1275/2629 [00:12<00:12, 106.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▊              | 1676/2629 [00:13<00:09, 97.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 1648/2629 [00:12<00:09, 104.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▍                | 1513/2629 [00:12<00:12, 86.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|████████████████████▎                  | 1372/2629 [00:13<00:16, 77.17it/s]\u001b[A\u001b[A\u001b[A\n",
      " 64%|█████████████████████████              | 1687/2629 [00:13<00:10, 91.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 1287/2629 [00:13<00:12, 109.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 1674/2629 [00:13<00:06, 139.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|█████████████████████████              | 1687/2629 [00:13<00:10, 91.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▌                | 1523/2629 [00:13<00:13, 81.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|█████████████████████████▏             | 1698/2629 [00:13<00:09, 94.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▍               | 1579/2629 [00:13<00:16, 65.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 1699/2629 [00:13<00:05, 165.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▍                  | 1381/2629 [00:13<00:18, 67.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|█████████████████████████▏             | 1697/2629 [00:13<00:11, 84.17it/s]\u001b[A\u001b[A\n",
      " 65%|████████████████████████▋             | 1710/2629 [00:13<00:09, 101.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 1532/2629 [00:13<00:13, 78.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▌               | 1586/2629 [00:13<00:17, 59.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 1718/2629 [00:13<00:05, 152.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|████████████████████████▉             | 1729/2629 [00:13<00:07, 122.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▊                | 1541/2629 [00:13<00:13, 79.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▌                  | 1389/2629 [00:13<00:20, 61.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 1335/2629 [00:13<00:10, 128.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|█████████████████████████▎             | 1706/2629 [00:13<00:12, 72.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▋               | 1593/2629 [00:13<00:17, 58.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|█████████████████████████▎            | 1750/2629 [00:13<00:05, 146.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████                | 1554/2629 [00:13<00:11, 90.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▋                  | 1398/2629 [00:13<00:18, 66.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 1358/2629 [00:13<00:08, 155.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|█████████████████████████▍             | 1716/2629 [00:13<00:11, 78.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▊               | 1603/2629 [00:13<00:15, 67.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|█████████████████████████▌            | 1770/2629 [00:13<00:05, 159.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 1568/2629 [00:13<00:10, 102.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▉                  | 1409/2629 [00:13<00:16, 76.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 1375/2629 [00:13<00:07, 159.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▌             | 1725/2629 [00:13<00:11, 80.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▉               | 1611/2629 [00:13<00:15, 67.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▍               | 1579/2629 [00:13<00:10, 97.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▊            | 1787/2629 [00:13<00:05, 145.51it/s]\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████                  | 1418/2629 [00:13<00:15, 75.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 1392/2629 [00:13<00:07, 158.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|████████████████████████               | 1618/2629 [00:13<00:16, 62.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████▏                 | 1426/2629 [00:13<00:16, 72.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████            | 1807/2629 [00:13<00:05, 151.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 69%|██████████████████████████            | 1802/2629 [00:13<00:06, 128.90it/s]\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▊             | 1743/2629 [00:13<00:11, 78.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 1409/2629 [00:13<00:08, 137.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▎                 | 1436/2629 [00:13<00:14, 79.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▋               | 1600/2629 [00:13<00:11, 90.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▍           | 1825/2629 [00:13<00:05, 155.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|█████████████████████████▉             | 1752/2629 [00:14<00:11, 73.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 1424/2629 [00:13<00:09, 132.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|████████████████████████▎              | 1638/2629 [00:14<00:13, 76.03it/s]\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▍                 | 1448/2629 [00:14<00:13, 88.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 1843/2629 [00:14<00:04, 158.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▉               | 1610/2629 [00:14<00:11, 87.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▏            | 1768/2629 [00:14<00:09, 93.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 1446/2629 [00:14<00:07, 152.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▌              | 1652/2629 [00:14<00:10, 92.24it/s]\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 1467/2629 [00:14<00:10, 114.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 1626/2629 [00:14<00:09, 106.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 1868/2629 [00:14<00:04, 177.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 1467/2629 [00:14<00:06, 167.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▊            | 1788/2629 [00:14<00:07, 118.95it/s]\u001b[A\u001b[A\n",
      " 63%|████████████████████████              | 1669/2629 [00:14<00:08, 111.41it/s]\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 1491/2629 [00:14<00:07, 145.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 1651/2629 [00:14<00:06, 143.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 1891/2629 [00:14<00:03, 188.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 1485/2629 [00:14<00:06, 169.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|██████████████████████████▊           | 1856/2629 [00:14<00:06, 124.97it/s]\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 1508/2629 [00:14<00:07, 151.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████            | 1801/2629 [00:14<00:07, 109.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 1681/2629 [00:14<00:09, 102.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▌          | 1911/2629 [00:14<00:04, 172.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 1503/2629 [00:14<00:06, 166.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 1525/2629 [00:14<00:07, 155.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▎           | 1820/2629 [00:14<00:06, 128.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 1693/2629 [00:14<00:08, 105.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|███████████████████████████           | 1869/2629 [00:14<00:07, 108.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▉          | 1930/2629 [00:14<00:04, 166.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 1541/2629 [00:14<00:07, 151.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 1520/2629 [00:14<00:07, 146.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 72%|███████████████████████████▏          | 1881/2629 [00:14<00:06, 109.53it/s]\u001b[A\n",
      "\n",
      " 70%|██████████████████████████▌           | 1834/2629 [00:14<00:06, 118.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▎             | 1704/2629 [00:14<00:09, 98.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 1948/2629 [00:14<00:04, 164.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 1557/2629 [00:14<00:07, 144.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████▋           | 1847/2629 [00:14<00:06, 118.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 1536/2629 [00:14<00:07, 137.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▍             | 1715/2629 [00:14<00:12, 73.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 1965/2629 [00:14<00:05, 122.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████████████████████████▌           | 1860/2629 [00:14<00:08, 95.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 1551/2629 [00:14<00:09, 109.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|████████████████████████████▎          | 1909/2629 [00:15<00:08, 86.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 1738/2629 [00:14<00:08, 104.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|███████████████████████▎               | 1572/2629 [00:15<00:11, 93.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 1979/2629 [00:15<00:05, 118.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▌             | 1724/2629 [00:15<00:13, 67.57it/s]\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▊          | 1925/2629 [00:15<00:06, 101.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 1564/2629 [00:15<00:10, 106.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 1751/2629 [00:15<00:08, 105.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 1996/2629 [00:15<00:04, 127.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████████████████████████▉           | 1882/2629 [00:15<00:07, 97.51it/s]\u001b[A\u001b[A\n",
      " 74%|███████████████████████████▉          | 1937/2629 [00:15<00:06, 103.47it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 1578/2629 [00:15<00:09, 112.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▋             | 1732/2629 [00:15<00:14, 60.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 2014/2629 [00:15<00:04, 137.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▏            | 1763/2629 [00:15<00:08, 99.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 1593/2629 [00:15<00:08, 121.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▏         | 1949/2629 [00:15<00:06, 106.38it/s]\u001b[A\n",
      "\n",
      " 72%|████████████████████████████           | 1893/2629 [00:15<00:08, 88.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▊             | 1739/2629 [00:15<00:15, 59.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 1609/2629 [00:15<00:07, 129.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 1963/2629 [00:15<00:05, 112.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|████████████████████████████▏          | 1903/2629 [00:15<00:08, 88.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▊               | 1607/2629 [00:15<00:11, 89.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▉             | 1746/2629 [00:15<00:14, 59.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 1787/2629 [00:15<00:07, 105.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 1627/2629 [00:15<00:07, 142.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▌         | 1980/2629 [00:15<00:05, 122.50it/s]\u001b[A\n",
      "\n",
      " 73%|████████████████████████████▍          | 1914/2629 [00:15<00:07, 90.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████████████████████████             | 1755/2629 [00:15<00:13, 65.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 2073/2629 [00:15<00:03, 159.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 1642/2629 [00:15<00:06, 142.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▉         | 2001/2629 [00:15<00:04, 140.87it/s]\u001b[A\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 1639/2629 [00:15<00:08, 120.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▏            | 1764/2629 [00:15<00:12, 71.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 1815/2629 [00:15<00:06, 120.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 2097/2629 [00:15<00:02, 179.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 1657/2629 [00:15<00:06, 140.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▏        | 2019/2629 [00:15<00:04, 148.85it/s]\u001b[A\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 1655/2629 [00:15<00:07, 126.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████████████████████████▍            | 1779/2629 [00:15<00:09, 91.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▌       | 2118/2629 [00:15<00:02, 183.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 1828/2629 [00:15<00:07, 113.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▌            | 1789/2629 [00:15<00:09, 92.40it/s]\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▍        | 2035/2629 [00:15<00:04, 133.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 1672/2629 [00:15<00:08, 112.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▊          | 1946/2629 [00:15<00:08, 83.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 2137/2629 [00:15<00:02, 173.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 1840/2629 [00:15<00:07, 103.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 1685/2629 [00:15<00:07, 130.84it/s]\u001b[A\u001b[A\u001b[A\n",
      " 69%|██████████████████████████▋            | 1802/2629 [00:16<00:08, 99.11it/s]\u001b[A\n",
      "\n",
      " 74%|█████████████████████████████          | 1955/2629 [00:16<00:08, 83.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 1685/2629 [00:15<00:08, 109.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 2155/2629 [00:16<00:02, 158.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 1857/2629 [00:16<00:06, 116.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 1816/2629 [00:16<00:07, 106.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████▏         | 1964/2629 [00:16<00:07, 84.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 1700/2629 [00:16<00:07, 118.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 2172/2629 [00:16<00:02, 161.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 1871/2629 [00:16<00:06, 122.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 79%|█████████████████████████████▉        | 2075/2629 [00:16<00:04, 124.45it/s]\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 1828/2629 [00:16<00:07, 109.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████▎         | 1975/2629 [00:16<00:07, 89.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 1713/2629 [00:16<00:08, 111.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 2192/2629 [00:16<00:02, 169.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 1889/2629 [00:16<00:05, 138.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▏       | 2092/2629 [00:16<00:03, 134.42it/s]\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 1847/2629 [00:16<00:05, 130.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████▊         | 1992/2629 [00:16<00:05, 110.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 1726/2629 [00:16<00:07, 114.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▌          | 1904/2629 [00:16<00:05, 127.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|██████████████████████████▉           | 1861/2629 [00:16<00:06, 124.94it/s]\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 1750/2629 [00:16<00:06, 128.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 2210/2629 [00:16<00:02, 141.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████▉         | 2004/2629 [00:16<00:06, 100.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 1738/2629 [00:16<00:07, 113.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▋       | 2121/2629 [00:16<00:03, 129.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 1918/2629 [00:16<00:05, 124.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 2228/2629 [00:16<00:02, 149.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 1874/2629 [00:16<00:06, 115.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▏        | 2016/2629 [00:16<00:05, 104.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 1752/2629 [00:16<00:07, 117.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▉          | 1932/2629 [00:16<00:05, 124.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▊       | 2135/2629 [00:16<00:04, 120.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 2244/2629 [00:16<00:02, 133.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▋            | 1778/2629 [00:16<00:07, 113.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|██████████████████████████████         | 2027/2629 [00:16<00:07, 78.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▉           | 1886/2629 [00:16<00:08, 83.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 1945/2629 [00:16<00:06, 104.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 2259/2629 [00:16<00:02, 128.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 1790/2629 [00:16<00:08, 103.08it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▊       | 2148/2629 [00:16<00:05, 96.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 1896/2629 [00:17<00:08, 85.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 2280/2629 [00:16<00:02, 147.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|██████████████████████████████▏        | 2036/2629 [00:16<00:07, 75.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▎         | 1957/2629 [00:16<00:06, 100.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▏      | 2162/2629 [00:17<00:04, 105.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 1910/2629 [00:17<00:07, 97.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▋            | 1801/2629 [00:17<00:09, 89.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 2298/2629 [00:17<00:02, 153.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|██████████████████████████████▎        | 2045/2629 [00:17<00:07, 77.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▏         | 1968/2629 [00:17<00:07, 93.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▊          | 1923/2629 [00:17<00:06, 104.95it/s]\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 1819/2629 [00:17<00:07, 108.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|██████████████████████████████▌        | 2058/2629 [00:17<00:06, 87.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 2314/2629 [00:17<00:02, 144.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▋            | 1801/2629 [00:17<00:09, 89.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▌      | 2187/2629 [00:17<00:04, 106.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████▉          | 1937/2629 [00:17<00:06, 113.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 1835/2629 [00:17<00:06, 120.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▋        | 2071/2629 [00:17<00:05, 95.49it/s]\u001b[A\u001b[A\n",
      " 84%|███████████████████████████████▊      | 2205/2629 [00:17<00:03, 123.16it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 2329/2629 [00:17<00:02, 127.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 1950/2629 [00:17<00:06, 112.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▊        | 2081/2629 [00:17<00:05, 94.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 1811/2629 [00:17<00:10, 75.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▍         | 1988/2629 [00:17<00:08, 74.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▏     | 2227/2629 [00:17<00:02, 147.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 2346/2629 [00:17<00:02, 136.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 1962/2629 [00:17<00:05, 111.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▌         | 1996/2629 [00:17<00:08, 73.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████████████████████████████        | 2091/2629 [00:17<00:06, 82.92it/s]\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▍     | 2243/2629 [00:17<00:02, 143.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▉            | 1820/2629 [00:17<00:11, 69.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 1974/2629 [00:17<00:06, 101.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 2361/2629 [00:17<00:02, 109.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▋         | 2004/2629 [00:17<00:08, 73.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████            | 1828/2629 [00:17<00:11, 68.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▋         | 1987/2629 [00:17<00:06, 105.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 2374/2629 [00:17<00:02, 108.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▊         | 2012/2629 [00:17<00:08, 70.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████████████████████████████▏       | 2100/2629 [00:17<00:08, 63.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 1897/2629 [00:17<00:06, 105.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▏           | 1836/2629 [00:17<00:12, 65.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▉         | 2001/2629 [00:17<00:05, 111.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 2386/2629 [00:17<00:02, 108.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▌          | 1909/2629 [00:17<00:06, 108.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▉         | 2020/2629 [00:17<00:08, 69.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▏        | 2018/2629 [00:18<00:04, 126.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▎           | 1845/2629 [00:17<00:11, 68.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 2398/2629 [00:17<00:02, 102.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|███████████████████████████████▍       | 2117/2629 [00:18<00:07, 66.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 2033/2629 [00:18<00:04, 131.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 1854/2629 [00:18<00:10, 72.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▍          | 1921/2629 [00:18<00:07, 90.92it/s]\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████▉     | 2289/2629 [00:18<00:03, 92.53it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 2410/2629 [00:18<00:02, 105.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2125/2629 [00:18<00:07, 67.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████▏        | 2035/2629 [00:18<00:09, 65.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 1862/2629 [00:18<00:10, 72.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▋          | 1932/2629 [00:18<00:07, 90.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 2425/2629 [00:18<00:01, 116.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|███████████████████████████████▋       | 2133/2629 [00:18<00:07, 68.64it/s]\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▎        | 2047/2629 [00:18<00:06, 92.57it/s]\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 1943/2629 [00:18<00:07, 94.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 2042/2629 [00:18<00:10, 55.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 1870/2629 [00:18<00:12, 61.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 1959/2629 [00:18<00:06, 110.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|███████████████████████████████▊       | 2141/2629 [00:18<00:07, 61.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 2049/2629 [00:18<00:10, 57.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▏  | 2438/2629 [00:18<00:02, 90.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▊           | 1878/2629 [00:18<00:11, 63.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|██████████████████████████████▌        | 2058/2629 [00:18<00:07, 79.88it/s]\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 1975/2629 [00:18<00:05, 122.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████▉       | 2149/2629 [00:18<00:07, 64.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 2055/2629 [00:18<00:10, 55.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 1897/2629 [00:18<00:08, 91.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▎  | 2449/2629 [00:18<00:02, 85.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 2330/2629 [00:18<00:03, 93.19it/s]\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 1995/2629 [00:18<00:04, 143.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████▉       | 2157/2629 [00:18<00:06, 68.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 2068/2629 [00:18<00:08, 70.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 1907/2629 [00:18<00:08, 87.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▍  | 2459/2629 [00:18<00:01, 85.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 2343/2629 [00:18<00:02, 100.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████████████████████████████       | 2165/2629 [00:18<00:06, 69.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 2072/2629 [00:18<00:08, 65.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 2077/2629 [00:18<00:08, 67.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▉    | 2355/2629 [00:18<00:02, 94.91it/s]\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 2028/2629 [00:18<00:04, 132.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 2080/2629 [00:18<00:07, 69.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████████████████████████████▏      | 2173/2629 [00:18<00:07, 62.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████▉          | 1933/2629 [00:18<00:06, 105.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 2469/2629 [00:18<00:02, 70.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|███████████████████████████████████    | 2366/2629 [00:19<00:02, 96.76it/s]\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▉        | 2085/2629 [00:19<00:08, 61.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▉        | 2088/2629 [00:19<00:08, 65.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 1944/2629 [00:19<00:07, 89.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|███████████████████████████████        | 2093/2629 [00:19<00:08, 64.14it/s]\u001b[A\n",
      "\n",
      " 83%|████████████████████████████████▎      | 2180/2629 [00:19<00:09, 47.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 2477/2629 [00:19<00:02, 58.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▊        | 2060/2629 [00:19<00:05, 112.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████          | 1957/2629 [00:19<00:06, 99.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▏       | 2103/2629 [00:19<00:07, 71.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|██████████████████████████████████▌   | 2393/2629 [00:19<00:02, 101.71it/s]\u001b[A\n",
      "\n",
      " 83%|████████████████████████████████▌      | 2191/2629 [00:19<00:07, 59.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▊  | 2484/2629 [00:19<00:02, 58.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 1969/2629 [00:19<00:06, 103.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▏       | 2106/2629 [00:19<00:08, 65.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 2118/2629 [00:19<00:05, 90.29it/s]\u001b[A\u001b[A\u001b[A\n",
      " 92%|██████████████████████████████████▊   | 2410/2629 [00:19<00:01, 118.20it/s]\u001b[A\n",
      "\n",
      " 84%|████████████████████████████████▋      | 2200/2629 [00:19<00:06, 64.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 2496/2629 [00:19<00:01, 70.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 1984/2629 [00:19<00:05, 115.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▉       | 2139/2629 [00:19<00:04, 120.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▎       | 2114/2629 [00:19<00:07, 64.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 2085/2629 [00:19<00:05, 101.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████████████████████████████▊      | 2209/2629 [00:19<00:06, 69.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 2507/2629 [00:19<00:01, 77.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 1997/2629 [00:19<00:05, 112.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▏      | 2156/2629 [00:19<00:03, 127.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2126/2629 [00:19<00:06, 75.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 2098/2629 [00:19<00:05, 106.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████████████████████████████▉      | 2221/2629 [00:19<00:05, 80.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 2516/2629 [00:19<00:01, 74.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████         | 2009/2629 [00:19<00:06, 101.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 2135/2629 [00:19<00:06, 77.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▍  | 2450/2629 [00:19<00:01, 110.16it/s]\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████      | 2230/2629 [00:19<00:05, 79.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▎       | 2110/2629 [00:19<00:05, 98.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▎      | 2170/2629 [00:19<00:04, 103.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 2025/2629 [00:19<00:05, 113.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▊       | 2145/2629 [00:19<00:05, 81.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▌  | 2462/2629 [00:19<00:01, 106.46it/s]\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 2239/2629 [00:19<00:05, 77.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 2121/2629 [00:19<00:05, 94.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 2532/2629 [00:19<00:01, 68.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 2041/2629 [00:19<00:04, 125.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▎      | 2182/2629 [00:19<00:04, 91.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 2250/2629 [00:19<00:04, 83.28it/s]\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▊  | 2474/2629 [00:19<00:01, 101.18it/s]\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2131/2629 [00:19<00:05, 92.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 2543/2629 [00:19<00:01, 76.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 2172/2629 [00:19<00:04, 100.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▌      | 2194/2629 [00:20<00:04, 96.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▌     | 2260/2629 [00:20<00:04, 86.69it/s]\u001b[A\u001b[A\n",
      " 95%|███████████████████████████████████▉  | 2489/2629 [00:20<00:01, 113.35it/s]\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 2149/2629 [00:20<00:04, 114.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 2553/2629 [00:20<00:00, 81.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 2210/2629 [00:20<00:03, 108.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 2269/2629 [00:20<00:04, 84.38it/s]\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▏ | 2501/2629 [00:20<00:01, 112.16it/s]\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 2161/2629 [00:20<00:04, 110.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 2066/2629 [00:20<00:05, 99.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|██████████████████████████████████████ | 2563/2629 [00:20<00:00, 83.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 2224/2629 [00:20<00:03, 115.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████▊     | 2278/2629 [00:20<00:04, 83.75it/s]\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▍ | 2519/2629 [00:20<00:00, 129.55it/s]\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 2180/2629 [00:20<00:03, 130.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▏| 2573/2629 [00:20<00:00, 86.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 2077/2629 [00:20<00:05, 92.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 2287/2629 [00:20<00:04, 83.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 2204/2629 [00:20<00:04, 89.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▌ | 2533/2629 [00:20<00:00, 127.40it/s]\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 2237/2629 [00:20<00:03, 103.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 2092/2629 [00:20<00:05, 104.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▎| 2585/2629 [00:20<00:00, 89.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|██████████████████████████████████     | 2299/2629 [00:20<00:03, 92.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 2214/2629 [00:20<00:04, 90.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|████████████████████████████████████▊ | 2547/2629 [00:20<00:00, 127.91it/s]\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 2258/2629 [00:20<00:02, 128.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 2103/2629 [00:20<00:05, 104.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 2597/2629 [00:20<00:00, 96.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 2313/2629 [00:20<00:03, 105.32it/s]\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████ | 2568/2629 [00:20<00:00, 149.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 2278/2629 [00:20<00:02, 144.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 2228/2629 [00:20<00:02, 134.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 2607/2629 [00:20<00:00, 96.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 2116/2629 [00:20<00:04, 104.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 2327/2629 [00:20<00:02, 114.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 2243/2629 [00:20<00:03, 112.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████▏    | 2294/2629 [00:20<00:02, 143.78it/s]\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 2242/2629 [00:20<00:02, 131.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 2339/2629 [00:20<00:02, 114.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████▊| 2617/2629 [00:20<00:00, 86.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 2255/2629 [00:20<00:03, 105.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 2256/2629 [00:20<00:02, 133.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2127/2629 [00:20<00:05, 84.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▎    | 2309/2629 [00:20<00:02, 131.37it/s]\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 2352/2629 [00:20<00:02, 119.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████▉| 2626/2629 [00:20<00:00, 83.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:20<00:00, 125.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 2325/2629 [00:21<00:02, 137.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 2367/2629 [00:21<00:02, 127.53it/s]\u001b[A\u001b[A\n",
      " 99%|█████████████████████████████████████▊| 2615/2629 [00:21<00:00, 119.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 2137/2629 [00:20<00:06, 76.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 2279/2629 [00:20<00:03, 109.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:21<00:00, 124.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 2382/2629 [00:21<00:01, 132.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▊       | 2147/2629 [00:21<00:05, 81.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████     | 2291/2629 [00:21<00:03, 107.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 2296/2629 [00:21<00:02, 118.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 2398/2629 [00:21<00:01, 138.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 2160/2629 [00:21<00:05, 92.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 2361/2629 [00:21<00:02, 122.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 2412/2629 [00:21<00:01, 133.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 2308/2629 [00:21<00:03, 106.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▏      | 2170/2629 [00:21<00:04, 91.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 2383/2629 [00:21<00:01, 145.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 2319/2629 [00:21<00:02, 107.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 2184/2629 [00:21<00:04, 104.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|███████████████████████████████████   | 2426/2629 [00:21<00:01, 117.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 2401/2629 [00:21<00:01, 151.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 2330/2629 [00:21<00:02, 103.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 2418/2629 [00:21<00:01, 147.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▌      | 2195/2629 [00:21<00:05, 82.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 2434/2629 [00:21<00:01, 144.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 2341/2629 [00:21<00:03, 81.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▉    | 2359/2629 [00:21<00:02, 92.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 2449/2629 [00:21<00:01, 134.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▉    | 2352/2629 [00:21<00:03, 85.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████████▎  | 2450/2629 [00:21<00:02, 79.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 2372/2629 [00:21<00:02, 100.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 2214/2629 [00:21<00:06, 68.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 2463/2629 [00:22<00:01, 127.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████████▍  | 2459/2629 [00:22<00:02, 78.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 2384/2629 [00:22<00:02, 113.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 2477/2629 [00:22<00:01, 123.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 2383/2629 [00:22<00:03, 81.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████████▌  | 2468/2629 [00:22<00:02, 77.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 2240/2629 [00:22<00:04, 90.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 2396/2629 [00:22<00:02, 112.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|████████████████████████████████████▊  | 2478/2629 [00:22<00:01, 82.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 2490/2629 [00:22<00:01, 109.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 2251/2629 [00:22<00:04, 94.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 2409/2629 [00:22<00:01, 114.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 2487/2629 [00:22<00:01, 79.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 2502/2629 [00:22<00:01, 108.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 2271/2629 [00:22<00:02, 121.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 2429/2629 [00:22<00:01, 135.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████████████████████████████████  | 2500/2629 [00:22<00:01, 92.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 2518/2629 [00:22<00:00, 120.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 2293/2629 [00:22<00:02, 147.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 2449/2629 [00:22<00:01, 149.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 2513/2629 [00:22<00:01, 101.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▋ | 2534/2629 [00:22<00:00, 127.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 2313/2629 [00:22<00:01, 162.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 2472/2629 [00:22<00:00, 170.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 2532/2629 [00:22<00:00, 122.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 2441/2629 [00:22<00:01, 101.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 2548/2629 [00:22<00:00, 122.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 2490/2629 [00:22<00:00, 172.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 2548/2629 [00:22<00:00, 132.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 2453/2629 [00:22<00:01, 103.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████ | 2561/2629 [00:22<00:00, 122.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▎ | 2509/2629 [00:22<00:00, 175.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████ | 2567/2629 [00:22<00:00, 145.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 2467/2629 [00:22<00:01, 112.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 2575/2629 [00:22<00:00, 124.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 2527/2629 [00:22<00:00, 170.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 2582/2629 [00:23<00:00, 142.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 2394/2629 [00:22<00:01, 189.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 2592/2629 [00:23<00:00, 136.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 2548/2629 [00:23<00:00, 180.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 2490/2629 [00:23<00:01, 100.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 2597/2629 [00:23<00:00, 118.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 2606/2629 [00:23<00:00, 113.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 2585/2629 [00:23<00:00, 166.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 2433/2629 [00:23<00:01, 165.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 2610/2629 [00:23<00:00, 104.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▊| 2619/2629 [00:23<00:00, 105.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 2602/2629 [00:23<00:00, 160.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:23<00:00, 111.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████▉| 2622/2629 [00:23<00:00, 94.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▉| 2621/2629 [00:23<00:00, 165.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▏ | 2511/2629 [00:23<00:01, 72.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:23<00:00, 111.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:23<00:00, 111.43it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 2519/2629 [00:23<00:01, 64.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 2481/2629 [00:23<00:01, 128.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 2495/2629 [00:23<00:01, 122.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 2526/2629 [00:23<00:01, 57.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 2523/2629 [00:23<00:00, 160.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 2537/2629 [00:23<00:01, 68.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 2549/2629 [00:23<00:00, 185.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▊ | 2548/2629 [00:23<00:01, 76.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 2573/2629 [00:24<00:00, 196.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 2574/2629 [00:24<00:00, 120.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 2596/2629 [00:24<00:00, 144.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 2594/2629 [00:24<00:00, 186.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▊| 2612/2629 [00:24<00:00, 142.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:24<00:00, 107.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:24<00:00, 107.58it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_abolish.tsv\n",
      "Processing Started...\n",
      "Data Size:  281\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 15/40 [00:00<00:00, 144.89it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 38%|███████████████▊                          | 15/40 [00:00<00:00, 134.56it/s]\u001b[A\n",
      "\n",
      " 45%|██████████████████▉                       | 18/40 [00:00<00:00, 178.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|█████████████▋                            | 13/40 [00:00<00:00, 121.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▌        | 32/40 [00:00<00:00, 155.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 15/40 [00:00<00:00, 148.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|███████████████████▉                      | 19/40 [00:00<00:00, 184.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████████▊   | 37/40 [00:00<00:00, 182.46it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 152.28it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 185.46it/s]\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▍            | 28/40 [00:00<00:00, 134.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████▊     | 35/40 [00:00<00:00, 177.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 199.87it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 172.78it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 115.30it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 123.30it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_abolish.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_abolish.tsv\n",
      "Processing Started...\n",
      "Data Size:  283\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 18%|███████▋                                    | 7/40 [00:00<00:00, 62.75it/s]\n",
      " 35%|██████████████▋                           | 14/40 [00:00<00:00, 133.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▋                                    | 7/40 [00:00<00:00, 68.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|███████████▊                               | 11/40 [00:00<00:00, 87.71it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 40%|█████████████████▏                         | 16/40 [00:00<00:00, 71.88it/s]\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████▌                                     | 6/40 [00:00<00:00, 54.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|█████████████████████████████▍            | 28/40 [00:00<00:00, 111.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▊                               | 11/40 [00:00<00:00, 91.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|███████████████                            | 14/40 [00:00<00:00, 66.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████████████████████████▊                 | 24/40 [00:00<00:00, 72.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████▎                        | 17/40 [00:00<00:00, 84.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|██████████████████████▌                    | 21/40 [00:00<00:00, 93.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████▎                        | 17/40 [00:00<00:00, 80.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████████▍       | 33/40 [00:00<00:00, 95.65it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 99.42it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 100.62it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████              | 27/40 [00:00<00:00, 86.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 101.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 109.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 73.68it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 91.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 94.24it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_abolish.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_alter.tsv\n",
      "Processing Started...\n",
      "Data Size:  254\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 50%|█████████████████████                     | 18/36 [00:00<00:00, 166.58it/s]\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 18/36 [00:00<00:00, 170.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|███████████                                 | 9/36 [00:00<00:00, 89.97it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|███████████                                 | 9/36 [00:00<00:00, 82.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▉                               | 10/36 [00:00<00:00, 90.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▎                                    | 6/36 [00:00<00:00, 54.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 136.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 18/36 [00:00<00:00, 78.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████▌                 | 21/36 [00:00<00:00, 102.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 139.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 120.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|█████████████████▉                         | 15/36 [00:00<00:00, 70.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████▎          | 27/36 [00:00<00:00, 79.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 104.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████▊       | 30/36 [00:00<00:00, 84.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 36/36 [00:00<00:00, 83.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 36/36 [00:00<00:00, 89.85it/s]\n",
      "100%|███████████████████████████████████████████| 36/36 [00:00<00:00, 92.64it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_alter.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_alter.tsv\n",
      "Processing Started...\n",
      "Data Size:  255\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▉                               | 10/36 [00:00<00:00, 99.01it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 47%|███████████████████▊                      | 17/36 [00:00<00:00, 164.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|██████████████████▋                       | 16/36 [00:00<00:00, 152.92it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 75%|███████████████████████████████▌          | 27/36 [00:00<00:00, 135.69it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 53%|██████████████████████▏                   | 19/36 [00:00<00:00, 168.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 168.95it/s]\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████▊                      | 17/36 [00:00<00:00, 152.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 166.38it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 136.75it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▎                         | 14/36 [00:00<00:00, 139.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 162.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 183.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 164.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 155.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_alter.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_begin.tsv\n",
      "Processing Started...\n",
      "Data Size:  683\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████▍                                   | 15/97 [00:00<00:00, 149.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 20%|████████▏                                 | 19/97 [00:00<00:00, 183.42it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 14%|██████                                    | 14/97 [00:00<00:00, 138.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▊                                  | 18/97 [00:00<00:00, 168.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▋                                    | 13/97 [00:00<00:00, 120.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████▊                            | 32/97 [00:00<00:00, 161.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▊                                  | 18/97 [00:00<00:00, 177.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 34%|██████████████▎                           | 33/97 [00:00<00:00, 163.38it/s]\u001b[A\u001b[A\n",
      " 39%|████████████████▍                         | 38/97 [00:00<00:00, 155.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|██████████████████████▌                   | 52/97 [00:00<00:00, 176.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███████████████▏                          | 35/97 [00:00<00:00, 140.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▎                        | 40/97 [00:00<00:00, 201.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|██████████████████████                    | 51/97 [00:00<00:00, 169.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▏                       | 42/97 [00:00<00:00, 148.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|███████████████████████▍                  | 54/97 [00:00<00:00, 136.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▍                         | 38/97 [00:00<00:00, 114.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████▎           | 70/97 [00:00<00:00, 167.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▍               | 61/97 [00:00<00:00, 171.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|█████████████████████████████▍            | 68/97 [00:00<00:00, 144.38it/s]\u001b[A\u001b[A\n",
      " 70%|█████████████████████████████▍            | 68/97 [00:00<00:00, 131.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████                 | 58/97 [00:00<00:00, 133.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▋                    | 50/97 [00:00<00:00, 111.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████▋    | 87/97 [00:00<00:00, 157.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 163.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████    | 88/97 [00:00<00:00, 160.43it/s]\u001b[A\u001b[A\n",
      " 85%|███████████████████████████████████▌      | 82/97 [00:00<00:00, 132.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████████████████████████▊               | 62/97 [00:00<00:00, 109.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 162.43it/s]\n",
      " 74%|███████████████████████████████▏          | 72/97 [00:00<00:00, 123.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 176.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████████████████████████████████████▌| 96/97 [00:00<00:00, 126.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 134.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 141.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 136.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 131.03it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_begin.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_begin.tsv\n",
      "Processing Started...\n",
      "Data Size:  684\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▌                                | 22/97 [00:00<00:00, 204.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▊                                  | 18/97 [00:00<00:00, 177.95it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 19%|███████▊                                  | 18/97 [00:00<00:00, 179.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|██████                                    | 14/97 [00:00<00:00, 132.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▉                                   | 16/97 [00:00<00:00, 150.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▋                                    | 13/97 [00:00<00:00, 124.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▋                                 | 20/97 [00:00<00:00, 196.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|████████████████▍                         | 38/97 [00:00<00:00, 187.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|████████████▌                             | 29/97 [00:00<00:00, 141.92it/s]\u001b[A\u001b[A\u001b[A\n",
      " 44%|██████████████████▌                       | 43/97 [00:00<00:00, 166.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▏                          | 35/97 [00:00<00:00, 165.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████                              | 28/97 [00:00<00:00, 138.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▎                        | 40/97 [00:00<00:00, 176.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████████████████████▏                    | 49/97 [00:00<00:00, 166.33it/s]\u001b[A\u001b[A\u001b[A\n",
      " 56%|███████████████████████▍                  | 54/97 [00:00<00:00, 154.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▍               | 61/97 [00:00<00:00, 164.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|████████████████████████▋                 | 57/97 [00:00<00:00, 161.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████▉                      | 46/97 [00:00<00:00, 148.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████                 | 58/97 [00:00<00:00, 165.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 72%|██████████████████████████████▎           | 70/97 [00:00<00:00, 150.36it/s]\u001b[A\n",
      "\n",
      "\n",
      " 68%|████████████████████████████▌             | 66/97 [00:00<00:00, 148.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████████          | 74/97 [00:00<00:00, 154.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 78/97 [00:00<00:00, 143.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▍               | 61/97 [00:00<00:00, 136.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 78/97 [00:00<00:00, 176.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████████▏| 95/97 [00:00<00:00, 168.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 177.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████████▏    | 86/97 [00:00<00:00, 139.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 167.14it/s]\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████████▎ | 93/97 [00:00<00:00, 144.48it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 181.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 148.76it/s]\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 144.42it/s]\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 148.95it/s]\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 147.80it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_begin.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_block.tsv\n",
      "Processing Started...\n",
      "Data Size:  362\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 22%|█████████                                 | 11/51 [00:00<00:00, 104.55it/s]\n",
      " 24%|█████████▉                                | 12/51 [00:00<00:00, 106.94it/s]\u001b[A\n",
      "\n",
      " 24%|█████████▉                                | 12/51 [00:00<00:00, 113.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 15/51 [00:00<00:00, 145.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▌                              | 14/51 [00:00<00:00, 137.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▌                              | 14/51 [00:00<00:00, 134.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████▊                      | 24/51 [00:00<00:00, 110.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 47%|███████████████████▊                      | 24/51 [00:00<00:00, 112.41it/s]\u001b[A\n",
      "\n",
      "\n",
      " 59%|████████████████████████▋                 | 30/51 [00:00<00:00, 139.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|████████████████████▏                      | 24/51 [00:00<00:00, 99.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████                   | 28/51 [00:00<00:00, 123.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████                   | 28/51 [00:00<00:00, 124.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▉         | 40/51 [00:00<00:00, 126.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|█████████████████████████████▋            | 36/51 [00:00<00:00, 108.35it/s]\u001b[A\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████▋   | 47/51 [00:00<00:00, 152.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 150.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████▋   | 47/51 [00:00<00:00, 151.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 151.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 124.68it/s]\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 140.33it/s]\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 157.91it/s]\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 119.31it/s]\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 120.91it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_block.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_block.tsv\n",
      "Processing Started...\n",
      "Data Size:  363\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 41%|█████████████████▎                        | 21/51 [00:00<00:00, 201.85it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 29%|████████████▎                             | 15/51 [00:00<00:00, 145.12it/s]\u001b[A\n",
      "\n",
      " 31%|█████████████▏                            | 16/51 [00:00<00:00, 153.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|█████████████▏                            | 16/51 [00:00<00:00, 155.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▋                          | 19/51 [00:00<00:00, 187.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▍                                  | 10/51 [00:00<00:00, 84.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████                                 | 11/51 [00:00<00:00, 101.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████████████████████████▎               | 32/51 [00:00<00:00, 149.46it/s]\u001b[A\u001b[A\n",
      " 82%|██████████████████████████████████▌       | 42/51 [00:00<00:00, 150.33it/s]\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▎               | 32/51 [00:00<00:00, 127.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▌                        | 22/51 [00:00<00:00, 98.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 154.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 146.08it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████████▍      | 43/51 [00:00<00:00, 111.12it/s]\u001b[A\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████▉    | 46/51 [00:00<00:00, 130.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▎          | 38/51 [00:00<00:00, 104.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▏              | 33/51 [00:00<00:00, 101.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 127.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 117.95it/s]\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 116.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████████     | 45/51 [00:00<00:00, 107.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 108.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 101.50it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_block.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_catalyse.tsv\n",
      "Processing Started...\n",
      "Data Size:  195\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▋                       | 12/27 [00:00<00:00, 114.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|██████████████▋                             | 9/27 [00:00<00:00, 84.61it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 30%|█████████████                               | 8/27 [00:00<00:00, 72.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|██████████████▋                             | 9/27 [00:00<00:00, 82.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████████▎    | 24/27 [00:00<00:00, 116.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▋                       | 12/27 [00:00<00:00, 113.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 115.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|██████████████████████████████████████▉   | 25/27 [00:00<00:00, 125.02it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 119.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 119.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 134.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 84.81it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 94.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 106.39it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_catalyse.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_catalyse.tsv\n",
      "Processing Started...\n",
      "Data Size:  196\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 54%|██████████████████████▌                   | 15/28 [00:00<00:00, 149.72it/s]\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 108.48it/s]\u001b[A\n",
      "\n",
      " 54%|██████████████████████▌                   | 15/28 [00:00<00:00, 139.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|██████████████████████▌                   | 15/28 [00:00<00:00, 140.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 164.32it/s]\n",
      " 57%|████████████████████████                  | 16/28 [00:00<00:00, 150.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 14/28 [00:00<00:00, 139.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 14/28 [00:00<00:00, 138.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 124.94it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 131.22it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 138.61it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 113.38it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 137.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 111.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_catalyse.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_confer.tsv\n",
      "Processing Started...\n",
      "Data Size:  317\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▊                         | 18/45 [00:00<00:00, 173.81it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 29%|████████████▏                             | 13/45 [00:00<00:00, 122.69it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 31%|█████████████                             | 14/45 [00:00<00:00, 135.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▏                             | 13/45 [00:00<00:00, 105.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▊                                    | 8/45 [00:00<00:00, 77.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▊                                     | 7/45 [00:00<00:00, 61.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▊                                     | 7/45 [00:00<00:00, 66.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|█████████████████████████████████▌        | 36/45 [00:00<00:00, 130.23it/s]\u001b[A\n",
      "\n",
      "\n",
      " 53%|██████████████████████▉                    | 24/45 [00:00<00:00, 96.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|████████████████▏                          | 17/45 [00:00<00:00, 84.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▍                             | 14/45 [00:00<00:00, 64.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▋                       | 20/45 [00:00<00:00, 100.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 132.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 127.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▋         | 35/45 [00:00<00:00, 101.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████████████████████████████▋          | 34/45 [00:00<00:00, 122.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|███████████████████████████               | 29/45 [00:00<00:00, 101.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▌        | 36/45 [00:00<00:00, 125.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 111.59it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 109.21it/s]\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 119.20it/s]\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 114.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 100.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_confer.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_confer.tsv\n",
      "Processing Started...\n",
      "Data Size:  319\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 38%|███████████████▊                          | 17/45 [00:00<00:00, 162.12it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 47%|███████████████████▌                      | 21/45 [00:00<00:00, 203.50it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 44%|██████████████████▋                       | 20/45 [00:00<00:00, 199.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 17/45 [00:00<00:00, 169.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████                            | 15/45 [00:00<00:00, 136.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▋         | 35/45 [00:00<00:00, 167.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████▉                           | 16/45 [00:00<00:00, 152.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████████▎    | 40/45 [00:00<00:00, 195.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▋         | 35/45 [00:00<00:00, 175.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 190.71it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 195.25it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 167.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 161.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 155.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 147.65it/s]\n",
      "100%|██████████████████████████████████████████| 45/45 [00:00<00:00, 155.49it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_confer.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_decrease.tsv\n",
      "Processing Started...\n",
      "Data Size:  195\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 44%|██████████████████▋                       | 12/27 [00:00<00:00, 118.83it/s]\n",
      " 48%|████████████████████▏                     | 13/27 [00:00<00:00, 129.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|██████████████████▋                       | 12/27 [00:00<00:00, 110.63it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▍               | 17/27 [00:00<00:00, 156.50it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 237.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 133.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 193.77it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 146.89it/s]\n",
      "\n",
      " 96%|████████████████████████████████████████▍ | 26/27 [00:00<00:00, 116.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 120.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 200.97it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 107.64it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_decrease.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_decrease.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▎                           | 10/28 [00:00<00:00, 97.24it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 116.80it/s]\u001b[A\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 115.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 118.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███████████████▎                           | 10/28 [00:00<00:00, 85.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████         | 22/28 [00:00<00:00, 107.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▌                      | 13/28 [00:00<00:00, 115.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████████      | 24/28 [00:00<00:00, 109.96it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 159.79it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 100.77it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 106.37it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 134.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 142.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 109.73it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 101.21it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_decrease.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_delete.tsv\n",
      "Processing Started...\n",
      "Data Size:  411\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▉                                  | 11/58 [00:00<00:00, 109.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|██████████▏                               | 14/58 [00:00<00:00, 136.94it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 17/58 [00:00<00:00, 155.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|█████████▍                                | 13/58 [00:00<00:00, 114.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 17/58 [00:00<00:00, 165.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▌                              | 16/58 [00:00<00:00, 149.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 29/58 [00:00<00:00, 145.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|████████████████████▎                     | 28/58 [00:00<00:00, 136.49it/s]\u001b[A\n",
      "\n",
      " 64%|██████████████████████████▊               | 37/58 [00:00<00:00, 170.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▎                | 35/58 [00:00<00:00, 164.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|██████████████████████▍                   | 31/58 [00:00<00:00, 137.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|████████████████████████▌                 | 34/58 [00:00<00:00, 138.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▌         | 45/58 [00:00<00:00, 151.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|███████████████████████████████▏          | 43/58 [00:00<00:00, 142.28it/s]\u001b[A\n",
      "\n",
      " 97%|████████████████████████████████████████▌ | 56/58 [00:00<00:00, 178.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 173.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 163.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 156.27it/s]\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 153.92it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████████▊  | 55/58 [00:00<00:00, 154.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 152.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 151.42it/s]\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 161.47it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_delete.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_delete.tsv\n",
      "Processing Started...\n",
      "Data Size:  413\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 39%|████████████████▎                         | 23/59 [00:00<00:00, 226.58it/s]\n",
      " 36%|██████████████▉                           | 21/59 [00:00<00:00, 204.76it/s]\u001b[A\n",
      "\n",
      " 36%|██████████████▉                           | 21/59 [00:00<00:00, 207.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|████████████████▎                         | 23/59 [00:00<00:00, 224.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████▉                           | 21/59 [00:00<00:00, 204.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████                              | 17/59 [00:00<00:00, 168.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████▏       | 48/59 [00:00<00:00, 239.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|██████████████████████████████▌           | 43/59 [00:00<00:00, 206.46it/s]\u001b[A\u001b[A\n",
      " 71%|█████████████████████████████▉            | 42/59 [00:00<00:00, 188.59it/s]\u001b[A\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▋         | 46/59 [00:00<00:00, 222.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 226.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▎               | 37/59 [00:00<00:00, 184.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 228.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 208.55it/s]\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 199.11it/s]\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 183.42it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 184.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 187.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_delete.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_develop.tsv\n",
      "Processing Started...\n",
      "Data Size:  62\n",
      "number of threads:  7\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 99.65it/s]\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 92.16it/s]\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 94.83it/s]\u001b[A\u001b[A\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 56.64it/s]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 80.19it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 61.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 41.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_develop.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_develop.tsv\n",
      "Processing Started...\n",
      "Data Size:  62\n",
      "number of threads:  7\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 93.70it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 87.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 87.72it/s]\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 76.36it/s]\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████████▌                      | 4/8 [00:00<00:00, 35.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 45.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 63.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 42.21it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_develop.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_disrupt.tsv\n",
      "Processing Started...\n",
      "Data Size:  119\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|█████████████████████████████▋            | 12/17 [00:00<00:00, 115.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████████          | 13/17 [00:00<00:00, 120.48it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 128.88it/s]\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 133.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▏              | 11/17 [00:00<00:00, 106.34it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 112.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 131.32it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 91.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 142.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 99.94it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_disrupt.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_disrupt.tsv\n",
      "Processing Started...\n",
      "Data Size:  120\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 191.53it/s]\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 149.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████████▌       | 14/17 [00:00<00:00, 139.70it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 141.20it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████████     | 15/17 [00:00<00:00, 149.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 157.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 120.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 137.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 116.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_disrupt.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_eliminate.tsv\n",
      "Processing Started...\n",
      "Data Size:  191\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 70%|█████████████████████████████▌            | 19/27 [00:00<00:00, 186.54it/s]\n",
      " 52%|█████████████████████▊                    | 14/27 [00:00<00:00, 134.26it/s]\u001b[A\n",
      "\n",
      " 44%|██████████████████▋                       | 12/27 [00:00<00:00, 117.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 173.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▌            | 19/27 [00:00<00:00, 168.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████              | 18/27 [00:00<00:00, 174.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 154.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 128.38it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 130.71it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 144.64it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 168.02it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 128.13it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_eliminate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_eliminate.tsv\n",
      "Processing Started...\n",
      "Data Size:  192\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|█████████████████████████████▌            | 19/27 [00:00<00:00, 175.53it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 52%|█████████████████████▊                    | 14/27 [00:00<00:00, 125.82it/s]\u001b[A\u001b[A\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 72.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 158.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████                         | 11/27 [00:00<00:00, 101.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 145.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 90.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|████████████████████████████▋              | 18/27 [00:00<00:00, 74.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 127.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 138.28it/s]\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 93.83it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 140.07it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 137.18it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_eliminate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_encode.tsv\n",
      "Processing Started...\n",
      "Data Size:  196\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 57%|████████████████████████                  | 16/28 [00:00<00:00, 157.62it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|████████████████████████                  | 16/28 [00:00<00:00, 151.14it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 46%|███████████████████▌                      | 13/28 [00:00<00:00, 126.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|██████████████████████▌                   | 15/28 [00:00<00:00, 148.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████                  | 16/28 [00:00<00:00, 154.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▌                      | 13/28 [00:00<00:00, 126.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 155.47it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 174.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 178.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 143.88it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 141.64it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 180.11it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_encode.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_encode.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 68%|████████████████████████████▌             | 19/28 [00:00<00:00, 178.93it/s]\n",
      " 79%|█████████████████████████████████         | 22/28 [00:00<00:00, 217.72it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 232.22it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 215.38it/s]\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████                  | 16/28 [00:00<00:00, 148.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 119.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|███████████████████████████               | 18/28 [00:00<00:00, 176.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 155.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 143.41it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 107.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 110.24it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 115.61it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_encode.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_express.tsv\n",
      "Processing Started...\n",
      "Data Size:  395\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████▋                             | 17/56 [00:00<00:00, 165.14it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 30%|████████████▋                             | 17/56 [00:00<00:00, 153.82it/s]\u001b[A\n",
      "\n",
      " 29%|████████████                              | 16/56 [00:00<00:00, 151.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|████████████▋                             | 17/56 [00:00<00:00, 167.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▊                                | 13/56 [00:00<00:00, 124.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                 | 12/56 [00:00<00:00, 110.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▋                                   | 10/56 [00:00<00:00, 90.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|████████████████████████                  | 32/56 [00:00<00:00, 154.38it/s]\u001b[A\u001b[A\n",
      " 59%|████████████████████████▊                 | 33/56 [00:00<00:00, 132.31it/s]\u001b[A\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▍                | 34/56 [00:00<00:00, 141.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▍                | 34/56 [00:00<00:00, 118.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 24/56 [00:00<00:00, 109.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▎                        | 23/56 [00:00<00:00, 112.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████████      | 48/56 [00:00<00:00, 145.98it/s]\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████████      | 48/56 [00:00<00:00, 125.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▎         | 43/56 [00:00<00:00, 140.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████▊     | 49/56 [00:00<00:00, 138.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 147.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 148.17it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 148.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 134.53it/s]\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 138.86it/s]\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 137.42it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 136.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_express.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_express.tsv\n",
      "Processing Started...\n",
      "Data Size:  397\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 41%|█████████████████▎                        | 23/56 [00:00<00:00, 214.10it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 34%|██████████████▎                           | 19/56 [00:00<00:00, 182.27it/s]\u001b[A\n",
      "\n",
      " 39%|████████████████▌                         | 22/56 [00:00<00:00, 216.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|████████████▋                             | 17/56 [00:00<00:00, 169.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▌                            | 18/56 [00:00<00:00, 176.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▎                              | 15/56 [00:00<00:00, 145.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████▋                             | 17/56 [00:00<00:00, 166.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 45/56 [00:00<00:00, 184.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▍                | 34/56 [00:00<00:00, 145.75it/s]\u001b[A\u001b[A\u001b[A\n",
      " 68%|████████████████████████████▌             | 38/56 [00:00<00:00, 145.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 183.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▍                | 34/56 [00:00<00:00, 137.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 148.99it/s]\n",
      " 54%|███████████████████████                    | 30/56 [00:00<00:00, 97.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████▊     | 49/56 [00:00<00:00, 125.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 148.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|███████████████████████████████████████▊  | 53/56 [00:00<00:00, 110.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 130.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 118.10it/s]\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 138.90it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 111.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_express.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_generate.tsv\n",
      "Processing Started...\n",
      "Data Size:  370\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 21%|████████▉                                 | 11/52 [00:00<00:00, 105.14it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|████████▎                                  | 10/52 [00:00<00:00, 94.13it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|████████▎                                  | 10/52 [00:00<00:00, 97.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▉                                 | 11/52 [00:00<00:00, 109.65it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████▏                        | 22/52 [00:00<00:00, 99.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|█████████████████▎                         | 21/52 [00:00<00:00, 96.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▌                               | 13/52 [00:00<00:00, 129.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                  | 11/52 [00:00<00:00, 97.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|█████████████████▊                        | 22/52 [00:00<00:00, 104.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|█████████████████▊                        | 22/52 [00:00<00:00, 102.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▍              | 34/52 [00:00<00:00, 104.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|█████████████████████████▊                | 32/52 [00:00<00:00, 100.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 26/52 [00:00<00:00, 125.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▊                    | 27/52 [00:00<00:00, 130.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████████████████████████▋               | 33/52 [00:00<00:00, 104.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▌          | 39/52 [00:00<00:00, 128.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████▉    | 47/52 [00:00<00:00, 154.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 155.95it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 133.03it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 113.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████████▍ | 50/52 [00:00<00:00, 170.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 122.20it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 155.04it/s]\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 159.92it/s]\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 112.99it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_generate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_generate.tsv\n",
      "Processing Started...\n",
      "Data Size:  371\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 28%|███████████▉                              | 15/53 [00:00<00:00, 148.13it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 26%|███████████                               | 14/53 [00:00<00:00, 132.28it/s]\u001b[A\n",
      "\n",
      " 23%|█████████▌                                | 12/53 [00:00<00:00, 111.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▍                            | 17/53 [00:00<00:00, 166.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 105.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|███████████████████████████▋              | 35/53 [00:00<00:00, 175.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|██████████████████████▏                   | 28/53 [00:00<00:00, 123.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 106.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|███████████████████▍                       | 24/53 [00:00<00:00, 93.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▎            | 37/53 [00:00<00:00, 181.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|███████████████████                       | 24/53 [00:00<00:00, 118.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|█████████████████▍                        | 22/53 [00:00<00:00, 102.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████▊                      | 25/53 [00:00<00:00, 121.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 167.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 130.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 116.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████            | 38/53 [00:00<00:00, 115.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████████▏    | 47/53 [00:00<00:00, 105.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 107.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 119.49it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 116.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 129.55it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_generate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_inhibit.tsv\n",
      "Processing Started...\n",
      "Data Size:  339\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 44%|██████████████████▍                       | 21/48 [00:00<00:00, 209.41it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|██████████▌                               | 12/48 [00:00<00:00, 115.38it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 35%|██████████████▉                           | 17/48 [00:00<00:00, 157.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 14/48 [00:00<00:00, 137.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▉                                  | 10/48 [00:00<00:00, 97.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                              | 13/48 [00:00<00:00, 126.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▉                                  | 10/48 [00:00<00:00, 94.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|████████████████████████████████████▊     | 42/48 [00:00<00:00, 167.93it/s]\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████              | 32/48 [00:00<00:00, 158.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|████████████████████████████▉             | 33/48 [00:00<00:00, 139.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 173.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|██████████████████████▊                   | 26/48 [00:00<00:00, 106.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████████▎ | 46/48 [00:00<00:00, 158.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 149.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 160.24it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 139.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▍         | 37/48 [00:00<00:00, 111.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████▌   | 44/48 [00:00<00:00, 135.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 133.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 117.57it/s]\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 122.45it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_inhibit.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_inhibit.tsv\n",
      "Processing Started...\n",
      "Data Size:  341\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 42%|█████████████████▌                        | 20/48 [00:00<00:00, 195.69it/s]\n",
      " 44%|██████████████████▍                       | 21/48 [00:00<00:00, 205.93it/s]\u001b[A\n",
      "\n",
      " 31%|█████████████▏                            | 15/48 [00:00<00:00, 147.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▏                            | 15/48 [00:00<00:00, 143.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|█████████████████▌                        | 20/48 [00:00<00:00, 197.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▏                            | 15/48 [00:00<00:00, 149.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████       | 40/48 [00:00<00:00, 193.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████████████████████████▎               | 30/48 [00:00<00:00, 147.78it/s]\u001b[A\u001b[A\n",
      " 88%|████████████████████████████████████▊     | 42/48 [00:00<00:00, 182.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 195.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 178.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████       | 40/48 [00:00<00:00, 164.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 157.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 137.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████▍  | 45/48 [00:00<00:00, 132.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 149.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 130.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 131.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_inhibit.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_initiate.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 54%|██████████████████████▌                   | 15/28 [00:00<00:00, 140.51it/s]\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 102.08it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 116.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|███████████████████▌                      | 13/28 [00:00<00:00, 104.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 116.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 108.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 128.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████████▌    | 25/28 [00:00<00:00, 115.29it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 114.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 115.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 119.61it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 139.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 125.42it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 120.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_initiate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_initiate.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 111.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 50%|█████████████████████                     | 14/28 [00:00<00:00, 134.32it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 118.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 14/28 [00:00<00:00, 131.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 156.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 128.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 140.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 145.22it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 148.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 119.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 103.07it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_initiate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_lead.tsv\n",
      "Processing Started...\n",
      "Data Size:  492\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 30%|████████████▌                             | 21/70 [00:00<00:00, 186.47it/s]\n",
      " 20%|████████▍                                 | 14/70 [00:00<00:00, 134.21it/s]\u001b[A\n",
      "\n",
      " 26%|██████████▊                               | 18/70 [00:00<00:00, 176.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|█████████                                 | 15/70 [00:00<00:00, 146.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▌                                | 16/70 [00:00<00:00, 155.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████▌                             | 21/70 [00:00<00:00, 198.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████                  | 40/70 [00:00<00:00, 185.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 41%|█████████████████▍                        | 29/70 [00:00<00:00, 137.74it/s]\u001b[A\n",
      "\n",
      " 51%|█████████████████████▌                    | 36/70 [00:00<00:00, 177.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|███████████████████▏                      | 32/70 [00:00<00:00, 157.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████████████████████▌                    | 36/70 [00:00<00:00, 180.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|██████████████████████▏                   | 37/70 [00:00<00:00, 179.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|████████████████████████▌                 | 41/70 [00:00<00:00, 178.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|████████████████████████████████▍         | 54/70 [00:00<00:00, 174.89it/s]\u001b[A\u001b[A\n",
      " 63%|██████████████████████████▍               | 44/70 [00:00<00:00, 138.30it/s]\u001b[A\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████████▍      | 59/70 [00:00<00:00, 148.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████         | 55/70 [00:00<00:00, 147.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████         | 55/70 [00:00<00:00, 169.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 154.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 159.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 158.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 165.48it/s]\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 146.55it/s]\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 134.84it/s]\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 152.60it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_lead.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_lead.tsv\n",
      "Processing Started...\n",
      "Data Size:  493\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 21%|█████████                                 | 15/70 [00:00<00:00, 140.77it/s]\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 98.65it/s]\u001b[A\n",
      "\n",
      " 26%|██████████▊                               | 18/70 [00:00<00:00, 168.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|███████▏                                  | 12/70 [00:00<00:00, 110.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▏                                  | 12/70 [00:00<00:00, 109.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                 | 15/70 [00:00<00:00, 143.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                 | 15/70 [00:00<00:00, 132.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|████████████▉                              | 21/70 [00:00<00:00, 97.47it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 30/70 [00:00<00:00, 98.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████████████████████                     | 35/70 [00:00<00:00, 122.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▌                       | 31/70 [00:00<00:00, 139.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 30/70 [00:00<00:00, 122.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|███████████████████                        | 31/70 [00:00<00:00, 97.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████████████████████▉                      | 34/70 [00:00<00:00, 97.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|████████████████████████████▊             | 48/70 [00:00<00:00, 115.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 35/70 [00:00<00:00, 84.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|███████████████████████████               | 45/70 [00:00<00:00, 126.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▏                 | 41/70 [00:00<00:00, 81.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|█████████████████████████▏                 | 41/70 [00:00<00:00, 78.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|██████████████████████████████████▊       | 58/70 [00:00<00:00, 124.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████████                | 44/70 [00:00<00:00, 77.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|███████████████████████████                | 44/70 [00:00<00:00, 69.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████████▊      | 60/70 [00:00<00:00, 91.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 126.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 109.71it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 115.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████████▏         | 54/70 [00:00<00:00, 81.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████▏      | 59/70 [00:00<00:00, 76.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 93.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████████▎   | 64/70 [00:00<00:00, 85.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 86.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 89.89it/s]\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 86.36it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_lead.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_lose.tsv\n",
      "Processing Started...\n",
      "Data Size:  286\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████                   | 22/40 [00:00<00:00, 205.65it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 50%|█████████████████████                     | 20/40 [00:00<00:00, 198.64it/s]\u001b[A\n",
      "\n",
      " 45%|██████████████████▉                       | 18/40 [00:00<00:00, 174.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|██████████████████▉                       | 18/40 [00:00<00:00, 179.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▊                         | 16/40 [00:00<00:00, 159.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 217.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████                   | 22/40 [00:00<00:00, 218.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████████████████████████████████▊    | 36/40 [00:00<00:00, 164.14it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 170.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████▊    | 36/40 [00:00<00:00, 159.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 198.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 167.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 162.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 163.41it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 184.06it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_lose.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_lose.tsv\n",
      "Processing Started...\n",
      "Data Size:  287\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████████████████████▌                    | 21/41 [00:00<00:00, 200.11it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 51%|█████████████████████▌                    | 21/41 [00:00<00:00, 209.62it/s]\u001b[A\n",
      "\n",
      " 56%|███████████████████████▌                  | 23/41 [00:00<00:00, 229.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                        | 17/41 [00:00<00:00, 155.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                        | 17/41 [00:00<00:00, 168.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████▎                           | 14/41 [00:00<00:00, 139.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 199.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 202.08it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 173.00it/s]\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 33/41 [00:00<00:00, 142.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|████████████████████████████▋             | 28/41 [00:00<00:00, 127.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|██████████████████████████████████▊       | 34/41 [00:00<00:00, 142.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 152.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 151.05it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 154.69it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 131.92it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_lose.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_modify.tsv\n",
      "Processing Started...\n",
      "Data Size:  166\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 65%|███████████████████████████▍              | 15/23 [00:00<00:00, 138.71it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 70%|█████████████████████████████▏            | 16/23 [00:00<00:00, 156.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|█████████████████████████▌                | 14/23 [00:00<00:00, 125.29it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 39%|█████████████████▏                          | 9/23 [00:00<00:00, 89.75it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 121.30it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 134.82it/s]\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 98.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████▍                                | 6/23 [00:00<00:00, 45.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 43.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 82.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 91.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|██████████████████████▍                    | 12/23 [00:00<00:00, 49.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 70.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████▌       | 19/23 [00:00<00:00, 55.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 52.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 51.00it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_modify.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_modify.tsv\n",
      "Processing Started...\n",
      "Data Size:  167\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 77.20it/s]\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 72.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 91%|██████████████████████████████████████▎   | 21/23 [00:00<00:00, 105.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 97.86it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 99.03it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 70%|█████████████████████████████▉             | 16/23 [00:00<00:00, 67.65it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 101.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 114.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▋                                    | 4/23 [00:00<00:00, 35.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▋                                    | 4/23 [00:00<00:00, 35.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 109.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 64.90it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 112.08it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 48.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|█████████████████▏                          | 9/23 [00:00<00:00, 42.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 67.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 70.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_modify.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_mutate.tsv\n",
      "Processing Started...\n",
      "Data Size:  244\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████▋                                | 9/34 [00:00<00:00, 79.12it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 26%|███████████▋                                | 9/34 [00:00<00:00, 87.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 35%|██████████████▊                           | 12/34 [00:00<00:00, 117.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▌                | 21/34 [00:00<00:00, 96.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████▋                                | 9/34 [00:00<00:00, 89.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|██████████████████████▊                    | 18/34 [00:00<00:00, 79.56it/s]\u001b[A\n",
      "\n",
      " 71%|█████████████████████████████▋            | 24/34 [00:00<00:00, 118.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                   | 7/34 [00:00<00:00, 69.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 34/34 [00:00<00:00, 123.42it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████████▏   | 31/34 [00:00<00:00, 88.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████████▋      | 29/34 [00:00<00:00, 86.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 86.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 84.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▎                 | 20/34 [00:00<00:00, 57.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████████▏        | 27/34 [00:00<00:00, 83.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▎            | 24/34 [00:00<00:00, 73.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 89.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████▍       | 28/34 [00:00<00:00, 63.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 76.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 63.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████████▉          | 26/34 [00:00<00:00, 55.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 56.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_mutate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_mutate.tsv\n",
      "Processing Started...\n",
      "Data Size:  245\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▌                             | 11/35 [00:00<00:00, 89.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▎                              | 10/35 [00:00<00:00, 87.71it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|██████████                                  | 8/35 [00:00<00:00, 64.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▊                                   | 7/35 [00:00<00:00, 68.87it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▍               | 22/35 [00:00<00:00, 105.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|███████████████████████████                | 22/35 [00:00<00:00, 92.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|██████████████████████                     | 18/35 [00:00<00:00, 90.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|███████████████████████▎                   | 19/35 [00:00<00:00, 88.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 35/35 [00:00<00:00, 124.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▌                  | 20/35 [00:00<00:00, 94.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 97.78it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 35/35 [00:00<00:00, 104.61it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████▋       | 29/35 [00:00<00:00, 97.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████▋       | 29/35 [00:00<00:00, 91.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 97.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 86.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 99.55it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 87.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_mutate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_proliferate.tsv\n",
      "Processing Started...\n",
      "Data Size:  162\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 74%|███████████████████████████████           | 17/23 [00:00<00:00, 168.95it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|█████████████████████████▌                | 14/23 [00:00<00:00, 139.38it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 172.84it/s]\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 151.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 137.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 126.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 181.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 145.26it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 183.32it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_proliferate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_proliferate.tsv\n",
      "Processing Started...\n",
      "Data Size:  163\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 78%|████████████████████████████████▊         | 18/23 [00:00<00:00, 179.50it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 221.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 183.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 209.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▏            | 16/23 [00:00<00:00, 155.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 143.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 162.48it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 186.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 141.27it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_proliferate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_recognize.tsv\n",
      "Processing Started...\n",
      "Data Size:  291\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 12/41 [00:00<00:00, 117.86it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 37%|███████████████▎                          | 15/41 [00:00<00:00, 140.74it/s]\u001b[A\n",
      "\n",
      " 24%|██████████▍                                | 10/41 [00:00<00:00, 99.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 12/41 [00:00<00:00, 116.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████▋                                  | 9/41 [00:00<00:00, 70.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 49%|████████████████████▉                      | 20/41 [00:00<00:00, 89.91it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▏                 | 24/41 [00:00<00:00, 82.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|███████████████████████████████▍           | 30/41 [00:00<00:00, 98.72it/s]\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▏                 | 24/41 [00:00<00:00, 80.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▎                                       | 4/41 [00:00<00:01, 34.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▉                       | 19/41 [00:00<00:00, 80.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████▌        | 33/41 [00:00<00:00, 75.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████████████████████████████▍           | 30/41 [00:00<00:00, 72.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████████▊     | 36/41 [00:00<00:00, 92.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▍            | 29/41 [00:00<00:00, 84.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 93.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▋                           | 15/41 [00:00<00:00, 68.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 89.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 96.67it/s]\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 78.09it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 78.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████▊   | 38/41 [00:00<00:00, 82.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 76.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 75.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_recognize.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_recognize.tsv\n",
      "Processing Started...\n",
      "Data Size:  293\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 41%|█████████████████▍                        | 17/41 [00:00<00:00, 165.73it/s]\n",
      " 44%|██████████████████▍                       | 18/41 [00:00<00:00, 178.98it/s]\u001b[A\n",
      "\n",
      " 46%|███████████████████▍                      | 19/41 [00:00<00:00, 183.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|██████████████████▍                       | 18/41 [00:00<00:00, 167.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▍                       | 18/41 [00:00<00:00, 174.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████████████████████▌                    | 21/41 [00:00<00:00, 207.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████▉     | 36/41 [00:00<00:00, 177.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 165.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 165.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 190.52it/s]\n",
      "\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████▊      | 35/41 [00:00<00:00, 142.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 181.01it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 141.07it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 131.18it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 139.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_recognize.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_result.tsv\n",
      "Processing Started...\n",
      "Data Size:  496\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 91.92it/s]\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 104.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 103.31it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 11%|█████                                       | 8/70 [00:00<00:00, 77.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▊                                    | 11/70 [00:00<00:00, 99.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                              | 20/70 [00:00<00:00, 94.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 96.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 31%|█████████████▌                             | 22/70 [00:00<00:00, 93.52it/s]\u001b[A\n",
      "\n",
      "\n",
      " 31%|█████████████▏                            | 22/70 [00:00<00:00, 106.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|██████████▍                                | 17/70 [00:00<00:00, 82.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                        | 29/70 [00:00<00:00, 141.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 30/70 [00:00<00:00, 90.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                              | 20/70 [00:00<00:00, 93.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████████████████████▌                    | 36/70 [00:00<00:00, 118.91it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|███████████████████▋                       | 32/70 [00:00<00:00, 88.81it/s]\u001b[A\n",
      "\n",
      " 39%|████████████████▌                          | 27/70 [00:00<00:00, 89.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▏                 | 41/70 [00:00<00:00, 97.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 35/70 [00:00<00:00, 115.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|████████████████████████████▊             | 48/70 [00:00<00:00, 115.70it/s]\u001b[A\u001b[A\u001b[A\n",
      " 64%|███████████████████████████               | 45/70 [00:00<00:00, 102.96it/s]\u001b[A\n",
      "\n",
      " 56%|███████████████████████▉                   | 39/70 [00:00<00:00, 99.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████      | 60/70 [00:00<00:00, 146.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|███████████████████████████████▊          | 53/70 [00:00<00:00, 105.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████            | 50/70 [00:00<00:00, 125.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████████▏    | 62/70 [00:00<00:00, 122.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 137.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 135.01it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 119.05it/s]\n",
      " 91%|██████████████████████████████████████▍   | 64/70 [00:00<00:00, 104.55it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 129.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 101.79it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 102.31it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 108.51it/s]\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_result.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_result.tsv\n",
      "Processing Started...\n",
      "Data Size:  497\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 20%|████████▎                                 | 14/71 [00:00<00:00, 139.64it/s]\n",
      " 18%|███████▋                                  | 13/71 [00:00<00:00, 129.92it/s]\u001b[A\n",
      "\n",
      " 18%|███████▋                                  | 13/71 [00:00<00:00, 124.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▊                                 | 15/71 [00:00<00:00, 148.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▋                               | 18/71 [00:00<00:00, 177.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▋                               | 18/71 [00:00<00:00, 163.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 34/71 [00:00<00:00, 169.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|███████████████████▌                      | 33/71 [00:00<00:00, 171.02it/s]\u001b[A\n",
      "\n",
      " 38%|███████████████▉                          | 27/71 [00:00<00:00, 128.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████████████████████▋                     | 35/71 [00:00<00:00, 173.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▉                    | 37/71 [00:00<00:00, 182.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████▋                  | 40/71 [00:00<00:00, 190.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▎          | 53/71 [00:00<00:00, 177.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|███████████████████████████████▎          | 53/71 [00:00<00:00, 179.55it/s]\u001b[A\n",
      "\n",
      " 61%|█████████████████████████▍                | 43/71 [00:00<00:00, 138.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|███████████████████████████████▉          | 54/71 [00:00<00:00, 180.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████▍      | 60/71 [00:00<00:00, 199.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████▋  | 67/71 [00:00<00:00, 223.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 173.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 175.24it/s]\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 217.28it/s]\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 182.88it/s]\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 192.04it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 149.98it/s]\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_result.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_skip.tsv\n",
      "Processing Started...\n",
      "Data Size:  79\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 174.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 135.37it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 123.88it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 150.02it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 148.72it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 166.54it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 143.76it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_skip.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_skip.tsv\n",
      "Processing Started...\n",
      "Data Size:  80\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 172.39it/s]\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 161.15it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 132.58it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 134.43it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 133.06it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 170.97it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 191.69it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_skip.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_splice.tsv\n",
      "Processing Started...\n",
      "Data Size:  390\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 33%|█████████████▋                            | 18/55 [00:00<00:00, 170.04it/s]\n",
      "\n",
      " 29%|████████████▏                             | 16/55 [00:00<00:00, 156.20it/s]\u001b[A\u001b[A\n",
      " 33%|█████████████▋                            | 18/55 [00:00<00:00, 158.90it/s]\u001b[A\n",
      "\n",
      "\n",
      " 25%|██████████▋                               | 14/55 [00:00<00:00, 133.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|███████▏                                    | 9/55 [00:00<00:00, 87.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████▋                            | 18/55 [00:00<00:00, 160.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▍              | 36/55 [00:00<00:00, 149.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|██████████████████████▉                   | 30/55 [00:00<00:00, 147.52it/s]\u001b[A\u001b[A\u001b[A\n",
      " 62%|█████████████████████████▉                | 34/55 [00:00<00:00, 141.10it/s]\u001b[A\n",
      "\n",
      " 58%|████████████████████████▍                 | 32/55 [00:00<00:00, 138.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████▊                      | 26/55 [00:00<00:00, 133.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|██████████████████████████▋               | 35/55 [00:00<00:00, 155.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|████████████████████▌                     | 27/55 [00:00<00:00, 134.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 156.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 156.57it/s]\n",
      " 89%|█████████████████████████████████████▍    | 49/55 [00:00<00:00, 148.36it/s]\u001b[A\u001b[A\n",
      " 89%|█████████████████████████████████████▍    | 49/55 [00:00<00:00, 140.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 146.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 149.88it/s]\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 150.47it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▌        | 44/55 [00:00<00:00, 147.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 146.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 151.72it/s]\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 135.43it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_splice.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_splice.tsv\n",
      "Processing Started...\n",
      "Data Size:  390\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|██████████████▌                           | 19/55 [00:00<00:00, 184.87it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 36%|███████████████▎                          | 20/55 [00:00<00:00, 184.60it/s]\u001b[A\n",
      "\n",
      " 27%|███████████▍                              | 15/55 [00:00<00:00, 135.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|████████████████                          | 21/55 [00:00<00:00, 196.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▎                          | 20/55 [00:00<00:00, 194.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▏                             | 16/55 [00:00<00:00, 155.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████             | 38/55 [00:00<00:00, 161.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|██████████████████████▉                   | 30/55 [00:00<00:00, 137.39it/s]\u001b[A\u001b[A\n",
      " 71%|█████████████████████████████▊            | 39/55 [00:00<00:00, 170.09it/s]\u001b[A\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▎          | 41/55 [00:00<00:00, 185.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|██████████████████████████████▌           | 40/55 [00:00<00:00, 171.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▏                | 33/55 [00:00<00:00, 154.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 189.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 168.33it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 163.77it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 160.70it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 145.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 164.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 162.76it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_splice.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_transcribe.tsv\n",
      "Processing Started...\n",
      "Data Size:  799\n",
      "number of threads:  7\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 18%|███████▌                                 | 21/114 [00:00<00:00, 205.78it/s]\n",
      " 16%|██████▍                                  | 18/114 [00:00<00:00, 173.91it/s]\u001b[A\n",
      "\n",
      " 14%|█████▊                                   | 16/114 [00:00<00:00, 154.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▊                                  | 19/114 [00:00<00:00, 180.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▋                                | 24/114 [00:00<00:00, 237.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▌                                 | 21/114 [00:00<00:00, 199.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████                          | 42/114 [00:00<00:00, 188.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▉                            | 36/114 [00:00<00:00, 168.73it/s]\u001b[A\n",
      "\n",
      " 33%|█████████████▋                           | 38/114 [00:00<00:00, 191.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████▎                      | 51/114 [00:00<00:00, 249.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|█████████████▋                           | 38/114 [00:00<00:00, 166.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▋                      | 52/114 [00:00<00:00, 236.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████▋                          | 41/114 [00:00<00:00, 171.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 47%|███████████████████▍                     | 54/114 [00:00<00:00, 173.63it/s]\u001b[A\n",
      "\n",
      " 54%|█████████████████████▉                   | 61/114 [00:00<00:00, 170.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|████████████████████▌                    | 57/114 [00:00<00:00, 176.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|███████████████████████████▎             | 76/114 [00:00<00:00, 214.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▏                   | 59/114 [00:00<00:00, 149.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|███████████████████████████▎             | 76/114 [00:00<00:00, 197.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|█████████████████████████▉               | 72/114 [00:00<00:00, 150.09it/s]\u001b[A\n",
      "\n",
      " 71%|█████████████████████████████▏           | 81/114 [00:00<00:00, 166.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|████████████████████████████▍            | 79/114 [00:00<00:00, 140.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|███████████████████████████████████▏     | 98/114 [00:00<00:00, 188.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|███████████████████████████████▋         | 88/114 [00:00<00:00, 151.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|██████████████████████████████████▉      | 97/114 [00:00<00:00, 176.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|███████████████████████████████████▌     | 99/114 [00:00<00:00, 170.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 198.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 179.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 195.19it/s]\n",
      "\n",
      " 91%|████████████████████████████████████▍   | 104/114 [00:00<00:00, 146.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 166.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 156.20it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 152.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 164.62it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_transcribe.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_transcribe.tsv\n",
      "Processing Started...\n",
      "Data Size:  801\n",
      "number of threads:  7\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 18%|███████▌                                 | 21/114 [00:00<00:00, 207.71it/s]\n",
      " 21%|████████▋                                | 24/114 [00:00<00:00, 237.98it/s]\u001b[A\n",
      "\n",
      " 20%|████████▎                                | 23/114 [00:00<00:00, 224.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|████████▎                                | 23/114 [00:00<00:00, 227.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▉                                 | 22/114 [00:00<00:00, 206.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▎                                | 23/114 [00:00<00:00, 225.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████                          | 42/114 [00:00<00:00, 204.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|█████████████████▌                       | 49/114 [00:00<00:00, 238.64it/s]\u001b[A\u001b[A\n",
      " 42%|█████████████████▎                       | 48/114 [00:00<00:00, 213.29it/s]\u001b[A\n",
      "\n",
      "\n",
      " 40%|████████████████▌                        | 46/114 [00:00<00:00, 218.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▊                         | 44/114 [00:00<00:00, 205.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▌                        | 46/114 [00:00<00:00, 223.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████▋                  | 63/114 [00:00<00:00, 201.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|█████████████████████████▏               | 70/114 [00:00<00:00, 213.71it/s]\u001b[A\n",
      "\n",
      "\n",
      " 61%|████████████████████████▊                | 69/114 [00:00<00:00, 221.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████████████████████████▎              | 73/114 [00:00<00:00, 214.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|████████████████████████▍                | 68/114 [00:00<00:00, 217.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████▊                | 69/114 [00:00<00:00, 222.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|██████████████████████████████▏          | 84/114 [00:00<00:00, 197.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|█████████████████████████████████        | 92/114 [00:00<00:00, 214.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|██████████████████████████████████▏      | 95/114 [00:00<00:00, 211.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|█████████████████████████████████        | 92/114 [00:00<00:00, 224.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|█████████████████████████████████        | 92/114 [00:00<00:00, 194.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|█████████████████████████████████        | 92/114 [00:00<00:00, 224.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|████████████████████████████████████▍   | 104/114 [00:00<00:00, 183.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 210.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 204.83it/s]\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 208.06it/s]\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 206.21it/s]\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 180.44it/s]\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 176.15it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 190.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_transcribe.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_transform.tsv\n",
      "Processing Started...\n",
      "Data Size:  375\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 47%|███████████████████▊                      | 25/53 [00:00<00:00, 248.82it/s]\n",
      " 43%|██████████████████▏                       | 23/53 [00:00<00:00, 229.33it/s]\u001b[A\n",
      "\n",
      " 51%|█████████████████████▍                    | 27/53 [00:00<00:00, 264.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|██████████████████▏                       | 23/53 [00:00<00:00, 228.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▏                       | 23/53 [00:00<00:00, 222.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 20/53 [00:00<00:00, 194.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████▌  | 50/53 [00:00<00:00, 231.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 228.10it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 206.30it/s]\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████████▍     | 46/53 [00:00<00:00, 182.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 188.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 190.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 178.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 194.61it/s]\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 178.87it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_transform.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_transform.tsv\n",
      "Processing Started...\n",
      "Data Size:  377\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 28%|███████████▉                              | 15/53 [00:00<00:00, 149.62it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 19%|████████                                   | 10/53 [00:00<00:00, 93.34it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 30%|████████████▋                             | 16/53 [00:00<00:00, 148.66it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▌                                | 12/53 [00:00<00:00, 116.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████            | 38/53 [00:00<00:00, 194.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▉                              | 15/53 [00:00<00:00, 142.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|███████████████████                       | 24/53 [00:00<00:00, 118.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▏                       | 23/53 [00:00<00:00, 223.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|███████████████████████████▋              | 35/53 [00:00<00:00, 170.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▏               | 33/53 [00:00<00:00, 162.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 186.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 177.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|███████████████████████▊                  | 30/53 [00:00<00:00, 135.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 217.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 144.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 155.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 172.12it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_transform.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_translate.tsv\n",
      "Processing Started...\n",
      "Data Size:  678\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████                                   | 16/96 [00:00<00:00, 155.92it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 12%|█████▎                                    | 12/96 [00:00<00:00, 117.97it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████▊                                     | 11/96 [00:00<00:00, 105.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▍                                      | 10/96 [00:00<00:01, 85.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▍                                      | 10/96 [00:00<00:00, 97.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▊                                     | 11/96 [00:00<00:00, 105.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▋                                        | 8/96 [00:00<00:01, 76.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|██████████████                            | 32/96 [00:00<00:00, 117.65it/s]\u001b[A\u001b[A\n",
      " 25%|██████████▊                                | 24/96 [00:00<00:00, 91.90it/s]\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▉                                  | 20/96 [00:00<00:00, 87.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▉                                  | 20/96 [00:00<00:00, 90.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▏                                   | 16/96 [00:00<00:01, 77.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|████████████████▏                         | 37/96 [00:00<00:00, 111.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▊                                 | 22/96 [00:00<00:00, 91.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|███████████████▏                           | 34/96 [00:00<00:00, 84.61it/s]\u001b[A\n",
      "\n",
      "\n",
      " 30%|████████████▉                              | 29/96 [00:00<00:00, 82.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████████████████████▍                    | 49/96 [00:00<00:00, 113.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▍                             | 30/96 [00:00<00:00, 80.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▊                                | 24/96 [00:00<00:01, 62.55it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████▏                      | 45/96 [00:00<00:00, 79.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|███████████████████▋                       | 44/96 [00:00<00:00, 85.22it/s]\u001b[A\n",
      "\n",
      "\n",
      " 40%|█████████████████                          | 38/96 [00:00<00:00, 84.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████████████████████████▋               | 61/96 [00:00<00:00, 100.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████▎                            | 32/96 [00:00<00:00, 65.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                         | 39/96 [00:00<00:00, 68.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 55%|███████████████████████▋                   | 53/96 [00:00<00:00, 80.34it/s]\u001b[A\n",
      "\n",
      "\n",
      " 49%|█████████████████████                      | 47/96 [00:00<00:00, 74.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▋                  | 55/96 [00:00<00:00, 64.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|████████████████████████████████▎          | 72/96 [00:00<00:00, 94.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████████████████████████                  | 56/96 [00:00<00:00, 76.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▋                  | 55/96 [00:00<00:00, 83.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████████▎          | 72/96 [00:00<00:00, 87.28it/s]\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████████▌   | 88/96 [00:00<00:00, 109.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████                      | 47/96 [00:00<00:00, 52.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                         | 39/96 [00:00<00:01, 43.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 107.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████████████████████████████▎           | 70/96 [00:01<00:00, 56.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████              | 65/96 [00:01<00:00, 53.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████▍        | 77/96 [00:01<00:00, 56.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████████▏     | 83/96 [00:01<00:00, 57.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████▎          | 72/96 [00:01<00:00, 47.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████▉        | 78/96 [00:01<00:00, 67.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|██████████████████████████████████████▉    | 87/96 [00:01<00:00, 64.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|███████████████████████▎                   | 52/96 [00:01<00:01, 40.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████▏ | 92/96 [00:01<00:00, 61.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████▍       | 79/96 [00:01<00:00, 50.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 71.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 70.40it/s]\n",
      " 78%|█████████████████████████████████▌         | 75/96 [00:01<00:00, 58.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████▉    | 87/96 [00:01<00:00, 67.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████▉            | 69/96 [00:01<00:00, 58.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████     | 85/96 [00:01<00:00, 67.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 71.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████████▍   | 88/96 [00:01<00:00, 52.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 64.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 64.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 59.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_translate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_translate.tsv\n",
      "Processing Started...\n",
      "Data Size:  678\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▉                                      | 11/96 [00:00<00:00, 87.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|███████▍                                  | 17/96 [00:00<00:00, 155.39it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▋                                        | 8/96 [00:00<00:01, 77.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▉                                  | 20/96 [00:00<00:00, 87.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|█████████████▏                            | 30/96 [00:00<00:00, 144.63it/s]\u001b[A\u001b[A\n",
      " 16%|██████▋                                    | 15/96 [00:00<00:01, 66.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                   | 15/96 [00:00<00:00, 143.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|██████████████▍                           | 33/96 [00:00<00:00, 139.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████▍                                     | 12/96 [00:00<00:01, 52.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▏                                   | 16/96 [00:00<00:01, 58.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|████████████▉                              | 29/96 [00:00<00:00, 81.81it/s]\u001b[A\u001b[A\n",
      " 23%|█████████▊                                 | 22/96 [00:00<00:01, 64.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▏                            | 30/96 [00:00<00:00, 125.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 48/96 [00:00<00:00, 133.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▊                                 | 22/96 [00:00<00:01, 70.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████                          | 38/96 [00:00<00:00, 82.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|██████████████▊                            | 33/96 [00:00<00:00, 77.88it/s]\u001b[A\n",
      "\n",
      " 61%|█████████████████████████▊                | 59/96 [00:00<00:00, 127.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▎                      | 44/96 [00:00<00:00, 125.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▉                             | 31/96 [00:00<00:00, 76.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▏              | 62/96 [00:00<00:00, 120.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████▎                            | 32/96 [00:00<00:00, 69.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|█████████████████████                     | 48/96 [00:00<00:00, 101.02it/s]\u001b[A\n",
      "\n",
      " 75%|███████████████████████████████▌          | 72/96 [00:00<00:00, 125.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████                      | 47/96 [00:00<00:00, 73.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▊                        | 42/96 [00:00<00:00, 87.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████▎        | 76/96 [00:00<00:00, 126.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████▏                      | 45/96 [00:00<00:00, 87.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 69%|████████████████████████████▉             | 66/96 [00:00<00:00, 124.81it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 142.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████              | 64/96 [00:00<00:00, 100.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████▌                 | 56/96 [00:00<00:00, 104.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▉                 | 58/96 [00:00<00:00, 99.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████████▊  | 91/96 [00:00<00:00, 122.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 129.53it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 146.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████████▏       | 78/96 [00:00<00:00, 109.25it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 115.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 107.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 117.69it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 107.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_translate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_truncate.tsv\n",
      "Processing Started...\n",
      "Data Size:  161\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 52%|█████████████████████▉                    | 12/23 [00:00<00:00, 118.46it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 57%|███████████████████████▋                  | 13/23 [00:00<00:00, 119.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 57%|███████████████████████▋                  | 13/23 [00:00<00:00, 122.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 109.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 120.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 120.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 114.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 100.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 112.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 112.51it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 115.84it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 106.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_truncate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_truncate.tsv\n",
      "Processing Started...\n",
      "Data Size:  161\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2418: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 57%|███████████████████████▋                  | 13/23 [00:00<00:00, 118.60it/s]\n",
      " 70%|█████████████████████████████▏            | 16/23 [00:00<00:00, 147.92it/s]\u001b[A\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 107.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 103.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 154.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 129.50it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 159.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▍              | 15/23 [00:00<00:00, 148.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 135.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 117.97it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 140.78it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 137.40it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_truncate.json\n"
     ]
    }
   ],
   "source": [
    "#!python ../data_preparation.py --task_file 'tasks_file_SRL.yml' --data_dir 'coNLL_data' --max_seq_len 50\n",
    "!python ../data_preparation.py --task_file tasks_file_SRL.yml --data_dir ../data/coNLL_tsv --max_seq_len 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train.py \\\n",
    "    --data_dir 'content/data/bert-base-uncased_prepared_data' \\\n",
    "    --task_file 'tasks_file_SRL.yml' \\\n",
    "    --out_dir 'conll_ner_pos_bert_base' \\\n",
    "    --epochs 10 \\\n",
    "    --train_batch_size 32 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --grad_accumulation_steps 1 \\\n",
    "    --log_per_updates 50 \\\n",
    "    --max_seq_len 50 \\\n",
    "    --eval_while_train \\\n",
    "    --test_while_train \\\n",
    "    --silent\n",
    "    \n",
    "# python ../train.py --data_dir ../data/coNLL_tsv/bert-base-uncased_prepared_data --task_file tasks_file_SRL.yml --out_dir ../output/ --epochs 10 --train_batch_size 32 --eval_batch_size 32 --grad_accumulation_steps 32 --log_per_updates 50 --max_seq_len 50 --eval_while_train --test_while_train --silent\n",
    "\n",
    "# python ./train.py --data_dir ./data/coNLL_tsv/bert-base-uncased_prepared_data --task_file tasks_file_SRL.yml --out_dir ../output/ --epochs 10 --train_batch_size 32 --eval_batch_size 32 --grad_accumulation_steps 32 --log_per_updates 50 --max_seq_len 50 --eval_while_train --test_while_train --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train.py --data_dir ../data/coNLL_tsv/dmis-lab/biobert-base-cased-v1.2_prepared_data --task_file tasks_file_SRL.yml --out_dir ../output/ --epochs 10 --train_batch_size 32 --eval_batch_size 32 --grad_accumulation_steps 32 --log_per_updates 50 --max_seq_len 50 --eval_while_train --test_while_train --silent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from infer_pipeline import inferPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe = inferPipeline(modelPath='../output/multi_task_model_9_204.pt', maxSeqLen=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to get word representations from biobert model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'embedding.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# run embedding from original biobert (cha duoi terminal)\n",
    "!python embedding.py --data_dir ./data/coNLL_tsv/bert-base-uncased_prepared_data --transform_file word_represent/embedding.yml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to get predictions from biobert model to calculate the f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
