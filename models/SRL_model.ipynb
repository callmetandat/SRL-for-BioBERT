{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../data_transformations.py --transform_file 'transform_file_conll.yml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Current Directory:  /mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/models../data/coNLL_tsv\n",
      "task object created from task file...\n",
      "bert model tokenizer loaded for config bert-base-uncased\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_train.tsv\n",
      "Processing Started...\n",
      "Data Size:  41740\n",
      "number of threads:  7\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|▏                                       | 21/5962 [00:00<00:28, 206.67it/s]\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  1%|▍                                       | 64/5962 [00:00<00:17, 332.22it/s]\n",
      "  0%|▏                                       | 28/5962 [00:00<00:21, 271.81it/s]\u001b[A\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  2%|▋                                       | 98/5962 [00:00<00:19, 301.43it/s]\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  1%|▍                                       | 56/5962 [00:00<00:25, 230.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|                                        | 16/5962 [00:00<00:39, 149.03it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                       | 23/5962 [00:00<00:26, 227.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  2%|▊                                      | 129/5962 [00:00<00:24, 241.63it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                        | 12/5962 [00:00<00:55, 106.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▏                                       | 31/5962 [00:00<00:44, 134.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▎                                       | 50/5962 [00:00<00:23, 249.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "  1%|▌                                       | 80/5962 [00:00<00:30, 190.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/5962 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                       | 24/5962 [00:00<00:55, 107.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▎                                       | 52/5962 [00:00<00:35, 164.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▌                                       | 77/5962 [00:00<00:22, 256.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "  3%|█                                      | 155/5962 [00:00<00:28, 204.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏                                       | 37/5962 [00:00<00:32, 181.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                       | 21/5962 [00:00<00:29, 203.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏                                       | 35/5962 [00:00<00:58, 101.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▍                                       | 69/5962 [00:00<00:36, 159.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▋                                      | 103/5962 [00:00<00:22, 254.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "  2%|▊                                      | 120/5962 [00:00<00:31, 187.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 65/5962 [00:00<00:26, 221.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 45/5962 [00:00<00:26, 222.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  1%|▌                                       | 86/5962 [00:00<00:36, 161.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                     | 177/5962 [00:00<00:34, 170.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▊                                      | 129/5962 [00:00<00:24, 240.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                       | 89/5962 [00:00<00:26, 224.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 70/5962 [00:00<00:25, 233.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  2%|▉                                      | 139/5962 [00:00<00:36, 159.45it/s]\u001b[A\n",
      "\n",
      "  2%|▋                                      | 109/5962 [00:00<00:32, 182.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▍                                       | 61/5962 [00:00<00:51, 113.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                      | 112/5962 [00:00<00:26, 219.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                     | 196/5962 [00:01<00:38, 151.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█                                      | 154/5962 [00:00<00:27, 208.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                       | 77/5962 [00:00<00:46, 127.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                      | 143/5962 [00:00<00:23, 248.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▊                                      | 128/5962 [00:00<00:36, 161.73it/s]\u001b[A\u001b[A\n",
      "  3%|█                                      | 156/5962 [00:00<00:43, 134.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 213/5962 [00:01<00:40, 143.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 95/5962 [00:00<00:41, 142.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 116/5962 [00:00<00:33, 173.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                      | 169/5962 [00:00<00:23, 251.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█                                      | 154/5962 [00:00<00:30, 188.10it/s]\u001b[A\u001b[A\n",
      "  3%|█                                      | 171/5962 [00:01<00:48, 120.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 228/5962 [00:01<00:45, 126.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▎                                     | 197/5962 [00:00<00:35, 160.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                     | 195/5962 [00:00<00:29, 193.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                      | 135/5962 [00:00<00:43, 135.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  3%|█▏                                     | 184/5962 [00:01<00:51, 111.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                      | 123/5962 [00:01<00:45, 127.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▏                                     | 174/5962 [00:01<00:41, 140.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 242/5962 [00:01<00:50, 113.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▉                                      | 151/5962 [00:00<00:41, 139.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                      | 138/5962 [00:01<00:44, 131.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  3%|█▎                                     | 202/5962 [00:01<00:46, 124.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 217/5962 [00:01<00:32, 176.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 233/5962 [00:01<00:35, 160.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▋                                     | 255/5962 [00:01<00:49, 116.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                      | 167/5962 [00:01<00:40, 144.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|▉                                      | 152/5962 [00:01<00:43, 134.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▍                                     | 223/5962 [00:01<00:39, 144.60it/s]\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▊                                     | 268/5962 [00:01<00:48, 117.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 237/5962 [00:01<00:36, 158.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                     | 183/5962 [00:01<00:39, 146.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▎                                     | 206/5962 [00:01<00:45, 125.23it/s]\u001b[A\u001b[A\n",
      "  4%|█▌                                     | 240/5962 [00:01<00:38, 150.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                      | 166/5962 [00:01<00:44, 131.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|█▊                                     | 271/5962 [00:01<00:32, 172.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                     | 200/5962 [00:01<00:37, 152.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▍                                     | 221/5962 [00:01<00:44, 130.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 255/5962 [00:01<00:37, 150.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▋                                     | 256/5962 [00:01<00:38, 146.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                     | 281/5962 [00:01<00:54, 103.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 289/5962 [00:01<00:34, 163.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 216/5962 [00:01<00:37, 154.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▌                                     | 238/5962 [00:01<00:40, 139.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                     | 277/5962 [00:01<00:34, 166.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▊                                     | 277/5962 [00:01<00:36, 157.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                      | 292/5962 [00:02<00:58, 97.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 233/5962 [00:01<00:36, 155.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                     | 306/5962 [00:01<00:37, 149.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 305/5962 [00:01<00:29, 194.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▉                                     | 298/5962 [00:01<00:33, 171.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 304/5962 [00:02<00:55, 102.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  5%|█▊                                     | 269/5962 [00:01<00:39, 142.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 249/5962 [00:01<00:38, 147.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                    | 326/5962 [00:01<00:29, 191.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                     | 222/5962 [00:01<00:43, 132.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|██                                     | 322/5962 [00:01<00:41, 134.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "  5%|██▏                                    | 326/5962 [00:02<00:42, 131.84it/s]\u001b[A\n",
      "\n",
      "  5%|█▉                                     | 288/5962 [00:01<00:36, 155.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 265/5962 [00:01<00:38, 149.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 352/5962 [00:01<00:26, 208.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 239/5962 [00:01<00:40, 141.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 344/5962 [00:02<00:39, 143.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▏                                    | 333/5962 [00:02<00:37, 152.03it/s]\u001b[A\n",
      "\n",
      "  5%|█▉                                     | 304/5962 [00:02<00:36, 156.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 289/5962 [00:01<00:32, 174.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▌                                    | 383/5962 [00:01<00:23, 234.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 264/5962 [00:01<00:33, 171.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 365/5962 [00:02<00:35, 158.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▎                                    | 349/5962 [00:02<00:38, 146.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                    | 326/5962 [00:01<00:24, 229.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  5%|██                                     | 320/5962 [00:02<00:37, 149.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 410/5962 [00:02<00:22, 242.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 289/5962 [00:02<00:29, 192.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 382/5962 [00:02<00:35, 156.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 359/5962 [00:01<00:21, 258.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 364/5962 [00:02<00:40, 139.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▉                                    | 443/5962 [00:02<00:20, 266.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|██                                     | 313/5962 [00:02<00:27, 205.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 402/5962 [00:02<00:33, 167.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▎                                    | 357/5962 [00:02<00:33, 166.54it/s]\u001b[A\u001b[A\n",
      "  6%|██▍                                    | 380/5962 [00:02<00:39, 142.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 336/5962 [00:02<00:27, 208.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▌                                    | 386/5962 [00:02<00:24, 224.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▊                                    | 425/5962 [00:02<00:28, 197.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▊                                    | 428/5962 [00:02<00:28, 193.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▍                                    | 382/5962 [00:02<00:29, 190.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                    | 357/5962 [00:02<00:27, 200.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|██▉                                    | 448/5962 [00:02<00:29, 186.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▌                                    | 395/5962 [00:02<00:47, 117.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 410/5962 [00:02<00:27, 200.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 497/5962 [00:02<00:27, 202.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███                                    | 470/5962 [00:02<00:26, 207.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 378/5962 [00:02<00:29, 186.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▋                                    | 408/5962 [00:02<00:48, 114.88it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 467/5962 [00:02<00:32, 166.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▊                                    | 423/5962 [00:02<00:29, 185.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 522/5962 [00:02<00:25, 212.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 503/5962 [00:02<00:22, 240.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▌                                    | 397/5962 [00:02<00:31, 178.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▊                                    | 431/5962 [00:02<00:39, 139.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 485/5962 [00:03<00:33, 163.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 545/5962 [00:02<00:28, 193.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 528/5962 [00:02<00:23, 227.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▉                                    | 442/5962 [00:02<00:35, 156.59it/s]\u001b[A\u001b[A\n",
      "  8%|██▉                                    | 450/5962 [00:03<00:36, 152.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 475/5962 [00:02<00:27, 200.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 502/5962 [00:03<00:33, 165.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 566/5962 [00:02<00:27, 196.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 562/5962 [00:02<00:21, 250.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "  8%|███                                    | 470/5962 [00:03<00:33, 164.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 523/5962 [00:03<00:31, 171.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███                                    | 459/5962 [00:03<00:39, 138.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▊                                    | 433/5962 [00:02<00:35, 154.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 589/5962 [00:02<00:26, 200.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 519/5962 [00:02<00:26, 203.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▌                                   | 544/5962 [00:03<00:30, 177.36it/s]\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 588/5962 [00:03<00:25, 210.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|██▉                                    | 449/5962 [00:03<00:40, 135.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 564/5962 [00:03<00:29, 183.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 611/5962 [00:03<00:24, 214.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███                                    | 474/5962 [00:03<00:49, 109.99it/s]\u001b[A\u001b[A\n",
      "  9%|███▎                                   | 510/5962 [00:03<00:37, 146.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 610/5962 [00:03<00:35, 150.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 469/5962 [00:03<00:36, 148.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 562/5962 [00:03<00:26, 207.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 639/5962 [00:03<00:22, 231.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███▏                                   | 487/5962 [00:03<00:51, 107.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 493/5962 [00:03<00:32, 169.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████                                   | 628/5962 [00:03<00:35, 149.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▍                                   | 526/5962 [00:03<00:40, 133.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 583/5962 [00:03<00:27, 195.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 664/5962 [00:03<00:23, 228.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▉                                   | 600/5962 [00:03<00:34, 153.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 646/5962 [00:03<00:35, 151.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▎                                   | 511/5962 [00:03<00:34, 157.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 603/5962 [00:03<00:28, 190.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 688/5962 [00:03<00:24, 219.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▌                                   | 540/5962 [00:03<00:48, 110.87it/s]\u001b[A\n",
      "\n",
      "  9%|███▍                                    | 511/5962 [00:03<00:54, 99.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 528/5962 [00:03<00:34, 157.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 623/5962 [00:03<00:28, 186.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 663/5962 [00:03<00:37, 142.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|████                                   | 616/5962 [00:03<00:40, 131.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▍                                   | 529/5962 [00:03<00:46, 117.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 550/5962 [00:03<00:31, 170.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 683/5962 [00:03<00:34, 155.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▋                                    | 552/5962 [00:03<00:55, 97.63it/s]\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 738/5962 [00:03<00:23, 224.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████                                   | 630/5962 [00:04<00:42, 124.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▌                                   | 549/5962 [00:03<00:39, 137.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 582/5962 [00:03<00:25, 210.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 703/5962 [00:03<00:32, 163.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████                                  | 768/5962 [00:03<00:21, 239.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 661/5962 [00:03<00:30, 171.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▊                                    | 563/5962 [00:04<00:59, 90.80it/s]\u001b[A\n",
      "\n",
      " 11%|████▏                                  | 643/5962 [00:04<00:46, 115.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 604/5962 [00:03<00:25, 211.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 724/5962 [00:03<00:30, 174.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 795/5962 [00:03<00:20, 246.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 682/5962 [00:03<00:29, 179.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▊                                    | 577/5962 [00:04<00:53, 99.76it/s]\u001b[A\n",
      "\n",
      " 11%|████▎                                  | 662/5962 [00:04<00:40, 131.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 742/5962 [00:03<00:31, 168.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 626/5962 [00:03<00:29, 183.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 703/5962 [00:03<00:28, 184.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 820/5962 [00:04<00:22, 228.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████                                   | 628/5962 [00:04<00:24, 217.93it/s]\u001b[A\u001b[A\n",
      " 12%|████▌                                  | 694/5962 [00:04<00:29, 178.98it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 767/5962 [00:04<00:28, 182.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 729/5962 [00:03<00:25, 202.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 844/5962 [00:04<00:22, 228.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                  | 646/5962 [00:04<00:30, 171.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▋                                  | 715/5962 [00:04<00:28, 187.02it/s]\u001b[A\n",
      "\n",
      " 11%|████▎                                  | 651/5962 [00:04<00:28, 188.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 753/5962 [00:04<00:25, 206.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 870/5962 [00:04<00:21, 235.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 736/5962 [00:04<00:27, 192.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▎                                  | 658/5962 [00:04<00:29, 181.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 664/5962 [00:04<00:32, 163.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████▍                                  | 674/5962 [00:04<00:27, 193.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 785/5962 [00:04<00:21, 237.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 756/5962 [00:04<00:26, 193.47it/s]\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▍                                  | 680/5962 [00:04<00:27, 191.88it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 693/5962 [00:04<00:27, 193.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▎                                 | 804/5962 [00:04<00:33, 153.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 821/5962 [00:04<00:18, 271.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 12%|████▌                                  | 695/5962 [00:04<00:27, 189.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 15%|██████                                 | 921/5962 [00:04<00:20, 242.07it/s]\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▌                                  | 704/5962 [00:04<00:25, 204.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 776/5962 [00:04<00:29, 177.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 820/5962 [00:04<00:34, 147.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 849/5962 [00:04<00:19, 259.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 946/5962 [00:04<00:22, 226.87it/s]\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▋                                  | 726/5962 [00:04<00:25, 201.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 748/5962 [00:04<00:22, 229.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████▏                                 | 796/5962 [00:05<00:28, 178.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 836/5962 [00:04<00:34, 146.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 883/5962 [00:04<00:18, 277.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 970/5962 [00:04<00:21, 227.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 772/5962 [00:04<00:23, 224.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 852/5962 [00:04<00:34, 149.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|████▉                                  | 747/5962 [00:04<00:31, 167.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 912/5962 [00:04<00:18, 270.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 996/5962 [00:04<00:21, 234.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 796/5962 [00:04<00:25, 203.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|████▉                                  | 750/5962 [00:04<00:33, 154.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 833/5962 [00:05<00:31, 162.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1020/5962 [00:04<00:21, 235.03it/s]\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████                                  | 765/5962 [00:05<00:36, 144.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 826/5962 [00:04<00:22, 227.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████                                  | 766/5962 [00:05<00:33, 155.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 940/5962 [00:04<00:22, 226.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 850/5962 [00:05<00:31, 161.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▋                               | 1047/5962 [00:05<00:20, 245.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████                                  | 782/5962 [00:05<00:34, 149.70it/s]\u001b[A\u001b[A\n",
      " 13%|█████                                  | 781/5962 [00:05<00:39, 132.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 867/5962 [00:05<00:35, 141.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1072/5962 [00:05<00:22, 212.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 964/5962 [00:04<00:26, 189.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████▏                                 | 798/5962 [00:05<00:34, 151.24it/s]\u001b[A\u001b[A\n",
      " 13%|█████▏                                 | 796/5962 [00:05<00:38, 135.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 850/5962 [00:05<00:31, 163.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 890/5962 [00:05<00:30, 163.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 870/5962 [00:05<00:30, 169.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▎                                 | 819/5962 [00:05<00:33, 153.15it/s]\u001b[A\n",
      "\n",
      " 14%|█████▎                                 | 814/5962 [00:05<00:36, 139.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 910/5962 [00:05<00:29, 172.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████                               | 1116/5962 [00:05<00:25, 188.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                               | 1005/5962 [00:05<00:29, 169.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▍                                 | 840/5962 [00:05<00:31, 164.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 890/5962 [00:05<00:29, 169.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████                                 | 928/5962 [00:05<00:29, 172.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 937/5962 [00:05<00:41, 120.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1136/5962 [00:05<00:25, 190.23it/s]\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▌                                 | 858/5962 [00:05<00:30, 165.77it/s]\u001b[A\n",
      "\n",
      " 14%|█████▌                                 | 844/5962 [00:05<00:37, 137.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 909/5962 [00:05<00:29, 168.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 948/5962 [00:05<00:28, 175.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 950/5962 [00:05<00:46, 108.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▍                              | 1160/5962 [00:05<00:23, 202.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 928/5962 [00:05<00:28, 173.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▋                                 | 876/5962 [00:05<00:31, 160.00it/s]\u001b[A\n",
      "\n",
      " 16%|██████▎                                | 966/5962 [00:06<00:28, 175.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                               | 1040/5962 [00:05<00:32, 153.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1182/5962 [00:05<00:23, 203.56it/s]\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▊                                 | 894/5962 [00:05<00:30, 164.70it/s]\u001b[A\n",
      "\n",
      " 15%|█████▋                                 | 878/5962 [00:05<00:33, 150.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                                | 984/5962 [00:06<00:29, 166.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▋                               | 1056/5962 [00:05<00:32, 149.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▋                              | 1203/5962 [00:05<00:23, 204.78it/s]\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▉                                 | 911/5962 [00:06<00:30, 163.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                 | 973/5962 [00:05<00:50, 99.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 947/5962 [00:05<00:37, 133.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▍                               | 1003/5962 [00:06<00:29, 168.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1076/5962 [00:05<00:30, 161.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1225/5962 [00:05<00:23, 204.95it/s]\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████                                 | 931/5962 [00:06<00:29, 168.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                 | 984/5962 [00:05<00:53, 93.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▌                               | 1020/5962 [00:06<00:31, 155.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1093/5962 [00:05<00:32, 150.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 963/5962 [00:06<00:40, 122.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1246/5962 [00:06<00:26, 179.22it/s]\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████▏                                | 949/5962 [00:06<00:32, 156.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                 | 994/5962 [00:06<00:53, 92.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|██████                                 | 924/5962 [00:06<00:38, 130.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1036/5962 [00:06<00:34, 144.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 977/5962 [00:06<00:41, 118.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 1004/5962 [00:06<00:53, 93.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████                              | 1265/5962 [00:06<00:29, 158.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1127/5962 [00:06<00:31, 153.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▋                               | 1051/5962 [00:06<00:36, 134.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                                | 990/5962 [00:06<00:44, 112.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████▎                                | 965/5962 [00:06<00:39, 125.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1022/5962 [00:06<00:42, 116.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▏                             | 1286/5962 [00:06<00:27, 170.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1148/5962 [00:06<00:28, 167.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▊                               | 1069/5962 [00:06<00:33, 144.24it/s]\u001b[A\u001b[A\n",
      " 16%|██████▍                                | 979/5962 [00:06<00:40, 124.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                               | 1042/5962 [00:06<00:35, 137.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                               | 1002/5962 [00:06<00:46, 106.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1310/5962 [00:06<00:25, 184.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▍                              | 1171/5962 [00:06<00:25, 184.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▉                               | 1089/5962 [00:06<00:30, 158.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                               | 1061/5962 [00:06<00:32, 151.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▍                                | 993/5962 [00:06<00:42, 117.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▍                               | 1014/5962 [00:06<00:47, 103.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1190/5962 [00:06<00:26, 180.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████                               | 1114/5962 [00:06<00:26, 182.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▍                                | 976/5962 [00:06<00:42, 116.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1085/5962 [00:06<00:27, 176.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▍                               | 1006/5962 [00:06<00:42, 117.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▋                                | 1025/5962 [00:06<00:50, 98.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1144/5962 [00:07<00:22, 215.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▍                                | 988/5962 [00:06<00:43, 114.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1348/5962 [00:06<00:29, 158.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████                               | 1114/5962 [00:06<00:23, 206.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▍                               | 1019/5962 [00:06<00:42, 116.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                               | 1036/5962 [00:06<00:48, 100.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1231/5962 [00:06<00:25, 182.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▍                              | 1167/5962 [00:07<00:23, 202.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1365/5962 [00:06<00:28, 161.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1139/5962 [00:06<00:22, 217.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▌                               | 1034/5962 [00:07<00:39, 125.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1188/5962 [00:07<00:23, 202.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▍                               | 1019/5962 [00:06<00:39, 126.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                                | 1047/5962 [00:06<00:53, 92.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1382/5962 [00:06<00:29, 152.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                              | 1161/5962 [00:06<00:24, 199.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▋                               | 1047/5962 [00:07<00:40, 122.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                              | 1211/5962 [00:07<00:22, 209.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▌                               | 1032/5962 [00:07<00:39, 123.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 1057/5962 [00:07<00:53, 92.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▌                              | 1182/5962 [00:06<00:23, 201.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▉                             | 1398/5962 [00:07<00:32, 141.33it/s]\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▊                               | 1062/5962 [00:07<00:38, 126.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1233/5962 [00:07<00:22, 211.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 1068/5962 [00:07<00:50, 96.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|██████▋                               | 1048/5962 [00:07<00:38, 129.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                              | 1209/5962 [00:07<00:21, 216.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████                             | 1413/5962 [00:07<00:31, 142.43it/s]\u001b[A\u001b[A\u001b[A\n",
      " 18%|██████▉                               | 1080/5962 [00:07<00:34, 140.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                              | 1258/5962 [00:07<00:21, 221.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1080/5962 [00:07<00:47, 102.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1231/5962 [00:07<00:22, 214.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1432/5962 [00:07<00:29, 153.46it/s]\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▏                             | 1281/5962 [00:07<00:21, 222.36it/s]\u001b[A\n",
      "\n",
      " 18%|██████▊                               | 1061/5962 [00:07<00:47, 102.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                               | 1091/5962 [00:07<00:48, 100.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1344/5962 [00:07<00:26, 173.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1448/5962 [00:07<00:31, 145.18it/s]\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████                               | 1109/5962 [00:07<00:38, 126.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1253/5962 [00:07<00:27, 171.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████                                | 1073/5962 [00:07<00:50, 97.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1304/5962 [00:07<00:25, 184.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1363/5962 [00:07<00:28, 164.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▎                            | 1463/5962 [00:07<00:33, 135.86it/s]\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▏                              | 1128/5962 [00:07<00:33, 143.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                              | 1273/5962 [00:07<00:26, 176.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                               | 1114/5962 [00:07<00:48, 99.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████                                | 1084/5962 [00:07<00:50, 95.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1381/5962 [00:07<00:27, 164.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▍                             | 1324/5962 [00:08<00:27, 166.21it/s]\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1477/5962 [00:07<00:35, 127.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1303/5962 [00:07<00:22, 205.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                              | 1126/5962 [00:07<00:46, 103.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|████████▉                             | 1403/5962 [00:07<00:25, 176.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████▏                               | 1094/5962 [00:07<00:54, 89.89it/s]\u001b[A\u001b[A\n",
      " 20%|███████▍                              | 1165/5962 [00:07<00:31, 154.03it/s]\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1342/5962 [00:08<00:32, 142.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                               | 1137/5962 [00:07<00:49, 96.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▏                               | 1104/5962 [00:07<00:52, 92.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1325/5962 [00:07<00:26, 177.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▌                              | 1181/5962 [00:08<00:30, 155.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████                             | 1422/5962 [00:07<00:27, 162.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1358/5962 [00:08<00:31, 145.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                              | 1153/5962 [00:07<00:43, 111.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▌                             | 1345/5962 [00:07<00:26, 176.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▋                              | 1202/5962 [00:08<00:28, 169.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1440/5962 [00:07<00:27, 165.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1522/5962 [00:08<00:33, 133.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▊                             | 1374/5962 [00:08<00:31, 145.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▍                              | 1167/5962 [00:08<00:41, 116.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1367/5962 [00:07<00:24, 186.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|███████▊                              | 1230/5962 [00:08<00:23, 197.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▎                            | 1461/5962 [00:07<00:25, 174.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1536/5962 [00:08<00:33, 133.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▎                              | 1156/5962 [00:08<00:33, 143.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1391/5962 [00:08<00:31, 146.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|███████▉                              | 1250/5962 [00:08<00:24, 191.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1488/5962 [00:07<00:22, 198.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1554/5962 [00:08<00:30, 143.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▍                              | 1174/5962 [00:08<00:31, 152.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1387/5962 [00:08<00:30, 152.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|████████▉                             | 1407/5962 [00:08<00:30, 147.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▏                             | 1277/5962 [00:08<00:21, 213.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▋                            | 1516/5962 [00:08<00:20, 220.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████                            | 1571/5962 [00:08<00:29, 149.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████                             | 1423/5962 [00:08<00:31, 144.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                              | 1215/5962 [00:08<00:36, 131.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|████████▉                             | 1404/5962 [00:08<00:31, 146.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1547/5962 [00:08<00:18, 245.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████                            | 1588/5962 [00:08<00:28, 152.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▏                            | 1438/5962 [00:08<00:30, 146.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████                            | 1575/5962 [00:08<00:17, 253.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████                             | 1425/5962 [00:08<00:30, 150.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▊                              | 1229/5962 [00:08<00:39, 119.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▍                             | 1326/5962 [00:08<00:23, 200.23it/s]\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▎                            | 1453/5962 [00:08<00:30, 146.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|███████▊                              | 1229/5962 [00:08<00:30, 154.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1442/5962 [00:08<00:29, 153.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|███████▉                              | 1242/5962 [00:08<00:39, 120.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▌                             | 1350/5962 [00:08<00:21, 210.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1601/5962 [00:08<00:19, 220.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▍                           | 1628/5962 [00:08<00:25, 169.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▎                            | 1468/5962 [00:09<00:33, 133.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                              | 1262/5962 [00:08<00:33, 141.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▊                             | 1377/5962 [00:08<00:20, 226.13it/s]\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1651/5962 [00:08<00:23, 181.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                            | 1458/5962 [00:08<00:33, 136.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1625/5962 [00:08<00:21, 201.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▏                             | 1284/5962 [00:08<00:22, 210.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1482/5962 [00:09<00:36, 123.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1674/5962 [00:08<00:22, 194.89it/s]\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▉                             | 1401/5962 [00:09<00:22, 201.19it/s]\u001b[A\n",
      "\n",
      " 22%|████████▎                             | 1306/5962 [00:08<00:22, 203.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1473/5962 [00:08<00:35, 124.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▎                             | 1297/5962 [00:08<00:30, 154.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▍                           | 1647/5962 [00:08<00:25, 169.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1495/5962 [00:09<00:40, 110.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▍                             | 1327/5962 [00:09<00:23, 196.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1486/5962 [00:08<00:36, 123.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▍                             | 1322/5962 [00:09<00:25, 178.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▌                            | 1507/5962 [00:09<00:39, 112.65it/s]\u001b[A\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1714/5962 [00:09<00:23, 179.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1666/5962 [00:08<00:27, 157.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▌                             | 1350/5962 [00:09<00:22, 204.51it/s]\u001b[A\u001b[A\n",
      " 24%|█████████▏                            | 1445/5962 [00:09<00:23, 190.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                             | 1341/5962 [00:09<00:25, 179.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▋                            | 1520/5962 [00:09<00:38, 116.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████                           | 1735/5962 [00:09<00:23, 181.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▋                             | 1371/5962 [00:09<00:24, 191.07it/s]\u001b[A\u001b[A\n",
      " 25%|█████████▎                            | 1465/5962 [00:09<00:24, 186.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▋                             | 1360/5962 [00:09<00:26, 170.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1534/5962 [00:09<00:37, 117.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1683/5962 [00:09<00:32, 129.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▏                          | 1754/5962 [00:09<00:23, 179.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 23%|████████▉                             | 1396/5962 [00:09<00:22, 206.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                             | 1381/5962 [00:09<00:25, 181.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▍                            | 1485/5962 [00:09<00:24, 181.47it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1554/5962 [00:09<00:31, 139.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▎                          | 1773/5962 [00:09<00:24, 174.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████                             | 1418/5962 [00:09<00:22, 199.88it/s]\u001b[A\u001b[A\n",
      " 25%|█████████▌                            | 1507/5962 [00:09<00:23, 188.89it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▉                             | 1400/5962 [00:09<00:26, 175.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                           | 1698/5962 [00:09<00:37, 115.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1538/5962 [00:09<00:42, 103.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1439/5962 [00:09<00:23, 193.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▍                          | 1791/5962 [00:09<00:26, 155.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1527/5962 [00:09<00:23, 186.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1711/5962 [00:09<00:37, 114.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████                            | 1583/5962 [00:10<00:33, 131.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 26%|█████████▊                            | 1546/5962 [00:09<00:23, 184.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▏                            | 1436/5962 [00:09<00:28, 158.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▎                            | 1459/5962 [00:09<00:26, 170.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1724/5962 [00:09<00:38, 111.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▌                          | 1807/5962 [00:09<00:32, 129.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1563/5962 [00:09<00:42, 103.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▏                           | 1597/5962 [00:10<00:39, 111.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████                           | 1741/5962 [00:09<00:33, 124.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                            | 1453/5962 [00:09<00:30, 146.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████                            | 1574/5962 [00:09<00:42, 104.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                          | 1755/5962 [00:09<00:34, 121.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▍                            | 1477/5962 [00:10<00:35, 127.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▎                            | 1468/5962 [00:09<00:31, 140.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▌                          | 1821/5962 [00:10<00:39, 103.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████                            | 1585/5962 [00:09<00:42, 103.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▌                            | 1609/5962 [00:10<00:47, 90.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▎                          | 1768/5962 [00:09<00:37, 113.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1833/5962 [00:10<00:41, 100.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▍                            | 1596/5962 [00:10<00:45, 96.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▍                            | 1483/5962 [00:10<00:35, 125.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▌                            | 1492/5962 [00:10<00:38, 117.42it/s]\u001b[A\u001b[A\n",
      " 27%|██████████▏                           | 1599/5962 [00:10<00:32, 134.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▍                          | 1790/5962 [00:10<00:30, 139.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 1620/5962 [00:10<00:55, 77.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████                           | 1844/5962 [00:10<00:42, 97.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1496/5962 [00:10<00:36, 123.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1506/5962 [00:10<00:39, 112.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▋                            | 1630/5962 [00:10<00:53, 80.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1627/5962 [00:10<00:35, 122.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▉                          | 1868/5962 [00:10<00:31, 129.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                            | 1510/5962 [00:10<00:36, 122.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▍                           | 1636/5962 [00:10<00:29, 147.31it/s]\u001b[A\n",
      "\n",
      " 25%|█████████▋                            | 1519/5962 [00:10<00:41, 106.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                            | 1641/5962 [00:10<00:49, 87.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1888/5962 [00:10<00:28, 144.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▍                           | 1642/5962 [00:10<00:34, 125.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|██████████▌                           | 1652/5962 [00:10<00:28, 149.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▋                            | 1523/5962 [00:10<00:40, 108.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 1654/5962 [00:10<00:44, 97.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|█████████▊                            | 1531/5962 [00:10<00:42, 104.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1904/5962 [00:10<00:27, 147.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▌                           | 1658/5962 [00:10<00:32, 134.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|██████████▋                           | 1675/5962 [00:10<00:25, 169.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1670/5962 [00:11<00:38, 111.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1535/5962 [00:10<00:41, 107.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▎                         | 1933/5962 [00:10<00:21, 184.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1673/5962 [00:10<00:31, 136.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|██████████▊                           | 1701/5962 [00:10<00:22, 191.12it/s]\u001b[A\n",
      "\n",
      " 26%|█████████▉                            | 1564/5962 [00:10<00:34, 127.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                           | 1682/5962 [00:11<00:38, 111.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▊                            | 1546/5962 [00:10<00:43, 102.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                           | 1688/5962 [00:10<00:30, 138.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1963/5962 [00:10<00:19, 208.56it/s]\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████                           | 1729/5962 [00:11<00:19, 213.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1917/5962 [00:10<00:22, 182.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|█████████▉                            | 1565/5962 [00:10<00:35, 124.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▊                           | 1695/5962 [00:11<00:37, 113.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▊                           | 1706/5962 [00:10<00:28, 146.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▏                          | 1752/5962 [00:11<00:19, 216.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1589/5962 [00:10<00:28, 152.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1709/5962 [00:11<00:35, 119.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1721/5962 [00:10<00:30, 140.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▎                          | 1775/5962 [00:11<00:23, 177.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1955/5962 [00:10<00:24, 165.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|██████████▉                           | 1722/5962 [00:11<00:39, 107.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▏                           | 1605/5962 [00:11<00:37, 117.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2004/5962 [00:11<00:29, 132.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                          | 1753/5962 [00:11<00:28, 145.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████                           | 1734/5962 [00:11<00:38, 109.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 27%|██████████▌                            | 1609/5962 [00:11<00:44, 97.50it/s]\u001b[A\u001b[A\n",
      " 30%|███████████▍                          | 1795/5962 [00:11<00:26, 155.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▎                          | 1777/5962 [00:11<00:24, 172.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                          | 1746/5962 [00:11<00:38, 108.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2020/5962 [00:11<00:32, 123.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▎                           | 1619/5962 [00:11<00:42, 103.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▌                          | 1812/5962 [00:11<00:26, 156.32it/s]\u001b[A\n",
      "\n",
      " 27%|██████████▌                            | 1620/5962 [00:11<00:45, 95.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2022/5962 [00:11<00:19, 202.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▏                          | 1763/5962 [00:11<00:33, 124.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1829/5962 [00:11<00:26, 157.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2034/5962 [00:11<00:34, 113.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▎                          | 1777/5962 [00:11<00:33, 125.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▋                            | 1642/5962 [00:11<00:44, 97.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2043/5962 [00:11<00:22, 170.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                          | 1818/5962 [00:11<00:27, 149.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2047/5962 [00:11<00:34, 113.87it/s]\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▍                          | 1796/5962 [00:12<00:29, 142.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                            | 1642/5962 [00:11<00:46, 92.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1836/5962 [00:11<00:26, 157.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▌                           | 1656/5962 [00:11<00:40, 105.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2060/5962 [00:11<00:33, 116.85it/s]\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▌                          | 1813/5962 [00:12<00:27, 150.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2062/5962 [00:11<00:26, 147.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 1652/5962 [00:11<00:47, 90.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1854/5962 [00:11<00:25, 162.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1829/5962 [00:12<00:27, 148.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 1662/5962 [00:11<00:49, 87.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████                          | 1888/5962 [00:12<00:29, 139.96it/s]\u001b[A\n",
      "\n",
      " 28%|██████████▋                           | 1682/5962 [00:11<00:38, 111.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2088/5962 [00:11<00:31, 124.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▊                          | 1851/5962 [00:12<00:24, 168.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2078/5962 [00:11<00:32, 120.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▏                         | 1904/5962 [00:12<00:29, 139.48it/s]\u001b[A\n",
      "\n",
      " 28%|██████████▊                           | 1698/5962 [00:12<00:35, 119.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2104/5962 [00:12<00:29, 132.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                          | 1871/5962 [00:12<00:23, 173.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1886/5962 [00:12<00:32, 124.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|██████████▉                           | 1711/5962 [00:12<00:34, 122.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▍                        | 2118/5962 [00:12<00:28, 133.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1890/5962 [00:12<00:23, 171.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▏                         | 1919/5962 [00:12<00:35, 113.25it/s]\u001b[A\n",
      "\n",
      " 29%|███████████                           | 1726/5962 [00:12<00:32, 129.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▉                            | 1681/5962 [00:12<01:02, 68.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2133/5962 [00:12<00:28, 133.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1908/5962 [00:12<00:24, 164.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 2104/5962 [00:12<00:38, 99.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████                           | 1741/5962 [00:12<00:31, 134.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 1689/5962 [00:12<01:03, 67.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2147/5962 [00:12<00:28, 131.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▎                         | 1927/5962 [00:12<00:23, 170.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 2115/5962 [00:12<00:38, 99.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▏                          | 1759/5962 [00:12<00:28, 146.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2161/5962 [00:12<00:29, 130.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 1697/5962 [00:12<01:07, 63.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1944/5962 [00:12<00:39, 101.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2128/5962 [00:12<00:37, 103.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▎                          | 1774/5962 [00:12<00:29, 141.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2175/5962 [00:12<00:28, 130.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1956/5962 [00:12<00:38, 104.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1965/5962 [00:13<00:23, 172.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2143/5962 [00:12<00:34, 112.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▍                          | 1794/5962 [00:12<00:26, 156.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2189/5962 [00:12<00:29, 126.70it/s]\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▋                         | 1981/5962 [00:12<00:28, 139.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1967/5962 [00:12<00:27, 144.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2156/5962 [00:12<00:33, 114.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▌                          | 1811/5962 [00:12<00:26, 159.07it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▏                           | 1712/5962 [00:12<01:11, 59.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▋                         | 1983/5962 [00:13<00:29, 136.55it/s]\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2202/5962 [00:12<00:32, 114.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1983/5962 [00:12<00:29, 133.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2168/5962 [00:12<00:35, 106.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▋                          | 1827/5962 [00:12<00:27, 148.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2003/5962 [00:13<00:26, 150.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2219/5962 [00:12<00:29, 128.84it/s]\u001b[A\u001b[A\u001b[A\n",
      " 34%|████████████▊                         | 2018/5962 [00:13<00:26, 151.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2011/5962 [00:12<00:23, 169.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2180/5962 [00:12<00:34, 109.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▊                          | 1849/5962 [00:13<00:25, 164.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 1725/5962 [00:12<01:15, 55.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2020/5962 [00:13<00:26, 149.01it/s]\u001b[A\u001b[A\u001b[A\n",
      " 34%|████████████▉                         | 2034/5962 [00:13<00:26, 148.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▎                        | 2192/5962 [00:12<00:38, 96.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|███████████▉                          | 1866/5962 [00:13<00:29, 138.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2249/5962 [00:13<00:28, 129.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2036/5962 [00:13<00:27, 140.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|█████████████                         | 2050/5962 [00:13<00:27, 140.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2212/5962 [00:13<00:30, 122.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2051/5962 [00:13<00:27, 140.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▏                        | 2067/5962 [00:13<00:26, 144.87it/s]\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2263/5962 [00:13<00:30, 119.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2045/5962 [00:13<00:30, 130.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|███████████▉                          | 1881/5962 [00:13<00:32, 127.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▍                           | 1753/5962 [00:13<00:52, 79.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2066/5962 [00:13<00:27, 142.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▎                        | 2085/5962 [00:13<00:25, 152.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2069/5962 [00:13<00:25, 154.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2276/5962 [00:13<00:31, 118.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                           | 1764/5962 [00:13<00:50, 83.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▎                        | 2081/5962 [00:13<00:28, 136.50it/s]\u001b[A\n",
      "\n",
      " 32%|████████████▏                         | 1910/5962 [00:13<00:30, 133.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2250/5962 [00:13<00:29, 126.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2288/5962 [00:13<00:31, 118.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2086/5962 [00:13<00:25, 151.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                           | 1776/5962 [00:13<00:45, 92.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▎                        | 2097/5962 [00:14<00:27, 141.96it/s]\u001b[A\n",
      "\n",
      " 32%|████████████▎                         | 1926/5962 [00:13<00:28, 140.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2303/5962 [00:13<00:28, 126.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2267/5962 [00:13<00:27, 134.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2103/5962 [00:13<00:24, 154.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▋                           | 1788/5962 [00:13<00:42, 99.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 36%|█████████████▌                        | 2137/5962 [00:13<00:23, 162.27it/s]\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2316/5962 [00:13<00:29, 124.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2112/5962 [00:14<00:29, 128.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████▎                         | 1941/5962 [00:13<00:34, 117.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 1799/5962 [00:13<00:44, 92.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 36%|█████████████▊                        | 2161/5962 [00:14<00:20, 183.28it/s]\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2126/5962 [00:14<00:29, 130.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2296/5962 [00:13<00:28, 127.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2136/5962 [00:13<00:26, 143.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                          | 1812/5962 [00:13<00:40, 101.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|█████████████▉                        | 2180/5962 [00:14<00:21, 179.26it/s]\u001b[A\n",
      "\n",
      " 33%|████████████▍                         | 1954/5962 [00:14<00:35, 112.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2141/5962 [00:14<00:28, 135.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▋                        | 2153/5962 [00:13<00:25, 147.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2310/5962 [00:13<00:31, 117.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▌                          | 1823/5962 [00:13<00:39, 103.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▋                        | 2155/5962 [00:14<00:28, 134.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2376/5962 [00:14<00:23, 151.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▊                        | 2169/5962 [00:14<00:25, 149.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████                        | 2199/5962 [00:14<00:25, 149.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▋                          | 1834/5962 [00:14<00:39, 103.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|█████████████▉                        | 2186/5962 [00:14<00:24, 153.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▏                       | 2323/5962 [00:14<00:36, 98.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▊                        | 2169/5962 [00:14<00:33, 113.51it/s]\u001b[A\u001b[A\n",
      " 37%|██████████████                        | 2215/5962 [00:14<00:27, 137.30it/s]\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2392/5962 [00:14<00:28, 126.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████                           | 1845/5962 [00:14<00:45, 90.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2207/5962 [00:14<00:22, 168.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2338/5962 [00:14<00:33, 107.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████▉                        | 2181/5962 [00:14<00:33, 113.16it/s]\u001b[A\u001b[A\n",
      " 37%|██████████████▏                       | 2230/5962 [00:14<00:27, 133.69it/s]\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2406/5962 [00:14<00:28, 123.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2226/5962 [00:14<00:21, 171.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2353/5962 [00:14<00:30, 117.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████▉                        | 2194/5962 [00:14<00:32, 115.61it/s]\u001b[A\u001b[A\n",
      " 38%|██████████████▎                       | 2244/5962 [00:14<00:27, 134.20it/s]\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2428/5962 [00:14<00:24, 146.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2252/5962 [00:14<00:18, 196.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                          | 1870/5962 [00:14<00:39, 102.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████                        | 2211/5962 [00:14<00:28, 129.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 38%|██████████████▍                       | 2259/5962 [00:14<00:27, 137.07it/s]\u001b[A\n",
      "\n",
      " 34%|████████████▊                         | 2017/5962 [00:14<00:38, 101.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 2445/5962 [00:14<00:23, 151.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|███████████▉                          | 1881/5962 [00:14<00:40, 100.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2386/5962 [00:14<00:26, 134.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2225/5962 [00:15<00:29, 127.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 38%|██████████████▍                       | 2273/5962 [00:14<00:27, 134.90it/s]\u001b[A\n",
      "\n",
      " 34%|████████████▉                         | 2036/5962 [00:14<00:32, 121.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 2461/5962 [00:14<00:24, 144.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████                          | 1897/5962 [00:14<00:35, 116.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2243/5962 [00:15<00:26, 141.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 38%|██████████████▌                       | 2294/5962 [00:15<00:24, 152.57it/s]\u001b[A\n",
      "\n",
      " 35%|█████████████                         | 2059/5962 [00:14<00:26, 149.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▏                         | 1914/5962 [00:14<00:30, 130.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2424/5962 [00:14<00:21, 162.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2477/5962 [00:14<00:24, 141.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 2264/5962 [00:15<00:23, 159.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▏                        | 2075/5962 [00:14<00:25, 150.26it/s]\u001b[A\u001b[A\n",
      " 39%|██████████████▋                       | 2310/5962 [00:15<00:26, 137.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 2449/5962 [00:14<00:18, 186.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2290/5962 [00:15<00:19, 184.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2306/5962 [00:14<00:28, 126.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▎                        | 2091/5962 [00:15<00:27, 141.83it/s]\u001b[A\u001b[A\n",
      " 39%|██████████████▊                       | 2325/5962 [00:15<00:25, 140.54it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2478/5962 [00:14<00:16, 215.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2309/5962 [00:15<00:19, 183.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1944/5962 [00:15<00:34, 117.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2320/5962 [00:15<00:28, 128.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 39%|██████████████▉                       | 2348/5962 [00:15<00:22, 163.87it/s]\u001b[A\n",
      "\n",
      " 35%|█████████████▍                        | 2106/5962 [00:15<00:27, 139.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2508/5962 [00:14<00:14, 237.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2328/5962 [00:15<00:20, 178.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▍                         | 1957/5962 [00:15<00:34, 116.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2343/5962 [00:15<00:24, 149.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▌                        | 2126/5962 [00:15<00:24, 155.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▏                     | 2537/5962 [00:15<00:13, 252.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2517/5962 [00:15<00:32, 104.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▌                         | 1979/5962 [00:15<00:27, 143.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 2361/5962 [00:15<00:23, 156.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▉                       | 2346/5962 [00:15<00:22, 161.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2382/5962 [00:15<00:21, 163.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2529/5962 [00:15<00:31, 107.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▋                         | 1994/5962 [00:15<00:27, 143.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▊                        | 2169/5962 [00:15<00:22, 170.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 2378/5962 [00:15<00:25, 138.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████                       | 2363/5962 [00:15<00:25, 138.87it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▏                     | 2542/5962 [00:15<00:30, 111.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▊                         | 2011/5962 [00:15<00:26, 150.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2594/5962 [00:15<00:16, 207.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|█████████████▉                        | 2188/5962 [00:15<00:21, 173.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2395/5962 [00:15<00:24, 143.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████▏                      | 2378/5962 [00:16<00:26, 137.60it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2556/5962 [00:15<00:29, 116.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|████████████▉                         | 2027/5962 [00:15<00:27, 145.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2617/5962 [00:15<00:15, 209.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████                        | 2216/5962 [00:15<00:18, 200.67it/s]\u001b[A\u001b[A\n",
      " 41%|███████████████▌                      | 2443/5962 [00:15<00:19, 178.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2411/5962 [00:15<00:24, 143.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2569/5962 [00:15<00:29, 116.25it/s]\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                         | 2047/5962 [00:15<00:24, 160.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2393/5962 [00:16<00:28, 125.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▎                       | 2247/5962 [00:15<00:16, 225.67it/s]\u001b[A\u001b[A\n",
      " 41%|███████████████▋                      | 2462/5962 [00:16<00:19, 180.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2426/5962 [00:15<00:24, 145.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 2586/5962 [00:15<00:26, 127.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▏                        | 2064/5962 [00:15<00:24, 157.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 2667/5962 [00:15<00:16, 205.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2406/5962 [00:16<00:33, 106.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2600/5962 [00:15<00:25, 130.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▎                        | 2084/5962 [00:15<00:23, 166.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▊                      | 2481/5962 [00:16<00:22, 155.58it/s]\u001b[A\n",
      "\n",
      " 38%|██████████████▍                       | 2270/5962 [00:16<00:20, 177.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2690/5962 [00:15<00:15, 205.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 2456/5962 [00:15<00:25, 136.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▍                        | 2102/5962 [00:16<00:22, 169.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                       | 2418/5962 [00:16<00:39, 89.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▉                      | 2498/5962 [00:16<00:26, 132.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                    | 2712/5962 [00:15<00:17, 184.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2614/5962 [00:16<00:33, 101.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▌                        | 2124/5962 [00:16<00:21, 182.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▌                       | 2290/5962 [00:16<00:26, 139.19it/s]\u001b[A\u001b[A\n",
      " 42%|████████████████                      | 2513/5962 [00:16<00:29, 117.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2486/5962 [00:16<00:29, 115.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2732/5962 [00:16<00:20, 158.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 2428/5962 [00:16<00:46, 75.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|█████████████████▏                     | 2626/5962 [00:16<00:41, 80.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▋                       | 2307/5962 [00:16<00:29, 123.69it/s]\u001b[A\u001b[A\n",
      " 42%|████████████████▏                     | 2532/5962 [00:16<00:25, 132.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2501/5962 [00:16<00:28, 123.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2753/5962 [00:16<00:18, 169.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 2438/5962 [00:16<00:44, 78.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▊                       | 2322/5962 [00:16<00:28, 128.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      " 43%|████████████████▎                     | 2550/5962 [00:16<00:24, 141.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▋                    | 2775/5962 [00:16<00:17, 181.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 2529/5962 [00:16<00:21, 160.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 2447/5962 [00:16<00:44, 78.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▉                       | 2347/5962 [00:16<00:23, 155.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|█████████████████▎                     | 2648/5962 [00:16<00:37, 89.19it/s]\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▎                     | 2566/5962 [00:16<00:23, 144.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2797/5962 [00:16<00:16, 191.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 2458/5962 [00:17<00:43, 81.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 2664/5962 [00:16<00:31, 103.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████                       | 2365/5962 [00:16<00:23, 150.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▏                       | 2218/5962 [00:16<00:23, 162.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▍                     | 2582/5962 [00:16<00:23, 143.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2566/5962 [00:16<00:20, 168.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████▏                      | 2467/5962 [00:17<00:44, 77.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2680/5962 [00:16<00:28, 115.50it/s]\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▌                     | 2604/5962 [00:17<00:20, 163.80it/s]\u001b[A\n",
      "\n",
      " 40%|███████████████▏                      | 2382/5962 [00:16<00:23, 150.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▌                     | 2591/5962 [00:16<00:17, 190.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2237/5962 [00:16<00:24, 151.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2486/5962 [00:17<00:33, 102.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2693/5962 [00:16<00:27, 117.31it/s]\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▋                     | 2624/5962 [00:17<00:19, 170.53it/s]\u001b[A\n",
      "\n",
      " 40%|███████████████▎                      | 2402/5962 [00:17<00:22, 159.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2611/5962 [00:16<00:17, 186.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2505/5962 [00:17<00:28, 123.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▎                       | 2254/5962 [00:17<00:26, 138.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2706/5962 [00:17<00:27, 117.69it/s]\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▉                     | 2649/5962 [00:17<00:17, 191.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▊                     | 2633/5962 [00:16<00:17, 193.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▍                   | 2884/5962 [00:16<00:15, 197.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|████████████████▏                     | 2530/5962 [00:17<00:21, 156.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2275/5962 [00:17<00:24, 149.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▎                    | 2719/5962 [00:17<00:27, 118.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▉                     | 2653/5962 [00:17<00:18, 183.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████                     | 2669/5962 [00:17<00:18, 176.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2911/5962 [00:17<00:14, 215.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|████████████████▎                     | 2552/5962 [00:17<00:19, 173.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▌                       | 2292/5962 [00:17<00:23, 154.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▏                    | 2692/5962 [00:17<00:17, 190.09it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 2672/5962 [00:17<00:18, 180.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2732/5962 [00:17<00:31, 104.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▋                   | 2935/5962 [00:17<00:13, 220.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|████████████████▍                     | 2571/5962 [00:17<00:20, 163.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 2309/5962 [00:17<00:24, 150.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▎                    | 2712/5962 [00:17<00:18, 180.34it/s]\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2750/5962 [00:17<00:26, 122.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 2959/5962 [00:17<00:13, 222.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2691/5962 [00:17<00:19, 164.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▌                     | 2595/5962 [00:17<00:18, 181.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 2325/5962 [00:17<00:23, 151.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▋                    | 2771/5962 [00:17<00:22, 142.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2985/5962 [00:17<00:12, 231.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                    | 2708/5962 [00:17<00:20, 160.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▋                     | 2618/5962 [00:17<00:17, 193.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 2341/5962 [00:17<00:23, 153.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 2731/5962 [00:17<00:21, 152.15it/s]\u001b[A\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2791/5962 [00:17<00:20, 157.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▏                  | 3013/5962 [00:17<00:12, 243.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2727/5962 [00:17<00:19, 166.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▊                     | 2641/5962 [00:18<00:16, 203.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████                       | 2363/5962 [00:17<00:21, 166.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▌                    | 2748/5962 [00:17<00:22, 142.72it/s]\u001b[A\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2808/5962 [00:17<00:19, 159.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3038/5962 [00:17<00:11, 244.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 2665/5962 [00:18<00:15, 209.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 2395/5962 [00:17<00:17, 209.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▌                    | 2763/5962 [00:18<00:22, 144.39it/s]\u001b[A\n",
      "\n",
      " 43%|████████████████▏                     | 2539/5962 [00:17<00:22, 153.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▌                  | 3063/5962 [00:17<00:13, 213.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2687/5962 [00:18<00:18, 179.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|████████████████▎                     | 2556/5962 [00:18<00:22, 154.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 2417/5962 [00:17<00:19, 178.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 47%|█████████████████▋                    | 2778/5962 [00:18<00:23, 134.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 3086/5962 [00:17<00:13, 216.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2785/5962 [00:17<00:18, 169.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                    | 2710/5962 [00:18<00:16, 192.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|████████████████▍                     | 2576/5962 [00:18<00:20, 165.43it/s]\u001b[A\u001b[A\n",
      " 47%|█████████████████▉                    | 2807/5962 [00:18<00:18, 172.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 2436/5962 [00:18<00:21, 166.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3113/5962 [00:17<00:12, 227.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2803/5962 [00:18<00:19, 165.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2734/5962 [00:18<00:15, 204.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▌                     | 2594/5962 [00:18<00:20, 164.10it/s]\u001b[A\u001b[A\n",
      " 47%|██████████████████                    | 2830/5962 [00:18<00:16, 184.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3139/5962 [00:18<00:12, 234.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████                    | 2831/5962 [00:18<00:16, 194.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▋                    | 2766/5962 [00:18<00:13, 235.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2868/5962 [00:18<00:24, 125.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▋                     | 2612/5962 [00:18<00:19, 168.05it/s]\u001b[A\u001b[A\n",
      " 48%|██████████████████▏                   | 2850/5962 [00:18<00:16, 188.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3165/5962 [00:18<00:11, 234.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2851/5962 [00:18<00:15, 195.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▊                    | 2791/5962 [00:18<00:13, 237.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▎                   | 2870/5962 [00:18<00:16, 189.42it/s]\u001b[A\n",
      "\n",
      " 44%|████████████████▊                     | 2634/5962 [00:18<00:18, 178.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2881/5962 [00:18<00:26, 117.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▎                 | 3189/5962 [00:18<00:12, 230.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2874/5962 [00:18<00:15, 205.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 2488/5962 [00:18<00:21, 158.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▍                   | 2894/5962 [00:18<00:27, 112.70it/s]\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▍                   | 2890/5962 [00:18<00:18, 169.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2816/5962 [00:18<00:15, 201.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▍                   | 2895/5962 [00:18<00:15, 197.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▉                      | 2510/5962 [00:18<00:20, 169.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3236/5962 [00:18<00:12, 225.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2916/5962 [00:18<00:15, 196.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████                    | 2906/5962 [00:18<00:30, 99.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████                     | 2670/5962 [00:18<00:23, 141.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████                    | 2838/5962 [00:19<00:18, 165.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3260/5962 [00:18<00:11, 229.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▋                   | 2940/5962 [00:18<00:14, 208.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|██████████████████▋                   | 2931/5962 [00:18<00:17, 176.04it/s]\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████                    | 2917/5962 [00:18<00:30, 98.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████▏                    | 2695/5962 [00:18<00:19, 166.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▏                     | 2544/5962 [00:18<00:23, 143.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2962/5962 [00:18<00:14, 209.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▏                   | 2857/5962 [00:19<00:20, 154.92it/s]\u001b[A\n",
      "\n",
      " 46%|█████████████████▍                    | 2727/5962 [00:18<00:15, 202.69it/s]\n",
      "\n",
      "\n",
      " 49%|██████████████████▊                   | 2944/5962 [00:18<00:21, 137.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3283/5962 [00:18<00:14, 179.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 2559/5962 [00:18<00:25, 134.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2984/5962 [00:18<00:15, 190.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 2960/5962 [00:19<00:20, 143.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▎                   | 2874/5962 [00:19<00:23, 134.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 2577/5962 [00:19<00:23, 145.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|███████████████████▏                  | 3002/5962 [00:19<00:14, 203.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 3303/5962 [00:18<00:15, 167.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▏                  | 3004/5962 [00:19<00:15, 189.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2979/5962 [00:19<00:19, 154.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▍                   | 2896/5962 [00:19<00:20, 150.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 2597/5962 [00:19<00:21, 159.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 51%|███████████████████▍                  | 3040/5962 [00:19<00:11, 253.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3323/5962 [00:18<00:15, 173.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2997/5962 [00:19<00:18, 160.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2916/5962 [00:19<00:18, 160.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 2617/5962 [00:19<00:19, 170.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|█████████████████▊                    | 2801/5962 [00:19<00:16, 191.59it/s]\u001b[A\u001b[A\n",
      " 51%|███████████████████▌                  | 3067/5962 [00:19<00:11, 247.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▏                  | 3014/5962 [00:19<00:18, 156.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 3044/5962 [00:19<00:16, 176.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▋                   | 2934/5962 [00:19<00:18, 161.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|█████████████████▉                    | 2822/5962 [00:19<00:16, 195.17it/s]\u001b[A\u001b[A\n",
      " 52%|███████████████████▋                  | 3093/5962 [00:19<00:11, 242.54it/s]\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3038/5962 [00:19<00:16, 178.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 3359/5962 [00:19<00:16, 158.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▌                  | 3067/5962 [00:19<00:15, 190.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▊                   | 2951/5962 [00:19<00:18, 163.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▏                   | 2853/5962 [00:19<00:13, 222.84it/s]\u001b[A\u001b[A\n",
      " 52%|███████████████████▉                  | 3127/5962 [00:19<00:10, 268.01it/s]\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▌                  | 3061/5962 [00:19<00:15, 192.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3376/5962 [00:19<00:16, 157.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3099/5962 [00:19<00:12, 224.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2974/5962 [00:19<00:16, 178.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▎                   | 2876/5962 [00:19<00:14, 216.02it/s]\u001b[A\u001b[A\n",
      " 53%|████████████████████                  | 3155/5962 [00:19<00:10, 262.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 3398/5962 [00:19<00:14, 174.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▉                  | 3127/5962 [00:19<00:11, 236.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2993/5962 [00:20<00:16, 178.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|██████████████████▌                   | 2907/5962 [00:19<00:12, 240.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 2696/5962 [00:19<00:18, 176.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3426/5962 [00:19<00:12, 202.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▎                 | 3182/5962 [00:19<00:12, 224.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▏                  | 3012/5962 [00:20<00:17, 170.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3099/5962 [00:19<00:18, 152.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▎                    | 2714/5962 [00:19<00:19, 163.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3030/5962 [00:20<00:17, 163.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 2731/5962 [00:19<00:19, 164.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 54%|████████████████████▍                 | 3206/5962 [00:20<00:14, 189.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3475/5962 [00:19<00:11, 213.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3116/5962 [00:20<00:21, 134.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▍                  | 3051/5962 [00:20<00:16, 173.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 2751/5962 [00:20<00:18, 173.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 3195/5962 [00:19<00:14, 190.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3497/5962 [00:19<00:11, 212.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|███████████████████▉                  | 3131/5962 [00:20<00:20, 135.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|██████████████████▉                   | 2976/5962 [00:20<00:15, 190.32it/s]\u001b[A\u001b[A\n",
      " 51%|███████████████████▌                  | 3069/5962 [00:20<00:16, 170.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3216/5962 [00:20<00:14, 194.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3519/5962 [00:19<00:11, 213.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▋                    | 2769/5962 [00:20<00:19, 161.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3146/5962 [00:20<00:20, 136.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|███████████████████                   | 2999/5962 [00:20<00:14, 200.14it/s]\u001b[A\u001b[A\n",
      " 54%|████████████████████▋                 | 3246/5962 [00:20<00:15, 170.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3240/5962 [00:20<00:13, 206.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3547/5962 [00:20<00:10, 232.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 3087/5962 [00:20<00:18, 159.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▎                  | 3033/5962 [00:20<00:12, 236.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3161/5962 [00:20<00:20, 137.50it/s]\u001b[A\u001b[A\u001b[A\n",
      " 55%|████████████████████▊                 | 3275/5962 [00:20<00:13, 198.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3263/5962 [00:20<00:12, 210.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 3571/5962 [00:20<00:10, 231.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▉                    | 2811/5962 [00:20<00:17, 175.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▍                  | 3059/5962 [00:20<00:11, 242.87it/s]\u001b[A\u001b[A\n",
      " 52%|███████████████████▊                  | 3104/5962 [00:20<00:20, 138.50it/s]\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3176/5962 [00:20<00:21, 129.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3599/5962 [00:20<00:09, 244.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3288/5962 [00:20<00:12, 215.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████                    | 2831/5962 [00:20<00:17, 179.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 3190/5962 [00:20<00:23, 120.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|███████████████████▋                  | 3084/5962 [00:20<00:14, 196.33it/s]\u001b[A\u001b[A\n",
      " 56%|█████████████████████▏                | 3318/5962 [00:20<00:15, 171.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▉                  | 3119/5962 [00:21<00:24, 117.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 2850/5962 [00:20<00:18, 164.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████                 | 3310/5962 [00:20<00:14, 184.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3203/5962 [00:20<00:23, 118.68it/s]\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████▎                | 3339/5962 [00:20<00:14, 179.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3648/5962 [00:20<00:10, 220.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▎                   | 2869/5962 [00:20<00:18, 170.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|███████████████████▉                  | 3132/5962 [00:21<00:25, 109.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|███████████████████▊                  | 3106/5962 [00:20<00:16, 169.61it/s]\u001b[A\u001b[A\n",
      " 57%|█████████████████████▍                | 3371/5962 [00:21<00:12, 214.68it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3671/5962 [00:20<00:10, 220.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3216/5962 [00:20<00:24, 112.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3375/5962 [00:20<00:10, 246.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 3144/5962 [00:21<00:25, 110.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|█████████████████████▋                | 3395/5962 [00:21<00:11, 218.77it/s]\u001b[A\n",
      "\n",
      " 52%|███████████████████▉                  | 3125/5962 [00:20<00:17, 160.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3702/5962 [00:20<00:09, 239.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3414/5962 [00:20<00:08, 284.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3228/5962 [00:20<00:25, 106.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 2909/5962 [00:20<00:17, 174.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████                  | 3156/5962 [00:21<00:27, 100.49it/s]\u001b[A\n",
      "\n",
      " 53%|████████████████████                  | 3143/5962 [00:21<00:17, 158.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3731/5962 [00:20<00:08, 250.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3245/5962 [00:21<00:22, 121.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 3170/5962 [00:21<00:25, 108.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▏                 | 3160/5962 [00:21<00:18, 155.31it/s]\u001b[A\u001b[A\n",
      " 58%|██████████████████████                | 3454/5962 [00:21<00:10, 229.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 3444/5962 [00:21<00:11, 221.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3757/5962 [00:20<00:09, 231.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▎                 | 3183/5962 [00:21<00:24, 113.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▊                   | 2951/5962 [00:21<00:19, 155.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▏               | 3478/5962 [00:21<00:10, 229.33it/s]\u001b[A\n",
      "\n",
      " 53%|████████████████████▏                 | 3177/5962 [00:21<00:18, 152.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3781/5962 [00:21<00:10, 201.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3270/5962 [00:21<00:25, 106.72it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 3195/5962 [00:21<00:26, 104.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 2968/5962 [00:21<00:21, 141.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▎               | 3502/5962 [00:21<00:11, 209.89it/s]\u001b[A\n",
      "\n",
      " 54%|████████████████████▎                 | 3193/5962 [00:21<00:19, 138.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▍                 | 3281/5962 [00:21<00:27, 96.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▉                  | 3206/5962 [00:21<00:27, 98.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3491/5962 [00:21<00:15, 162.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2983/5962 [00:21<00:23, 125.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|████████████████████▍                 | 3208/5962 [00:21<00:22, 121.22it/s]\u001b[A\u001b[A\n",
      " 59%|██████████████████████▍               | 3524/5962 [00:21<00:14, 173.19it/s]\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 3291/5962 [00:21<00:27, 95.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████                  | 3217/5962 [00:22<00:30, 91.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 3305/5962 [00:21<00:25, 105.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 2997/5962 [00:21<00:25, 118.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|█████████████████████                  | 3227/5962 [00:22<00:29, 91.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▌               | 3543/5962 [00:21<00:16, 148.81it/s]\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3316/5962 [00:21<00:25, 101.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████                  | 3221/5962 [00:21<00:28, 94.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 3839/5962 [00:21<00:15, 141.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3527/5962 [00:21<00:16, 150.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▋                 | 3241/5962 [00:22<00:26, 102.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|██████████████████████▋               | 3560/5962 [00:22<00:16, 147.02it/s]\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3327/5962 [00:21<00:25, 103.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████▏                 | 3232/5962 [00:21<00:28, 95.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3544/5962 [00:21<00:15, 153.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3022/5962 [00:21<00:27, 107.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3259/5962 [00:22<00:22, 118.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3340/5962 [00:22<00:23, 109.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 3562/5962 [00:21<00:15, 159.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████████████████████▏                 | 3243/5962 [00:22<00:29, 90.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 3033/5962 [00:22<00:28, 101.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3868/5962 [00:21<00:17, 120.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|██████████████████████▊               | 3576/5962 [00:22<00:20, 114.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3272/5962 [00:22<00:25, 105.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3352/5962 [00:22<00:25, 101.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▎                 | 3254/5962 [00:22<00:28, 94.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▉                   | 3044/5962 [00:22<00:29, 99.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|██████████████████████▉               | 3595/5962 [00:22<00:18, 129.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3600/5962 [00:22<00:13, 173.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3283/5962 [00:22<00:26, 101.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|████████████████████▊                 | 3268/5962 [00:22<00:25, 104.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▉                 | 3363/5962 [00:22<00:26, 98.79it/s]\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████               | 3614/5962 [00:22<00:16, 138.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▉                   | 3055/5962 [00:22<00:31, 93.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3618/5962 [00:22<00:13, 169.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3893/5962 [00:22<00:18, 109.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|████████████████████▉                 | 3294/5962 [00:22<00:18, 142.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 3294/5962 [00:22<00:28, 94.11it/s]\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▏              | 3632/5962 [00:22<00:16, 145.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3636/5962 [00:22<00:14, 161.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████                 | 3313/5962 [00:22<00:17, 154.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▉             | 3905/5962 [00:22<00:19, 106.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|████████████████████                   | 3065/5962 [00:22<00:34, 84.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▌                 | 3304/5962 [00:22<00:29, 91.33it/s]\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▎              | 3649/5962 [00:22<00:15, 151.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3658/5962 [00:22<00:13, 176.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▎                | 3336/5962 [00:22<00:15, 172.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▏                  | 3078/5962 [00:22<00:31, 92.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 3399/5962 [00:22<00:24, 106.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▋                 | 3316/5962 [00:22<00:27, 96.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▎              | 3666/5962 [00:22<00:14, 153.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3676/5962 [00:22<00:13, 163.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▍                | 3354/5962 [00:22<00:15, 163.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3417/5962 [00:22<00:20, 124.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▏                | 3331/5962 [00:23<00:24, 109.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3929/5962 [00:22<00:19, 104.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▍              | 3685/5962 [00:22<00:14, 162.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3693/5962 [00:22<00:14, 157.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3346/5962 [00:23<00:22, 117.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 3109/5962 [00:22<00:26, 109.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3940/5962 [00:22<00:20, 100.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▍                | 3371/5962 [00:22<00:17, 147.81it/s]\u001b[A\u001b[A\n",
      " 62%|███████████████████████▌              | 3702/5962 [00:23<00:15, 147.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▉                 | 3358/5962 [00:23<00:26, 98.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 3447/5962 [00:23<00:23, 107.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▍                  | 3121/5962 [00:23<00:32, 87.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▌                | 3387/5962 [00:23<00:21, 117.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3710/5962 [00:22<00:19, 113.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▋              | 3718/5962 [00:23<00:18, 122.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▍                | 3371/5962 [00:23<00:24, 104.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 3461/5962 [00:23<00:21, 114.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▍                  | 3131/5962 [00:23<00:32, 86.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▋                | 3404/5962 [00:23<00:19, 128.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3728/5962 [00:23<00:17, 127.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 3390/5962 [00:23<00:20, 126.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3485/5962 [00:23<00:16, 145.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████████████████████▊                | 3425/5962 [00:23<00:17, 147.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▌                  | 3141/5962 [00:23<00:32, 87.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3751/5962 [00:23<00:14, 149.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|███████████████████████▉              | 3750/5962 [00:23<00:16, 130.26it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3988/5962 [00:23<00:19, 103.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3512/5962 [00:23<00:13, 178.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████████████████████▉                | 3448/5962 [00:23<00:14, 168.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3772/5962 [00:23<00:13, 156.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▌                  | 3151/5962 [00:23<00:33, 83.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3999/5962 [00:23<00:18, 105.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3542/5962 [00:23<00:11, 209.95it/s]\u001b[A\u001b[A\u001b[A\n",
      " 63%|███████████████████████▉              | 3764/5962 [00:23<00:17, 127.53it/s]\u001b[A\n",
      "\n",
      " 58%|██████████████████████                | 3467/5962 [00:23<00:14, 169.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 3789/5962 [00:23<00:14, 153.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4018/5962 [00:23<00:15, 128.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 3564/5962 [00:23<00:11, 209.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▎                | 3416/5962 [00:23<00:27, 92.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|██████████████████████▏               | 3485/5962 [00:23<00:15, 161.65it/s]\u001b[A\u001b[A\n",
      " 63%|████████████████████████              | 3778/5962 [00:23<00:20, 107.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▋            | 4032/5962 [00:23<00:15, 125.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 3586/5962 [00:23<00:11, 205.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▍                | 3428/5962 [00:24<00:26, 96.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▎               | 3504/5962 [00:23<00:14, 169.13it/s]\u001b[A\u001b[A\n",
      " 64%|████████████████████████▏             | 3790/5962 [00:23<00:20, 104.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4045/5962 [00:23<00:15, 122.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▎                 | 3187/5962 [00:23<00:26, 103.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▍                | 3439/5962 [00:24<00:25, 99.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▍               | 3524/5962 [00:23<00:13, 176.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3607/5962 [00:23<00:14, 164.95it/s]\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▏             | 3802/5962 [00:24<00:20, 106.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4063/5962 [00:23<00:13, 138.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 3205/5962 [00:23<00:23, 119.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 3451/5962 [00:24<00:24, 102.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3543/5962 [00:24<00:16, 148.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▉              | 3814/5962 [00:24<00:21, 97.80it/s]\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 3466/5962 [00:24<00:21, 114.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3856/5962 [00:23<00:14, 141.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 3218/5962 [00:24<00:26, 104.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▋               | 3559/5962 [00:24<00:16, 148.70it/s]\u001b[A\u001b[A\n",
      " 64%|████████████████████████▍             | 3827/5962 [00:24<00:20, 102.88it/s]\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3641/5962 [00:24<00:15, 145.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3871/5962 [00:24<00:15, 136.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▏               | 3479/5962 [00:24<00:23, 105.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████            | 4092/5962 [00:23<00:17, 109.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▊               | 3575/5962 [00:24<00:16, 147.66it/s]\u001b[A\u001b[A\n",
      " 64%|████████████████████████▍             | 3841/5962 [00:24<00:19, 109.74it/s]\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 3666/5962 [00:24<00:13, 168.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3885/5962 [00:24<00:15, 136.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3500/5962 [00:24<00:18, 131.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4107/5962 [00:24<00:15, 118.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▉               | 3591/5962 [00:24<00:15, 150.19it/s]\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3693/5962 [00:24<00:11, 194.11it/s]\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▌             | 3854/5962 [00:24<00:18, 112.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3906/5962 [00:24<00:13, 155.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▊                 | 3261/5962 [00:24<00:21, 124.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4125/5962 [00:24<00:13, 133.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3717/5962 [00:24<00:10, 204.47it/s]\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▋             | 3866/5962 [00:24<00:19, 110.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3923/5962 [00:24<00:12, 156.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 3281/5962 [00:24<00:18, 143.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 3541/5962 [00:24<00:14, 163.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████████████████████▉               | 3607/5962 [00:24<00:18, 128.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3742/5962 [00:24<00:10, 213.25it/s]\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▋             | 3878/5962 [00:24<00:18, 111.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3939/5962 [00:24<00:13, 155.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 3569/5962 [00:24<00:12, 194.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4168/5962 [00:24<00:10, 169.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████               | 3621/5962 [00:24<00:19, 118.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3765/5962 [00:24<00:10, 202.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 3955/5962 [00:24<00:12, 156.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▊             | 3890/5962 [00:24<00:19, 107.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 3590/5962 [00:25<00:13, 177.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████▏              | 3634/5962 [00:24<00:19, 121.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████                 | 3313/5962 [00:24<00:20, 127.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3972/5962 [00:24<00:12, 159.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▊             | 3902/5962 [00:24<00:19, 107.62it/s]\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 3786/5962 [00:24<00:11, 195.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 4204/5962 [00:24<00:10, 167.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████▏              | 3647/5962 [00:24<00:19, 118.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3609/5962 [00:25<00:14, 159.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3808/5962 [00:24<00:10, 198.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▉           | 4223/5962 [00:24<00:10, 171.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|████████████████████████▉             | 3913/5962 [00:25<00:20, 100.30it/s]\u001b[A\n",
      "\n",
      " 61%|███████████████████████▎              | 3665/5962 [00:24<00:17, 134.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 3346/5962 [00:24<00:18, 143.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4006/5962 [00:24<00:12, 153.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3626/5962 [00:25<00:17, 135.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|███████████████████████▍              | 3679/5962 [00:25<00:18, 126.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4241/5962 [00:24<00:12, 141.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▋             | 3924/5962 [00:25<00:24, 84.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 3361/5962 [00:25<00:21, 118.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▋            | 4022/5962 [00:25<00:14, 136.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|███████████████████████▌              | 3693/5962 [00:25<00:19, 118.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3848/5962 [00:25<00:15, 140.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3641/5962 [00:25<00:21, 108.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▋             | 3933/5962 [00:25<00:30, 67.36it/s]\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3866/5962 [00:25<00:14, 147.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|███████████████████████▌              | 3706/5962 [00:25<00:21, 105.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4278/5962 [00:25<00:12, 139.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████                 | 3374/5962 [00:25<00:28, 91.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3892/5962 [00:25<00:11, 174.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4304/5962 [00:25<00:09, 168.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▍              | 3684/5962 [00:25<00:15, 149.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▏                | 3386/5962 [00:25<00:26, 95.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 62%|████████████████████████▎              | 3717/5962 [00:25<00:23, 94.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3917/5962 [00:25<00:10, 193.41it/s]\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▌              | 3704/5962 [00:25<00:14, 160.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 3419/5962 [00:25<00:17, 148.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▌          | 4323/5962 [00:25<00:10, 159.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▍            | 4049/5962 [00:25<00:22, 86.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|███████████████████████▊              | 3737/5962 [00:25<00:18, 118.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 3945/5962 [00:25<00:09, 216.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▉             | 3971/5962 [00:25<00:21, 93.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 4343/5962 [00:25<00:09, 165.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|███████████████████████▉              | 3761/5962 [00:25<00:15, 145.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3968/5962 [00:25<00:09, 218.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▌            | 4060/5962 [00:25<00:23, 82.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3749/5962 [00:26<00:11, 185.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|██████████████████████████             | 3983/5962 [00:25<00:20, 98.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 4361/5962 [00:25<00:09, 167.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▏             | 3788/5962 [00:25<00:12, 172.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3993/5962 [00:25<00:08, 226.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▌            | 4070/5962 [00:25<00:22, 85.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|█████████████████████████▌            | 4002/5962 [00:26<00:16, 119.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3769/5962 [00:26<00:12, 171.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▎             | 3808/5962 [00:25<00:12, 179.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▉          | 4379/5962 [00:25<00:09, 159.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▋            | 4024/5962 [00:25<00:07, 249.14it/s]\u001b[A\u001b[A\u001b[A\n",
      " 67%|█████████████████████████▌            | 4016/5962 [00:26<00:15, 121.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 3509/5962 [00:25<00:13, 184.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 3799/5962 [00:26<00:10, 204.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 4400/5962 [00:25<00:09, 166.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4050/5962 [00:26<00:09, 208.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▋            | 4089/5962 [00:26<00:25, 74.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4417/5962 [00:25<00:09, 163.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▋            | 4029/5962 [00:26<00:18, 104.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 3529/5962 [00:26<00:15, 157.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 64%|████████████████████████▌             | 3844/5962 [00:26<00:13, 152.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3821/5962 [00:26<00:13, 157.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▊            | 4105/5962 [00:26<00:20, 92.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▊            | 4047/5962 [00:26<00:16, 119.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▎         | 4434/5962 [00:26<00:10, 152.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████            | 4096/5962 [00:26<00:08, 213.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|████████████████████████▌             | 3861/5962 [00:26<00:14, 147.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4120/5962 [00:26<00:17, 103.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▉            | 4060/5962 [00:26<00:15, 121.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 3840/5962 [00:26<00:15, 138.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4119/5962 [00:26<00:08, 214.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 4450/5962 [00:26<00:11, 136.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|████████████████████████▋             | 3877/5962 [00:26<00:14, 145.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4136/5962 [00:26<00:15, 117.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▉            | 4075/5962 [00:26<00:14, 127.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3856/5962 [00:26<00:16, 131.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 4156/5962 [00:26<00:13, 138.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4465/5962 [00:26<00:11, 128.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 69%|██████████████████████████            | 4093/5962 [00:26<00:13, 138.32it/s]\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▍           | 4142/5962 [00:26<00:09, 185.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|████████████████████████▊             | 3892/5962 [00:26<00:15, 129.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 3871/5962 [00:27<00:16, 128.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4479/5962 [00:26<00:11, 125.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4171/5962 [00:26<00:13, 130.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 3616/5962 [00:26<00:14, 165.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3887/5962 [00:27<00:15, 134.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|████████████████████████▉             | 3906/5962 [00:26<00:18, 108.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 4492/5962 [00:26<00:12, 121.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 69%|██████████████████████████▎           | 4128/5962 [00:27<00:12, 147.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 4185/5962 [00:26<00:13, 127.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 3645/5962 [00:26<00:11, 194.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3906/5962 [00:27<00:14, 144.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|████████████████████████▉             | 3918/5962 [00:26<00:18, 108.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 4506/5962 [00:26<00:11, 123.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▍           | 4150/5962 [00:27<00:11, 164.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▊           | 4199/5962 [00:26<00:14, 125.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 3670/5962 [00:26<00:11, 208.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▊           | 4198/5962 [00:27<00:11, 157.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████             | 3930/5962 [00:27<00:18, 109.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4523/5962 [00:26<00:10, 134.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▌           | 4175/5962 [00:27<00:09, 182.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 4212/5962 [00:26<00:14, 121.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 3693/5962 [00:27<00:10, 210.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3922/5962 [00:27<00:17, 114.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▏            | 3943/5962 [00:27<00:17, 112.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4539/5962 [00:26<00:10, 137.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▋           | 4196/5962 [00:27<00:09, 188.16it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▉           | 4229/5962 [00:27<00:12, 134.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 3716/5962 [00:27<00:10, 209.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 3935/5962 [00:27<00:18, 110.76it/s]\u001b[A\u001b[A\u001b[A\n",
      " 71%|██████████████████████████▊           | 4215/5962 [00:27<00:09, 183.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4248/5962 [00:27<00:11, 149.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████         | 4553/5962 [00:27<00:10, 129.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████▏            | 3948/5962 [00:27<00:17, 114.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▏          | 4266/5962 [00:27<00:10, 157.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▊              | 3738/5962 [00:27<00:12, 175.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4255/5962 [00:27<00:11, 145.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 4567/5962 [00:27<00:11, 125.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|█████████████████████████▉             | 3966/5962 [00:27<00:19, 99.92it/s]\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▏            | 3961/5962 [00:27<00:17, 116.13it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4282/5962 [00:27<00:10, 153.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4580/5962 [00:27<00:11, 120.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 3757/5962 [00:27<00:14, 157.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▏          | 4271/5962 [00:27<00:12, 137.35it/s]\u001b[A\u001b[A\u001b[A\n",
      " 71%|███████████████████████████▏          | 4262/5962 [00:27<00:09, 187.32it/s]\u001b[A\n",
      "\n",
      " 67%|██████████████████████████             | 3977/5962 [00:27<00:21, 94.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3974/5962 [00:27<00:17, 115.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4594/5962 [00:27<00:11, 124.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████              | 3781/5962 [00:27<00:12, 175.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 72%|███████████████████████████▎          | 4292/5962 [00:27<00:07, 215.67it/s]\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4286/5962 [00:27<00:12, 137.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████             | 3987/5962 [00:27<00:21, 93.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3990/5962 [00:28<00:15, 126.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 4611/5962 [00:27<00:10, 134.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 3808/5962 [00:27<00:10, 196.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4302/5962 [00:27<00:11, 143.43it/s]\u001b[A\u001b[A\u001b[A\n",
      " 72%|███████████████████████████▌          | 4315/5962 [00:27<00:07, 213.60it/s]\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▏            | 3997/5962 [00:27<00:21, 93.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4009/5962 [00:28<00:13, 143.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▍        | 4628/5962 [00:27<00:09, 144.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 3834/5962 [00:27<00:10, 211.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▏            | 4007/5962 [00:27<00:20, 95.18it/s]\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▋          | 4338/5962 [00:28<00:07, 212.96it/s]\u001b[A\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▌          | 4317/5962 [00:27<00:12, 129.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▋            | 4027/5962 [00:28<00:12, 150.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4662/5962 [00:27<00:06, 196.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 3858/5962 [00:27<00:09, 217.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▋            | 4027/5962 [00:27<00:15, 123.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▌          | 4332/5962 [00:27<00:12, 133.53it/s]\u001b[A\u001b[A\u001b[A\n",
      " 68%|█████████████████████████▊            | 4047/5962 [00:28<00:11, 164.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▊        | 4682/5962 [00:27<00:06, 195.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 3889/5962 [00:27<00:08, 238.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 4399/5962 [00:27<00:08, 186.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▊            | 4046/5962 [00:28<00:13, 140.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4067/5962 [00:28<00:10, 172.37it/s]\u001b[A\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▉          | 4382/5962 [00:28<00:08, 196.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 4713/5962 [00:27<00:05, 228.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 3918/5962 [00:28<00:08, 252.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4419/5962 [00:28<00:08, 185.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▉            | 4070/5962 [00:28<00:11, 166.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 4365/5962 [00:28<00:10, 148.66it/s]\u001b[A\u001b[A\u001b[A\n",
      " 69%|██████████████████████████            | 4087/5962 [00:28<00:10, 177.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 4737/5962 [00:28<00:05, 214.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 3944/5962 [00:28<00:08, 238.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████            | 4090/5962 [00:28<00:10, 174.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4105/5962 [00:28<00:10, 177.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▎         | 4439/5962 [00:28<00:09, 160.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▏         | 4431/5962 [00:28<00:08, 184.52it/s]\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▎           | 4120/5962 [00:28<00:08, 210.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 3969/5962 [00:28<00:08, 233.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4126/5962 [00:28<00:09, 186.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 4398/5962 [00:28<00:10, 150.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████▍           | 4150/5962 [00:28<00:07, 235.36it/s]\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▎         | 4451/5962 [00:28<00:08, 182.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4456/5962 [00:28<00:11, 136.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4780/5962 [00:28<00:06, 191.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4419/5962 [00:28<00:09, 164.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 3993/5962 [00:28<00:09, 202.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████▌           | 4174/5962 [00:28<00:08, 223.27it/s]\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▍         | 4470/5962 [00:28<00:08, 173.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4167/5962 [00:28<00:09, 191.80it/s]\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4471/5962 [00:28<00:11, 133.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▌       | 4800/5962 [00:28<00:06, 176.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 4015/5962 [00:28<00:10, 189.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████▊           | 4197/5962 [00:28<00:08, 216.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 4187/5962 [00:29<00:09, 186.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4457/5962 [00:28<00:09, 162.42it/s]\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▌         | 4488/5962 [00:28<00:09, 156.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4819/5962 [00:28<00:07, 150.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|██████████████████████████▉           | 4219/5962 [00:28<00:08, 198.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 4505/5962 [00:28<00:10, 134.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 4206/5962 [00:29<00:10, 162.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4474/5962 [00:28<00:10, 144.01it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▋         | 4505/5962 [00:29<00:10, 137.05it/s]\u001b[A\n",
      "\n",
      " 71%|███████████████████████████           | 4246/5962 [00:28<00:07, 217.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4835/5962 [00:28<00:08, 136.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4520/5962 [00:28<00:11, 126.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▉           | 4223/5962 [00:29<00:11, 152.15it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▊         | 4520/5962 [00:29<00:10, 135.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 4052/5962 [00:28<00:13, 140.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████████████████████████▏          | 4269/5962 [00:29<00:07, 218.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4850/5962 [00:28<00:07, 139.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4546/5962 [00:28<00:08, 158.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4241/5962 [00:29<00:11, 156.25it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▉         | 4535/5962 [00:29<00:10, 138.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 4072/5962 [00:29<00:12, 147.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████████████████████████▎          | 4292/5962 [00:29<00:07, 209.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4865/5962 [00:28<00:07, 140.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 4568/5962 [00:29<00:08, 172.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▏          | 4257/5962 [00:29<00:12, 139.13it/s]\u001b[A\u001b[A\u001b[A\n",
      " 76%|█████████████████████████████         | 4550/5962 [00:29<00:11, 119.11it/s]\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4545/5962 [00:29<00:08, 170.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4880/5962 [00:29<00:08, 133.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████            | 4088/5962 [00:29<00:14, 126.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▏          | 4272/5962 [00:29<00:12, 131.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 4563/5962 [00:29<00:08, 169.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████████████████████████▌          | 4334/5962 [00:29<00:09, 168.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4301/5962 [00:29<00:09, 169.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4102/5962 [00:29<00:17, 108.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▊         | 4563/5962 [00:29<00:14, 94.16it/s]\u001b[A\n",
      "\n",
      " 73%|███████████████████████████▋          | 4352/5962 [00:29<00:09, 169.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▌          | 4319/5962 [00:29<00:09, 167.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 4114/5962 [00:29<00:17, 106.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████▉          | 4385/5962 [00:29<00:07, 210.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4603/5962 [00:29<00:12, 105.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 4340/5962 [00:30<00:09, 177.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▉         | 4574/5962 [00:29<00:17, 79.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 4126/5962 [00:29<00:17, 103.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▍        | 4626/5962 [00:29<00:07, 174.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 4359/5962 [00:30<00:09, 177.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████          | 4408/5962 [00:29<00:08, 182.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████▏        | 4616/5962 [00:29<00:14, 95.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▍           | 4139/5962 [00:29<00:16, 107.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▉         | 4583/5962 [00:30<00:18, 76.12it/s]\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4645/5962 [00:29<00:07, 176.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████████████████████████▉          | 4378/5962 [00:30<00:09, 160.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4954/5962 [00:29<00:08, 114.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4664/5962 [00:30<00:07, 171.90it/s]\u001b[A\u001b[A\u001b[A\n",
      " 77%|██████████████████████████████         | 4592/5962 [00:30<00:18, 73.47it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 4151/5962 [00:29<00:17, 100.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 4628/5962 [00:29<00:15, 86.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████          | 4398/5962 [00:30<00:09, 169.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4967/5962 [00:29<00:08, 111.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|██████████████████████████████▏        | 4607/5962 [00:30<00:15, 88.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 4165/5962 [00:30<00:16, 108.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 4643/5962 [00:30<00:13, 96.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▏         | 4416/5962 [00:30<00:09, 162.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 4703/5962 [00:30<00:07, 176.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 4186/5962 [00:30<00:13, 133.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|██████████████████████████████▏        | 4620/5962 [00:30<00:14, 94.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4658/5962 [00:30<00:12, 107.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▋      | 4979/5962 [00:30<00:09, 103.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▎         | 4433/5962 [00:30<00:09, 159.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 4732/5962 [00:30<00:06, 204.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 4216/5962 [00:30<00:09, 177.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████▌        | 4634/5962 [00:30<00:12, 105.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▊        | 4680/5962 [00:30<00:09, 133.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████▊         | 4525/5962 [00:30<00:06, 223.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 4990/5962 [00:30<00:10, 92.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 4450/5962 [00:30<00:09, 159.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 4239/5962 [00:30<00:09, 190.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████▌        | 4648/5962 [00:30<00:11, 111.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 4705/5962 [00:30<00:07, 159.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████▉         | 4548/5962 [00:30<00:06, 225.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▋      | 5001/5962 [00:30<00:10, 95.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4776/5962 [00:30<00:05, 211.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4467/5962 [00:30<00:09, 154.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 4728/5962 [00:30<00:06, 176.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████▋        | 4662/5962 [00:30<00:11, 115.45it/s]\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4571/5962 [00:30<00:06, 203.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4798/5962 [00:30<00:05, 210.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 5011/5962 [00:30<00:10, 89.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▎          | 4291/5962 [00:30<00:07, 209.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4483/5962 [00:31<00:10, 146.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████▊        | 4675/5962 [00:30<00:11, 115.09it/s]\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▎        | 4592/5962 [00:30<00:07, 190.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4825/5962 [00:30<00:05, 226.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4775/5962 [00:30<00:05, 204.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 4499/5962 [00:31<00:10, 143.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 79%|█████████████████████████████▊        | 4687/5962 [00:30<00:11, 110.61it/s]\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4848/5962 [00:30<00:05, 208.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 4313/5962 [00:30<00:10, 151.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4514/5962 [00:31<00:10, 135.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4797/5962 [00:30<00:06, 180.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 79%|█████████████████████████████▉        | 4699/5962 [00:31<00:11, 106.26it/s]\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4870/5962 [00:30<00:05, 210.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 4339/5962 [00:30<00:09, 173.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▉         | 4539/5962 [00:31<00:08, 165.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 79%|██████████████████████████████        | 4717/5962 [00:31<00:09, 124.99it/s]\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4630/5962 [00:31<00:08, 153.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 4893/5962 [00:31<00:05, 212.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4817/5962 [00:30<00:07, 158.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4573/5962 [00:31<00:06, 210.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▏       | 4741/5962 [00:31<00:07, 155.26it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 4359/5962 [00:31<00:09, 168.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4647/5962 [00:31<00:09, 142.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▎      | 4915/5962 [00:31<00:05, 208.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████      | 5061/5962 [00:30<00:09, 93.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▎       | 4759/5962 [00:31<00:07, 161.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4835/5962 [00:31<00:08, 137.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▉          | 4378/5962 [00:31<00:10, 151.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4936/5962 [00:31<00:05, 198.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5071/5962 [00:31<00:10, 88.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▎        | 4595/5962 [00:31<00:08, 158.13it/s]\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4662/5962 [00:31<00:10, 122.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4850/5962 [00:31<00:08, 131.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 4395/5962 [00:31<00:10, 152.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4957/5962 [00:31<00:05, 194.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5081/5962 [00:31<00:09, 89.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▍        | 4614/5962 [00:31<00:09, 146.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 4416/5962 [00:31<00:09, 165.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▋       | 4812/5962 [00:31<00:07, 163.11it/s]\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4977/5962 [00:31<00:05, 175.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5091/5962 [00:31<00:09, 89.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▊        | 4675/5962 [00:31<00:12, 100.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4864/5962 [00:31<00:09, 113.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4631/5962 [00:31<00:09, 139.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▊       | 4832/5962 [00:31<00:06, 173.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▎     | 5102/5962 [00:31<00:09, 94.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▍         | 4456/5962 [00:31<00:08, 175.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4877/5962 [00:31<00:10, 101.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4995/5962 [00:31<00:06, 144.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4686/5962 [00:31<00:14, 86.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 5112/5962 [00:31<00:08, 95.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 4475/5962 [00:31<00:09, 161.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4647/5962 [00:32<00:11, 111.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 4888/5962 [00:31<00:11, 96.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▉       | 4850/5962 [00:32<00:08, 126.38it/s]\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4696/5962 [00:31<00:15, 79.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5011/5962 [00:31<00:07, 122.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5135/5962 [00:31<00:08, 102.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 4898/5962 [00:31<00:11, 95.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▋         | 4492/5962 [00:31<00:09, 150.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4705/5962 [00:32<00:15, 81.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4660/5962 [00:32<00:12, 101.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████       | 4865/5962 [00:32<00:09, 113.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 4908/5962 [00:31<00:10, 96.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5146/5962 [00:31<00:07, 102.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4513/5962 [00:32<00:08, 164.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4715/5962 [00:32<00:14, 85.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▌        | 4672/5962 [00:32<00:13, 96.77it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████       | 4878/5962 [00:32<00:09, 110.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5157/5962 [00:31<00:07, 104.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▊         | 4530/5962 [00:32<00:08, 159.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████████████████████████████▏      | 4918/5962 [00:32<00:11, 90.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 5060/5962 [00:32<00:06, 142.45it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▏      | 4896/5962 [00:32<00:08, 123.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5168/5962 [00:32<00:07, 101.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4683/5962 [00:32<00:13, 92.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▉        | 4735/5962 [00:32<00:13, 89.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 5078/5962 [00:32<00:05, 150.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▏      | 4928/5962 [00:32<00:12, 84.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▎      | 4919/5962 [00:32<00:07, 147.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 4694/5962 [00:32<00:13, 95.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████████████████████████████        | 4746/5962 [00:32<00:12, 94.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 5179/5962 [00:32<00:08, 95.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▍     | 5098/5962 [00:32<00:05, 161.86it/s]\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▍      | 4935/5962 [00:32<00:06, 150.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 4588/5962 [00:32<00:07, 174.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▎      | 4937/5962 [00:32<00:14, 73.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4760/5962 [00:32<00:11, 105.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▊        | 4704/5962 [00:32<00:13, 90.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5119/5962 [00:32<00:04, 174.39it/s]\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▌      | 4955/5962 [00:32<00:06, 161.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 4619/5962 [00:32<00:06, 212.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4777/5962 [00:32<00:09, 122.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 4719/5962 [00:32<00:11, 104.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5144/5962 [00:32<00:04, 195.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▎      | 4945/5962 [00:32<00:14, 68.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 84%|███████████████████████████████▊      | 4987/5962 [00:32<00:04, 198.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 4643/5962 [00:32<00:05, 220.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▌       | 4794/5962 [00:32<00:08, 130.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5214/5962 [00:32<00:07, 104.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▍      | 4953/5962 [00:32<00:14, 70.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 4745/5962 [00:33<00:10, 114.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5227/5962 [00:32<00:06, 108.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 4666/5962 [00:32<00:07, 182.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4808/5962 [00:32<00:10, 111.38it/s]\u001b[A\u001b[A\n",
      " 84%|███████████████████████████████▉      | 5008/5962 [00:33<00:06, 153.51it/s]\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4757/5962 [00:33<00:11, 108.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▌      | 4976/5962 [00:32<00:11, 86.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 5238/5962 [00:32<00:07, 97.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4822/5962 [00:33<00:09, 117.84it/s]\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▍       | 4773/5962 [00:33<00:09, 120.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4995/5962 [00:32<00:08, 111.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5250/5962 [00:32<00:06, 102.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5200/5962 [00:33<00:05, 140.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4843/5962 [00:33<00:07, 141.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 4711/5962 [00:33<00:06, 179.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▌       | 4794/5962 [00:33<00:08, 144.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 5024/5962 [00:33<00:05, 158.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5261/5962 [00:32<00:06, 102.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|██████████████████████████████▉       | 4862/5962 [00:33<00:07, 153.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5215/5962 [00:33<00:05, 128.36it/s]\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▋       | 4813/5962 [00:33<00:07, 157.01it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 4730/5962 [00:33<00:07, 157.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5048/5962 [00:33<00:05, 179.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5272/5962 [00:33<00:06, 103.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████       | 4879/5962 [00:33<00:06, 158.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5230/5962 [00:33<00:05, 133.26it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▌     | 5100/5962 [00:33<00:04, 186.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 4749/5962 [00:33<00:07, 164.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 4830/5962 [00:33<00:07, 147.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5286/5962 [00:33<00:05, 113.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████▏      | 4896/5962 [00:33<00:06, 159.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5244/5962 [00:33<00:05, 131.99it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▋     | 5120/5962 [00:33<00:04, 186.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4853/5962 [00:33<00:06, 169.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▎      | 4920/5962 [00:33<00:05, 182.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5298/5962 [00:33<00:06, 107.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5258/5962 [00:33<00:05, 134.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4767/5962 [00:33<00:08, 144.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████       | 4872/5962 [00:33<00:06, 174.17it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 5110/5962 [00:33<00:04, 188.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4943/5962 [00:33<00:05, 195.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5309/5962 [00:33<00:06, 107.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5272/5962 [00:33<00:05, 130.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 4783/5962 [00:33<00:08, 138.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▏      | 4899/5962 [00:34<00:05, 201.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5134/5962 [00:33<00:04, 200.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4969/5962 [00:33<00:04, 210.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 5322/5962 [00:33<00:05, 111.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5286/5962 [00:33<00:05, 128.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▎      | 4920/5962 [00:34<00:05, 195.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4994/5962 [00:33<00:04, 220.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5157/5962 [00:33<00:03, 201.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████    | 5339/5962 [00:33<00:04, 128.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████     | 5193/5962 [00:34<00:04, 186.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 4824/5962 [00:33<00:06, 162.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5299/5962 [00:33<00:05, 122.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5017/5962 [00:34<00:04, 207.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4940/5962 [00:34<00:05, 173.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 4846/5962 [00:33<00:06, 177.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████    | 5352/5962 [00:33<00:05, 110.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████▏    | 5213/5962 [00:34<00:04, 166.17it/s]\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4960/5962 [00:34<00:05, 180.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5204/5962 [00:33<00:03, 202.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 4868/5962 [00:34<00:05, 187.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▎    | 5236/5962 [00:34<00:04, 179.26it/s]\u001b[A\n",
      "\n",
      " 85%|████████████████████████████████      | 5038/5962 [00:34<00:05, 172.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▋      | 4981/5962 [00:34<00:05, 186.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5228/5962 [00:34<00:03, 208.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 5324/5962 [00:34<00:06, 94.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 4888/5962 [00:34<00:06, 176.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 5001/5962 [00:34<00:05, 186.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5057/5962 [00:34<00:06, 132.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5250/5962 [00:34<00:04, 158.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▉    | 5334/5962 [00:34<00:07, 80.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▎      | 4907/5962 [00:34<00:07, 146.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 84%|███████████████████████████████▉      | 5020/5962 [00:34<00:05, 168.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5385/5962 [00:34<00:06, 83.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 5396/5962 [00:34<00:06, 84.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▉    | 5343/5962 [00:34<00:08, 73.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 4923/5962 [00:34<00:08, 127.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████      | 5038/5962 [00:34<00:06, 133.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5414/5962 [00:34<00:05, 107.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 5073/5962 [00:34<00:09, 92.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 4944/5962 [00:34<00:07, 142.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|██████████████████████████████████▍    | 5271/5962 [00:34<00:07, 94.72it/s]\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████    | 5351/5962 [00:34<00:08, 68.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5053/5962 [00:35<00:06, 131.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▋      | 4964/5962 [00:34<00:06, 155.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████    | 5361/5962 [00:34<00:08, 74.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 5426/5962 [00:34<00:05, 97.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 5069/5962 [00:35<00:06, 137.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5086/5962 [00:34<00:10, 83.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 4986/5962 [00:34<00:05, 164.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5437/5962 [00:34<00:05, 99.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5372/5962 [00:34<00:07, 78.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 5084/5962 [00:35<00:06, 137.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▌    | 5284/5962 [00:35<00:08, 76.11it/s]\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 5381/5962 [00:35<00:07, 77.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5004/5962 [00:35<00:06, 153.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▍     | 5099/5962 [00:35<00:06, 137.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▋   | 5448/5962 [00:34<00:05, 89.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|█████████████████████████████████▎     | 5097/5962 [00:35<00:11, 76.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████    | 5352/5962 [00:35<00:04, 152.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▎   | 5392/5962 [00:35<00:07, 81.16it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▌     | 5114/5962 [00:35<00:06, 132.99it/s]\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 5106/5962 [00:35<00:10, 77.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 5020/5962 [00:35<00:07, 131.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▋   | 5458/5962 [00:35<00:06, 79.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 5368/5962 [00:35<00:04, 148.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▋     | 5133/5962 [00:35<00:05, 146.74it/s]\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 5401/5962 [00:35<00:07, 79.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 5115/5962 [00:35<00:10, 77.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████      | 5038/5962 [00:35<00:06, 141.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5388/5962 [00:35<00:03, 161.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▊   | 5467/5962 [00:35<00:06, 72.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|████████████████████████████████▉     | 5159/5962 [00:35<00:04, 176.68it/s]\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 5413/5962 [00:35<00:06, 88.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▌     | 5124/5962 [00:35<00:10, 79.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 5059/5962 [00:35<00:05, 157.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▊    | 5321/5962 [00:35<00:08, 77.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5405/5962 [00:35<00:03, 151.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5427/5962 [00:35<00:05, 98.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▌     | 5135/5962 [00:35<00:09, 85.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████     | 5178/5962 [00:35<00:04, 163.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▊   | 5475/5962 [00:35<00:07, 65.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|██████████████████████████████████▊    | 5330/5962 [00:35<00:08, 77.10it/s]\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5437/5962 [00:35<00:05, 97.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 5145/5962 [00:35<00:09, 88.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5421/5962 [00:35<00:03, 142.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▊   | 5482/5962 [00:35<00:07, 64.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████     | 5195/5962 [00:36<00:05, 133.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 5155/5962 [00:35<00:08, 90.43it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▋   | 5447/5962 [00:35<00:05, 91.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 5436/5962 [00:35<00:03, 133.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▉   | 5493/5962 [00:35<00:06, 72.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5120/5962 [00:35<00:05, 162.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████▊     | 5168/5962 [00:35<00:08, 99.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5210/5962 [00:36<00:06, 121.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▉   | 5502/5962 [00:35<00:05, 76.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 5137/5962 [00:35<00:05, 159.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████     | 5189/5962 [00:35<00:06, 128.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5479/5962 [00:35<00:03, 124.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████   | 5514/5962 [00:35<00:05, 87.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 5470/5962 [00:35<00:03, 147.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▎    | 5224/5962 [00:36<00:06, 110.34it/s]\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 5211/5962 [00:36<00:04, 153.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 5154/5962 [00:36<00:05, 141.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 5500/5962 [00:36<00:03, 148.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5486/5962 [00:35<00:03, 149.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5532/5962 [00:35<00:03, 110.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|███████████████████████████████████    | 5364/5962 [00:36<00:08, 73.25it/s]\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5520/5962 [00:36<00:02, 157.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 5236/5962 [00:36<00:07, 101.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 5504/5962 [00:36<00:02, 156.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5547/5962 [00:35<00:03, 114.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|███████████████████████████████████▏   | 5372/5962 [00:36<00:07, 74.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 5169/5962 [00:36<00:06, 118.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5538/5962 [00:36<00:02, 162.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5523/5962 [00:36<00:02, 165.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 5247/5962 [00:36<00:07, 101.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5568/5962 [00:36<00:02, 140.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|███████████████████████████████████▏   | 5388/5962 [00:36<00:06, 95.61it/s]\u001b[A\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5557/5962 [00:36<00:02, 169.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5258/5962 [00:36<00:07, 97.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5587/5962 [00:36<00:02, 148.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 5182/5962 [00:36<00:07, 99.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▎   | 5400/5962 [00:36<00:05, 98.69it/s]\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5257/5962 [00:36<00:05, 118.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 5268/5962 [00:36<00:07, 96.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5563/5962 [00:36<00:02, 158.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 5193/5962 [00:36<00:08, 95.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5270/5962 [00:36<00:05, 116.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 5280/5962 [00:37<00:06, 99.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5583/5962 [00:36<00:02, 168.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▍   | 5421/5962 [00:36<00:05, 93.76it/s]\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5612/5962 [00:36<00:02, 174.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████     | 5204/5962 [00:36<00:08, 93.90it/s]\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 5283/5962 [00:36<00:05, 118.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 5291/5962 [00:37<00:07, 85.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 5617/5962 [00:36<00:03, 97.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████     | 5214/5962 [00:36<00:08, 83.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5296/5962 [00:36<00:06, 102.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▉  | 5630/5962 [00:36<00:02, 135.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5618/5962 [00:36<00:02, 147.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 5300/5962 [00:37<00:08, 79.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▏    | 5223/5962 [00:36<00:08, 82.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▌   | 5440/5962 [00:37<00:06, 75.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5648/5962 [00:37<00:02, 145.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5643/5962 [00:36<00:02, 108.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▉  | 5634/5962 [00:36<00:02, 133.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 5309/5962 [00:37<00:08, 78.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 5320/5962 [00:37<00:06, 105.27it/s]\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▋   | 5449/5962 [00:37<00:06, 77.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 5664/5962 [00:37<00:02, 145.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 5656/5962 [00:36<00:02, 113.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5648/5962 [00:37<00:02, 134.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 5319/5962 [00:37<00:07, 83.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▋   | 5458/5962 [00:37<00:06, 80.13it/s]\u001b[A\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 5331/5962 [00:37<00:06, 103.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5680/5962 [00:37<00:01, 144.95it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████    | 5335/5962 [00:37<00:06, 102.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 5270/5962 [00:37<00:05, 126.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5669/5962 [00:37<00:02, 107.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████    | 5342/5962 [00:37<00:05, 103.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 5706/5962 [00:37<00:01, 175.33it/s]\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▊   | 5467/5962 [00:37<00:06, 74.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 5363/5962 [00:37<00:04, 145.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5681/5962 [00:37<00:02, 106.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 5361/5962 [00:37<00:04, 127.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 5725/5962 [00:37<00:01, 176.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▎ | 5689/5962 [00:37<00:01, 141.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▎   | 5391/5962 [00:37<00:03, 178.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 5307/5962 [00:37<00:04, 146.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▋ | 5751/5962 [00:37<00:01, 187.28it/s]\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▉   | 5487/5962 [00:37<00:05, 84.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 5704/5962 [00:37<00:01, 133.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5375/5962 [00:37<00:05, 114.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 5693/5962 [00:37<00:02, 89.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5410/5962 [00:38<00:03, 163.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████▉   | 5499/5962 [00:37<00:05, 92.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 5723/5962 [00:37<00:01, 144.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5387/5962 [00:37<00:05, 113.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5771/5962 [00:37<00:01, 179.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5429/5962 [00:38<00:03, 169.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 92%|████████████████████████████████████   | 5509/5962 [00:37<00:04, 92.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5738/5962 [00:37<00:01, 142.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 5703/5962 [00:37<00:03, 77.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5790/5962 [00:37<00:00, 176.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 5399/5962 [00:37<00:05, 104.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 5450/5962 [00:38<00:02, 177.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|████████████████████████████████████   | 5521/5962 [00:38<00:04, 96.59it/s]\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████ | 5808/5962 [00:37<00:00, 171.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▋ | 5753/5962 [00:37<00:01, 133.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 5415/5962 [00:37<00:04, 112.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 5391/5962 [00:37<00:03, 181.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 5469/5962 [00:38<00:02, 173.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▎  | 5535/5962 [00:38<00:04, 106.32it/s]\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5826/5962 [00:38<00:00, 170.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 5437/5962 [00:38<00:03, 134.42it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5720/5962 [00:37<00:03, 70.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5767/5962 [00:37<00:01, 120.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 5494/5962 [00:38<00:02, 181.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▍  | 5555/5962 [00:38<00:03, 128.35it/s]\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5844/5962 [00:38<00:00, 165.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 5464/5962 [00:38<00:02, 166.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 5728/5962 [00:37<00:03, 69.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▏  | 5513/5962 [00:38<00:02, 172.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|███████████████████████████████████▍  | 5568/5962 [00:38<00:03, 120.45it/s]\u001b[A\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5863/5962 [00:38<00:00, 168.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5780/5962 [00:38<00:01, 102.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5488/5962 [00:38<00:02, 185.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 5744/5962 [00:38<00:02, 88.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 5445/5962 [00:38<00:03, 160.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 5883/5962 [00:38<00:00, 172.17it/s]\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▌  | 5586/5962 [00:38<00:02, 131.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5531/5962 [00:38<00:02, 161.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5516/5962 [00:38<00:02, 211.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 5757/5962 [00:38<00:02, 98.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 5905/5962 [00:38<00:00, 183.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 5462/5962 [00:38<00:03, 144.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5802/5962 [00:38<00:01, 100.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5770/5962 [00:38<00:01, 106.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5538/5962 [00:38<00:02, 195.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5580/5962 [00:38<00:01, 196.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████ | 5821/5962 [00:38<00:01, 115.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▊  | 5617/5962 [00:38<00:02, 118.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5782/5962 [00:38<00:01, 102.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5559/5962 [00:38<00:02, 182.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5601/5962 [00:39<00:01, 195.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5477/5962 [00:38<00:04, 111.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5843/5962 [00:38<00:00, 140.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:38<00:00, 153.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▊  | 5622/5962 [00:39<00:01, 199.33it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 5491/5962 [00:38<00:04, 116.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5858/5962 [00:38<00:00, 136.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████ | 5808/5962 [00:38<00:01, 111.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|███████████████████████████████████▉  | 5643/5962 [00:39<00:01, 198.89it/s]\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5595/5962 [00:38<00:02, 156.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 5874/5962 [00:38<00:00, 142.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████   | 5504/5962 [00:38<00:04, 106.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████ | 5821/5962 [00:38<00:01, 113.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████  | 5667/5962 [00:39<00:01, 209.24it/s]\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5615/5962 [00:39<00:02, 166.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 5895/5962 [00:38<00:00, 160.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 5522/5962 [00:38<00:03, 123.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5833/5962 [00:38<00:01, 108.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▏ | 5677/5962 [00:39<00:02, 122.33it/s]\u001b[A\n",
      "\n",
      " 95%|████████████████████████████████████▎ | 5689/5962 [00:39<00:01, 184.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 5538/5962 [00:39<00:03, 127.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 5912/5962 [00:39<00:00, 144.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▎ | 5696/5962 [00:39<00:01, 138.69it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5845/5962 [00:38<00:01, 103.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 5709/5962 [00:39<00:01, 186.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5552/5962 [00:39<00:03, 125.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▍ | 5712/5962 [00:39<00:01, 143.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▊| 5927/5962 [00:39<00:00, 125.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5680/5962 [00:39<00:01, 197.65it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5737/5962 [00:39<00:01, 210.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 5567/5962 [00:39<00:03, 130.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▌ | 5728/5962 [00:39<00:01, 146.68it/s]\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 5701/5962 [00:39<00:01, 196.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▋ | 5759/5962 [00:39<00:01, 198.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▊| 5941/5962 [00:39<00:00, 114.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 5584/5962 [00:39<00:02, 136.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|████████████████████████████████████▋ | 5754/5962 [00:39<00:01, 176.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5780/5962 [00:39<00:00, 201.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 5722/5962 [00:39<00:01, 181.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▉| 5954/5962 [00:39<00:00, 117.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 5605/5962 [00:39<00:02, 154.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:39<00:00, 150.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5801/5962 [00:40<00:00, 169.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5741/5962 [00:39<00:01, 153.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 5621/5962 [00:39<00:02, 136.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|████████████████████████████████████▉ | 5789/5962 [00:39<00:01, 136.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 5895/5962 [00:39<00:00, 80.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████ | 5820/5962 [00:40<00:00, 162.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 5636/5962 [00:39<00:02, 131.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|█████████████████████████████████████ | 5807/5962 [00:40<00:01, 146.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 5916/5962 [00:39<00:00, 112.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5839/5962 [00:40<00:00, 164.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 5650/5962 [00:39<00:02, 123.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████ | 5824/5962 [00:40<00:00, 152.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▊| 5942/5962 [00:39<00:00, 147.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████▍| 5866/5962 [00:40<00:00, 191.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5669/5962 [00:40<00:02, 140.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:39<00:00, 149.42it/s]\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 5893/5962 [00:40<00:00, 212.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 5684/5962 [00:40<00:01, 142.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████▍| 5871/5962 [00:40<00:00, 190.59it/s]\u001b[A\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 5917/5962 [00:40<00:00, 218.64it/s]\u001b[A\u001b[A\n",
      " 99%|█████████████████████████████████████▌| 5901/5962 [00:40<00:00, 220.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 5699/5962 [00:40<00:01, 140.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████▊| 5940/5962 [00:40<00:00, 210.50it/s]\u001b[A\u001b[A\n",
      " 99%|█████████████████████████████████████▊| 5929/5962 [00:40<00:00, 231.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 5714/5962 [00:40<00:01, 132.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:40<00:00, 145.92it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████▉| 5953/5962 [00:40<00:00, 206.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5728/5962 [00:40<00:01, 125.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:40<00:00, 146.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 5742/5962 [00:40<00:01, 127.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:40<00:00, 146.19it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 5767/5962 [00:40<00:01, 160.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 5799/5962 [00:40<00:00, 204.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 5831/5962 [00:40<00:00, 233.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 5859/5962 [00:41<00:00, 245.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 5890/5962 [00:41<00:00, 262.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 5962/5962 [00:41<00:00, 144.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_train.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa.tsv\n",
      "Processing Started...\n",
      "Data Size:  9202\n",
      "number of threads:  7\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  1%|▌                                       | 17/1314 [00:00<00:07, 167.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  2%|▊                                       | 28/1314 [00:00<00:04, 268.63it/s]\u001b[A\n",
      "\n",
      "  1%|▍                                       | 16/1314 [00:00<00:08, 154.74it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 23/1314 [00:00<00:05, 227.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                         | 9/1314 [00:00<00:14, 89.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/1314 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  3%|█                                       | 34/1314 [00:00<00:08, 149.49it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                         | 9/1314 [00:00<00:14, 88.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                        | 18/1314 [00:00<00:14, 88.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 46/1314 [00:00<00:06, 193.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                      | 50/1314 [00:00<00:09, 132.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                        | 22/1314 [00:00<00:15, 84.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▋                                      | 55/1314 [00:00<00:08, 141.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                        | 29/1314 [00:00<00:13, 96.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 22/1314 [00:00<00:12, 100.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▎                                      | 45/1314 [00:00<00:11, 115.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                      | 64/1314 [00:00<00:10, 117.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                       | 39/1314 [00:00<00:14, 88.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                        | 33/1314 [00:00<00:13, 93.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|██                                      | 66/1314 [00:00<00:10, 117.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▊                                      | 58/1314 [00:00<00:12, 101.53it/s]\u001b[A\u001b[A\n",
      "  6%|██▏                                     | 73/1314 [00:00<00:10, 120.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▎                                     | 77/1314 [00:00<00:10, 113.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                       | 48/1314 [00:00<00:14, 87.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 47/1314 [00:00<00:11, 109.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▌                                     | 84/1314 [00:00<00:09, 132.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▏                                     | 73/1314 [00:00<00:10, 113.26it/s]\u001b[A\u001b[A\n",
      "  7%|██▊                                     | 93/1314 [00:00<00:08, 140.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 104/1314 [00:00<00:07, 155.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▊                                       | 60/1314 [00:00<00:13, 93.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                     | 71/1314 [00:00<00:08, 153.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 120/1314 [00:00<00:06, 192.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▍                                   | 114/1314 [00:00<00:07, 156.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 128/1314 [00:00<00:06, 175.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|██▏                                      | 70/1314 [00:00<00:13, 94.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 108/1314 [00:00<00:05, 222.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 146/1314 [00:00<00:05, 210.03it/s]\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▉                                   | 132/1314 [00:00<00:07, 161.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                     | 88/1314 [00:00<00:09, 131.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▉                                     | 97/1314 [00:00<00:11, 102.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                   | 136/1314 [00:00<00:04, 240.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 147/1314 [00:00<00:07, 161.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████                                  | 170/1314 [00:00<00:06, 186.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 102/1314 [00:00<00:09, 124.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███▎                                    | 108/1314 [00:01<00:12, 93.02it/s]\u001b[A\u001b[A\n",
      " 12%|████▊                                  | 164/1314 [00:01<00:08, 139.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▊                                      | 90/1314 [00:01<00:16, 73.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▊                                  | 161/1314 [00:00<00:06, 179.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▌                                    | 118/1314 [00:01<00:13, 90.09it/s]\u001b[A\u001b[A\n",
      " 13%|█████                                  | 172/1314 [00:01<00:07, 147.41it/s]\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 191/1314 [00:01<00:07, 159.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                    | 115/1314 [00:01<00:12, 93.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 182/1314 [00:01<00:06, 183.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▎                                 | 179/1314 [00:01<00:09, 121.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 210/1314 [00:01<00:06, 164.75it/s]\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▌                                 | 189/1314 [00:01<00:07, 141.00it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 208/1314 [00:01<00:05, 202.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 194/1314 [00:01<00:08, 126.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▊                                | 229/1314 [00:01<00:06, 170.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▉                                    | 128/1314 [00:01<00:16, 70.68it/s]\u001b[A\u001b[A\n",
      " 16%|██████                                 | 206/1314 [00:01<00:07, 144.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                    | 126/1314 [00:01<00:14, 80.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▊                                | 230/1314 [00:01<00:05, 190.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 211/1314 [00:01<00:08, 136.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████▎                                   | 140/1314 [00:01<00:14, 80.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▏                                   | 136/1314 [00:01<00:14, 82.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▎                               | 248/1314 [00:01<00:07, 147.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                                | 236/1314 [00:01<00:06, 164.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                    | 123/1314 [00:01<00:17, 69.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 12%|████▋                                   | 156/1314 [00:01<00:11, 96.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▌                                   | 150/1314 [00:01<00:12, 95.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▋                               | 257/1314 [00:01<00:05, 176.38it/s]\u001b[A\u001b[A\u001b[A\n",
      " 18%|███████                                | 239/1314 [00:01<00:08, 124.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                               | 271/1314 [00:01<00:05, 177.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 170/1314 [00:01<00:11, 103.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▉                                   | 161/1314 [00:01<00:12, 92.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▏                              | 276/1314 [00:01<00:05, 175.07it/s]\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▌                               | 253/1314 [00:01<00:08, 125.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▏                                   | 139/1314 [00:01<00:16, 70.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                              | 290/1314 [00:01<00:05, 176.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                  | 171/1314 [00:01<00:12, 90.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▉                              | 302/1314 [00:01<00:06, 159.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▌                                  | 182/1314 [00:01<00:12, 87.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▊                              | 295/1314 [00:01<00:06, 161.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                  | 184/1314 [00:01<00:11, 99.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▉                               | 267/1314 [00:01<00:09, 110.70it/s]\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▍                             | 319/1314 [00:01<00:06, 158.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▊                             | 332/1314 [00:01<00:05, 190.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                             | 312/1314 [00:02<00:06, 157.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 201/1314 [00:01<00:09, 117.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▎                              | 279/1314 [00:02<00:09, 111.05it/s]\u001b[A\n",
      "\n",
      "\n",
      " 26%|█████████▉                             | 336/1314 [00:02<00:06, 159.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|█████▊                                  | 192/1314 [00:02<00:15, 71.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                  | 169/1314 [00:02<00:13, 84.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████                             | 337/1314 [00:02<00:05, 182.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▋                              | 294/1314 [00:02<00:08, 119.94it/s]\u001b[A\n",
      "\n",
      " 15%|██████                                  | 201/1314 [00:02<00:14, 74.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▍                            | 353/1314 [00:02<00:06, 145.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 214/1314 [00:02<00:10, 102.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 357/1314 [00:02<00:05, 186.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 372/1314 [00:02<00:05, 178.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|█████████▏                             | 308/1314 [00:02<00:08, 122.22it/s]\u001b[A\n",
      "\n",
      " 29%|███████████▏                           | 379/1314 [00:02<00:04, 194.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▋                           | 392/1314 [00:02<00:05, 183.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|██████████▉                            | 368/1314 [00:02<00:06, 136.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▋                                  | 187/1314 [00:02<00:14, 80.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                 | 225/1314 [00:02<00:11, 95.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████▌                             | 321/1314 [00:02<00:08, 115.32it/s]\u001b[A\n",
      "\n",
      " 30%|███████████▊                           | 399/1314 [00:02<00:04, 188.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                  | 196/1314 [00:02<00:13, 82.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 382/1314 [00:02<00:07, 132.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 411/1314 [00:02<00:05, 178.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▏                                | 236/1314 [00:02<00:10, 98.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▉                             | 335/1314 [00:02<00:08, 119.08it/s]\u001b[A\n",
      "\n",
      " 32%|████████████▌                          | 424/1314 [00:02<00:04, 205.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                 | 205/1314 [00:02<00:13, 83.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|███████████▉                           | 401/1314 [00:02<00:06, 146.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                               | 247/1314 [00:02<00:10, 100.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 430/1314 [00:02<00:05, 174.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▎                            | 349/1314 [00:02<00:07, 122.48it/s]\u001b[A\n",
      "\n",
      " 34%|█████████████▏                         | 445/1314 [00:02<00:04, 201.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                               | 258/1314 [00:02<00:10, 101.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                 | 214/1314 [00:02<00:13, 80.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▎                          | 416/1314 [00:02<00:06, 137.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▎                         | 448/1314 [00:02<00:05, 167.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|██████████▊                            | 365/1314 [00:02<00:07, 130.96it/s]\u001b[A\n",
      "\n",
      " 19%|███████▋                                | 253/1314 [00:02<00:11, 94.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 466/1314 [00:02<00:04, 194.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 432/1314 [00:02<00:06, 135.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 465/1314 [00:02<00:05, 148.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▏                           | 379/1314 [00:02<00:07, 126.53it/s]\u001b[A\n",
      "\n",
      " 20%|████████                                | 265/1314 [00:02<00:10, 99.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                 | 223/1314 [00:02<00:16, 66.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                              | 281/1314 [00:02<00:10, 102.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▏                         | 446/1314 [00:02<00:07, 122.36it/s]\u001b[A\u001b[A\u001b[A\n",
      " 30%|███████████▋                           | 392/1314 [00:02<00:07, 123.73it/s]\u001b[A\n",
      "\n",
      " 37%|██████████████▍                        | 486/1314 [00:03<00:05, 153.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▋                              | 292/1314 [00:02<00:09, 103.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▎                        | 481/1314 [00:02<00:06, 125.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                                 | 231/1314 [00:03<00:18, 59.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 409/1314 [00:03<00:06, 136.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▉                        | 503/1314 [00:03<00:05, 148.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 496/1314 [00:02<00:06, 129.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▏                              | 303/1314 [00:03<00:10, 94.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████▎                        | 483/1314 [00:03<00:05, 147.21it/s]\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▋                          | 426/1314 [00:03<00:06, 143.85it/s]\u001b[A\n",
      "\n",
      " 23%|████████▊                              | 298/1314 [00:03<00:10, 101.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▍                       | 519/1314 [00:03<00:05, 149.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▏                       | 510/1314 [00:03<00:06, 128.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 499/1314 [00:03<00:05, 146.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▏                             | 310/1314 [00:03<00:09, 105.91it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                                | 244/1314 [00:03<00:19, 55.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 543/1314 [00:03<00:04, 168.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|█████████████                          | 441/1314 [00:03<00:07, 123.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▉                       | 538/1314 [00:03<00:04, 164.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▌                       | 523/1314 [00:03<00:04, 171.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|█████████▌                             | 322/1314 [00:03<00:09, 109.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▉                      | 570/1314 [00:03<00:03, 194.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▊                         | 465/1314 [00:03<00:05, 151.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▋                      | 561/1314 [00:03<00:04, 180.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|████████████████                       | 541/1314 [00:03<00:04, 173.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▌                     | 593/1314 [00:03<00:03, 203.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▊                                | 256/1314 [00:03<00:19, 55.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████▍                        | 488/1314 [00:03<00:04, 166.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▎                     | 582/1314 [00:03<00:03, 186.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|██████████▏                             | 333/1314 [00:03<00:10, 90.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████                              | 332/1314 [00:03<00:12, 76.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▌                      | 559/1314 [00:03<00:04, 168.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████                                | 265/1314 [00:03<00:16, 64.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 614/1314 [00:03<00:03, 177.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▍                             | 341/1314 [00:03<00:12, 78.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 44%|█████████████████▏                     | 578/1314 [00:03<00:04, 172.86it/s]\u001b[A\u001b[A\u001b[A\n",
      " 39%|███████████████                        | 506/1314 [00:03<00:05, 145.28it/s]\u001b[A\n",
      "\n",
      " 26%|██████████▍                             | 343/1314 [00:03<00:11, 81.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                               | 274/1314 [00:03<00:14, 69.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▌                    | 627/1314 [00:03<00:03, 174.12it/s]\n",
      "\n",
      " 27%|██████████▊                             | 357/1314 [00:03<00:10, 94.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▊                    | 633/1314 [00:03<00:04, 158.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|█████████████████▋                     | 596/1314 [00:03<00:04, 154.25it/s]\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████▍                       | 522/1314 [00:03<00:05, 132.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▌                               | 282/1314 [00:03<00:15, 65.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████▏                   | 646/1314 [00:03<00:03, 174.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▉                             | 359/1314 [00:03<00:12, 78.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 613/1314 [00:03<00:04, 158.06it/s]\u001b[A\u001b[A\u001b[A\n",
      " 49%|███████████████████▎                   | 650/1314 [00:04<00:04, 137.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▊                               | 289/1314 [00:03<00:16, 60.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████▌                            | 379/1314 [00:04<00:09, 99.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▏                            | 368/1314 [00:03<00:11, 80.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▋                   | 665/1314 [00:03<00:03, 170.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▊                    | 632/1314 [00:04<00:04, 160.19it/s]\u001b[A\u001b[A\u001b[A\n",
      " 42%|████████████████▍                      | 552/1314 [00:04<00:05, 137.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████                               | 297/1314 [00:04<00:15, 64.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▋                   | 665/1314 [00:04<00:05, 119.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|█████████████████▏                     | 579/1314 [00:04<00:04, 168.24it/s]\u001b[A\n",
      "\n",
      " 30%|███████████▊                            | 390/1314 [00:04<00:10, 89.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▎                  | 683/1314 [00:04<00:04, 152.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▎                              | 306/1314 [00:04<00:14, 69.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▊                            | 387/1314 [00:04<00:10, 86.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████▎                   | 649/1314 [00:04<00:05, 125.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|████████████▏                           | 400/1314 [00:04<00:10, 87.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▊                              | 324/1314 [00:04<00:10, 98.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████                   | 678/1314 [00:04<00:05, 109.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████                            | 397/1314 [00:04<00:10, 89.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▋                     | 597/1314 [00:04<00:05, 138.57it/s]\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▋                   | 664/1314 [00:04<00:05, 127.29it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|████████████▍                           | 410/1314 [00:04<00:10, 86.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▍                  | 690/1314 [00:04<00:06, 103.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▍                           | 407/1314 [00:04<00:10, 85.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|████████████████████                   | 678/1314 [00:04<00:05, 126.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|████████████▊                           | 419/1314 [00:04<00:10, 85.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 354/1314 [00:04<00:08, 117.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▋                 | 732/1314 [00:04<00:04, 141.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▊                           | 420/1314 [00:04<00:09, 94.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|█████████████████████▎                  | 701/1314 [00:04<00:06, 95.84it/s]\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████▌                  | 692/1314 [00:04<00:05, 123.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|█████████████                           | 428/1314 [00:04<00:10, 85.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 366/1314 [00:04<00:08, 116.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▏                | 747/1314 [00:04<00:04, 139.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████                           | 430/1314 [00:04<00:09, 93.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|█████████████████████▋                  | 711/1314 [00:04<00:06, 92.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|█████████████▎                          | 437/1314 [00:04<00:10, 85.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 380/1314 [00:04<00:07, 122.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████▌                    | 626/1314 [00:04<00:06, 102.97it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▌                | 762/1314 [00:04<00:04, 137.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████▍                          | 440/1314 [00:04<00:09, 88.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▍                 | 724/1314 [00:04<00:04, 137.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\u001b[A\n",
      " 49%|██████████████████▉                    | 639/1314 [00:04<00:06, 108.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▋                           | 393/1314 [00:04<00:07, 117.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████                | 776/1314 [00:04<00:03, 136.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|█████████████████████▉                 | 739/1314 [00:04<00:04, 138.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|██████████████                          | 460/1314 [00:04<00:08, 98.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▋                          | 449/1314 [00:04<00:10, 83.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|██████████████████████▏                 | 730/1314 [00:05<00:06, 85.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 410/1314 [00:04<00:07, 128.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▌               | 795/1314 [00:04<00:03, 149.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████▍                | 757/1314 [00:05<00:03, 149.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|██████████████▎                         | 470/1314 [00:05<00:08, 94.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▉                          | 458/1314 [00:05<00:10, 81.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|███████████████████▋                   | 663/1314 [00:05<00:05, 108.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|██████████████████████▍                 | 739/1314 [00:05<00:06, 82.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▏              | 816/1314 [00:04<00:03, 162.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|███████████████████████                | 779/1314 [00:05<00:03, 169.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████                   | 677/1314 [00:05<00:05, 115.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▊                 | 748/1314 [00:05<00:06, 83.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▊              | 835/1314 [00:05<00:02, 169.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████▌                         | 480/1314 [00:05<00:10, 82.42it/s]\u001b[A\u001b[A\n",
      " 53%|████████████████████▌                  | 694/1314 [00:05<00:04, 127.95it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████                 | 757/1314 [00:05<00:06, 84.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▌                         | 458/1314 [00:05<00:06, 142.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▎             | 853/1314 [00:05<00:02, 167.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▋               | 797/1314 [00:05<00:03, 137.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████▉                         | 489/1314 [00:05<00:11, 69.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████▎                | 766/1314 [00:05<00:07, 72.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 473/1314 [00:05<00:07, 116.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|███████████████▍                        | 506/1314 [00:05<00:08, 92.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▊             | 870/1314 [00:05<00:03, 128.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 54%|█████████████████████▌                  | 708/1314 [00:05<00:06, 95.45it/s]\u001b[A\n",
      "\n",
      "\n",
      " 62%|████████████████████████               | 812/1314 [00:05<00:04, 106.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████▌                | 775/1314 [00:05<00:07, 70.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▎                       | 516/1314 [00:05<00:07, 106.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▍                       | 521/1314 [00:05<00:07, 101.63it/s]\u001b[A\u001b[A\n",
      " 55%|█████████████████████▉                  | 720/1314 [00:05<00:06, 91.88it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▎            | 885/1314 [00:05<00:03, 119.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 500/1314 [00:05<00:06, 124.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|████████████████████████▍              | 825/1314 [00:05<00:04, 104.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▉                | 787/1314 [00:05<00:06, 81.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 41%|███████████████▉                       | 535/1314 [00:05<00:07, 109.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▉            | 907/1314 [00:05<00:02, 142.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▍                       | 519/1314 [00:05<00:05, 140.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 64%|████████████████████████▉              | 841/1314 [00:05<00:04, 112.78it/s]\u001b[A\u001b[A\u001b[A\n",
      " 56%|██████████████████████▎                 | 731/1314 [00:05<00:06, 85.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████▏               | 796/1314 [00:05<00:06, 79.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|████████████████▍                      | 555/1314 [00:05<00:05, 131.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 927/1314 [00:05<00:02, 155.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                       | 534/1314 [00:05<00:05, 142.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|█████████████████                      | 575/1314 [00:05<00:05, 145.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▌                      | 556/1314 [00:05<00:06, 109.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|████████████████████████▌               | 805/1314 [00:06<00:06, 73.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|██████████████████████▌                 | 741/1314 [00:06<00:07, 76.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████▎                      | 549/1314 [00:05<00:05, 142.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|█████████████████▌                     | 591/1314 [00:06<00:04, 149.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|█████████████████▎                      | 568/1314 [00:06<00:07, 99.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▋          | 966/1314 [00:05<00:02, 161.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▋                      | 564/1314 [00:06<00:05, 136.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|██████████████████████▊                 | 750/1314 [00:06<00:07, 72.51it/s]\u001b[A\n",
      "\n",
      " 46%|██████████████████                     | 607/1314 [00:06<00:04, 144.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▉              | 854/1314 [00:06<00:06, 72.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▎                     | 582/1314 [00:06<00:06, 108.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▌         | 994/1314 [00:06<00:01, 190.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████▉               | 821/1314 [00:06<00:07, 68.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|███████████████████████                 | 759/1314 [00:06<00:07, 73.85it/s]\u001b[A\n",
      "\n",
      " 48%|██████████████████▌                    | 627/1314 [00:06<00:04, 159.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▎             | 864/1314 [00:06<00:06, 73.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▋                     | 596/1314 [00:06<00:06, 116.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|█████████████████████████▏              | 829/1314 [00:06<00:06, 71.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▌                     | 592/1314 [00:06<00:05, 124.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 58%|███████████████████████▍                | 768/1314 [00:06<00:07, 76.09it/s]\u001b[A\n",
      "\n",
      " 49%|███████████████████▏                   | 647/1314 [00:06<00:03, 171.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▊             | 880/1314 [00:06<00:04, 89.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|█████████████████████████▌              | 838/1314 [00:06<00:06, 75.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 1038/1314 [00:06<00:01, 185.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████▏                    | 611/1314 [00:06<00:04, 141.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|███████████████████████▋                | 779/1314 [00:06<00:06, 84.35it/s]\u001b[A\n",
      "\n",
      " 51%|███████████████████▉                   | 671/1314 [00:06<00:03, 189.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▋            | 901/1314 [00:06<00:03, 114.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|█████████████████████████▊              | 848/1314 [00:06<00:05, 81.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 1060/1314 [00:06<00:01, 193.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▉                    | 638/1314 [00:06<00:03, 176.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████▋                  | 696/1314 [00:06<00:02, 206.59it/s]\u001b[A\u001b[A\n",
      " 60%|███████████████████████▉                | 788/1314 [00:06<00:06, 78.17it/s]\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████████████████████████              | 857/1314 [00:06<00:05, 83.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▌                   | 658/1314 [00:06<00:03, 182.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████████████████████▎                 | 718/1314 [00:06<00:02, 208.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|███████████████████▏                    | 632/1314 [00:06<00:07, 97.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 1080/1314 [00:06<00:01, 174.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 933/1314 [00:06<00:02, 130.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▎             | 866/1314 [00:06<00:06, 73.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▉                 | 740/1314 [00:06<00:02, 192.82it/s]\u001b[A\u001b[A\n",
      " 61%|████████████████████████▎               | 797/1314 [00:06<00:08, 63.89it/s]\u001b[A\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 954/1314 [00:06<00:02, 150.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 1099/1314 [00:06<00:01, 168.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|███████████████████▌                    | 643/1314 [00:06<00:07, 89.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|████████████████████████▍               | 804/1314 [00:06<00:07, 65.00it/s]\u001b[A\n",
      "\n",
      " 58%|██████████████████████▋                | 764/1314 [00:06<00:02, 203.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 1122/1314 [00:06<00:01, 183.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▌             | 874/1314 [00:07<00:06, 65.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▉                    | 653/1314 [00:06<00:07, 86.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|████████████████████████▊               | 814/1314 [00:07<00:06, 72.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 1141/1314 [00:06<00:01, 166.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████▎                 | 719/1314 [00:07<00:03, 155.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████▊             | 881/1314 [00:07<00:07, 58.95it/s]\u001b[A\u001b[A\n",
      " 63%|█████████████████████████               | 822/1314 [00:07<00:07, 70.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▉                 | 739/1314 [00:07<00:03, 166.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████                   | 677/1314 [00:07<00:06, 101.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████▉               | 805/1314 [00:07<00:02, 174.51it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|███████████████████████████             | 888/1314 [00:07<00:07, 59.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|█████████████████████████▎              | 830/1314 [00:07<00:06, 71.62it/s]\u001b[A\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▉          | 985/1314 [00:07<00:03, 97.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 763/1314 [00:07<00:02, 183.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▋                  | 695/1314 [00:07<00:05, 119.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|████████████████████████▋              | 830/1314 [00:07<00:02, 193.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|███████████████████████████▎            | 897/1314 [00:07<00:06, 66.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|█████████████████████████▋              | 845/1314 [00:07<00:05, 89.24it/s]\u001b[A\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████▎         | 997/1314 [00:07<00:03, 97.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▏               | 783/1314 [00:07<00:03, 174.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|█████████████████████████▎             | 851/1314 [00:07<00:02, 193.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████▌            | 904/1314 [00:07<00:06, 66.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 1191/1314 [00:07<00:00, 139.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 65%|██████████████████████████              | 856/1314 [00:07<00:05, 91.56it/s]\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 1010/1314 [00:07<00:02, 102.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▊               | 804/1314 [00:07<00:02, 182.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████████████████████████             | 878/1314 [00:07<00:02, 213.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▉            | 917/1314 [00:07<00:04, 81.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 1206/1314 [00:07<00:00, 136.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|██████████████████████████▎             | 866/1314 [00:07<00:05, 88.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████▍              | 823/1314 [00:07<00:02, 183.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████████████████████████▋            | 900/1314 [00:07<00:01, 207.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|██████████████████████▏                | 749/1314 [00:07<00:03, 150.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|████████████████████████████▏           | 927/1314 [00:07<00:04, 86.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▋                | 765/1314 [00:07<00:03, 152.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▉              | 842/1314 [00:07<00:02, 172.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 1220/1314 [00:07<00:00, 116.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▎           | 922/1314 [00:07<00:02, 194.04it/s]\u001b[A\u001b[A\n",
      " 71%|████████████████████████████▌           | 938/1314 [00:07<00:04, 91.88it/s]\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 1033/1314 [00:07<00:03, 89.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▌             | 863/1314 [00:07<00:02, 181.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▏               | 782/1314 [00:07<00:03, 154.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▊  | 1239/1314 [00:07<00:00, 133.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|███████████████████████████             | 887/1314 [00:07<00:04, 87.31it/s]\u001b[A\n",
      "\n",
      " 72%|████████████████████████████           | 947/1314 [00:07<00:01, 201.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▊           | 948/1314 [00:07<00:04, 84.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▏            | 882/1314 [00:07<00:02, 183.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 1259/1314 [00:07<00:00, 142.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|█████████████████████████████▏          | 958/1314 [00:08<00:04, 88.19it/s]\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▎       | 1054/1314 [00:07<00:02, 92.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▋               | 798/1314 [00:07<00:04, 125.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▋          | 968/1314 [00:08<00:01, 174.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▋            | 901/1314 [00:08<00:02, 168.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████▌          | 970/1314 [00:08<00:03, 95.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 1065/1314 [00:08<00:02, 96.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████▍              | 823/1314 [00:08<00:03, 155.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████▍         | 990/1314 [00:08<00:01, 185.72it/s]\u001b[A\u001b[A\n",
      " 70%|███████████████████████████▊            | 914/1314 [00:08<00:04, 88.76it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▍           | 925/1314 [00:08<00:02, 187.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▏         | 982/1314 [00:08<00:03, 100.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▉              | 840/1314 [00:08<00:03, 155.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|████████████████████████████▏           | 924/1314 [00:08<00:04, 90.65it/s]\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▏        | 1010/1314 [00:08<00:01, 178.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 1075/1314 [00:08<00:02, 85.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|██████████████████████████████▏         | 993/1314 [00:08<00:03, 99.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:08<00:00, 160.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▌             | 861/1314 [00:08<00:02, 168.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|█████████████████████████████▊        | 1031/1314 [00:08<00:01, 183.59it/s]\u001b[A\u001b[A\n",
      " 71%|████████████████████████████▍           | 934/1314 [00:08<00:04, 88.85it/s]\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████▏      | 1084/1314 [00:08<00:02, 84.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████         | 1005/1314 [00:08<00:03, 101.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████             | 879/1314 [00:08<00:02, 170.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 72%|████████████████████████████▊           | 945/1314 [00:08<00:03, 92.65it/s]\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████▎       | 1050/1314 [00:08<00:01, 178.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▍      | 1093/1314 [00:08<00:02, 79.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▎         | 986/1314 [00:08<00:01, 190.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 1016/1314 [00:08<00:02, 101.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████       | 1073/1314 [00:08<00:01, 191.25it/s]\u001b[A\u001b[A\n",
      " 73%|█████████████████████████████           | 955/1314 [00:08<00:04, 86.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 1006/1314 [00:08<00:01, 190.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 1034/1314 [00:08<00:02, 120.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▍           | 923/1314 [00:08<00:02, 184.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▌      | 1093/1314 [00:08<00:01, 189.04it/s]\u001b[A\u001b[A\n",
      " 74%|████████████████████████████▊          | 970/1314 [00:08<00:03, 102.54it/s]\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 1118/1314 [00:08<00:02, 96.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 1026/1314 [00:08<00:01, 181.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 1054/1314 [00:08<00:01, 141.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████████████████████████████▏     | 1113/1314 [00:08<00:01, 190.83it/s]\u001b[A\u001b[A\n",
      " 76%|█████████████████████████████▌         | 994/1314 [00:08<00:02, 137.91it/s]\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 1136/1314 [00:08<00:01, 117.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████▉       | 1071/1314 [00:08<00:01, 148.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 969/1314 [00:08<00:01, 204.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████▊     | 1133/1314 [00:08<00:00, 182.84it/s]\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▏        | 1009/1314 [00:08<00:02, 140.17it/s]\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 1149/1314 [00:08<00:01, 115.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 1087/1314 [00:09<00:01, 150.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▍         | 990/1314 [00:08<00:01, 205.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 1162/1314 [00:09<00:00, 212.47it/s]\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████▋        | 1027/1314 [00:09<00:01, 150.74it/s]\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 1170/1314 [00:09<00:01, 140.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▉      | 1106/1314 [00:09<00:01, 161.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▍        | 1019/1314 [00:08<00:01, 229.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▎       | 1047/1314 [00:09<00:01, 163.34it/s]\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 1186/1314 [00:09<00:00, 215.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 1111/1314 [00:09<00:00, 205.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 1126/1314 [00:09<00:01, 171.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 1046/1314 [00:09<00:01, 239.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▊       | 1064/1314 [00:09<00:01, 161.27it/s]\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 1208/1314 [00:09<00:00, 202.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 1147/1314 [00:09<00:00, 182.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 1080/1314 [00:09<00:00, 266.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▋     | 1132/1314 [00:09<00:00, 189.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▋    | 1167/1314 [00:09<00:00, 152.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▌  | 1229/1314 [00:09<00:00, 154.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 1107/1314 [00:09<00:00, 212.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▎      | 1081/1314 [00:09<00:01, 117.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 1184/1314 [00:09<00:00, 153.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 1234/1314 [00:09<00:00, 116.44it/s]\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▋      | 1095/1314 [00:09<00:01, 114.72it/s]\u001b[A\n",
      "\n",
      " 95%|████████████████████████████████████  | 1247/1314 [00:09<00:00, 138.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▊   | 1202/1314 [00:09<00:00, 155.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 1169/1314 [00:09<00:01, 123.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 84%|████████████████████████████████      | 1108/1314 [00:09<00:01, 113.35it/s]\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████  | 1247/1314 [00:09<00:00, 104.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 1266/1314 [00:09<00:00, 146.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 1219/1314 [00:09<00:00, 151.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▍     | 1121/1314 [00:09<00:01, 115.59it/s]\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████ | 1282/1314 [00:09<00:00, 142.06it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▉    | 1172/1314 [00:09<00:00, 173.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 1235/1314 [00:09<00:00, 135.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 1184/1314 [00:09<00:01, 95.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 1298/1314 [00:09<00:00, 142.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▌   | 1195/1314 [00:09<00:00, 185.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▏ | 1250/1314 [00:10<00:00, 136.33it/s]\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▋ | 1269/1314 [00:10<00:00, 85.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 1219/1314 [00:10<00:00, 199.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:10<00:00, 129.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 1264/1314 [00:10<00:00, 135.72it/s]\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 1196/1314 [00:10<00:01, 85.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████▉     | 1145/1314 [00:10<00:02, 84.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 1285/1314 [00:10<00:00, 154.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▋| 1302/1314 [00:10<00:00, 110.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▊   | 1206/1314 [00:10<00:01, 80.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|██████████████████████████████████▎    | 1155/1314 [00:10<00:01, 80.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:10<00:00, 127.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████   | 1215/1314 [00:10<00:01, 81.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:10<00:00, 125.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████ | 1280/1314 [00:10<00:00, 175.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▎  | 1224/1314 [00:10<00:01, 79.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 90%|███████████████████████████████████    | 1180/1314 [00:10<00:01, 97.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▌| 1298/1314 [00:10<00:00, 147.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▌  | 1233/1314 [00:10<00:01, 74.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▎   | 1191/1314 [00:10<00:01, 90.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:10<00:00, 122.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▊  | 1241/1314 [00:10<00:01, 71.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████▋   | 1201/1314 [00:10<00:01, 82.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 1249/1314 [00:10<00:00, 69.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 93%|████████████████████████████████████   | 1216/1314 [00:10<00:00, 98.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 1257/1314 [00:10<00:00, 71.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▋  | 1234/1314 [00:11<00:00, 118.44it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 1267/1314 [00:11<00:00, 78.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|████████████████████████████████████▏ | 1252/1314 [00:11<00:00, 134.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 1280/1314 [00:11<00:00, 90.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|████████████████████████████████████▋ | 1267/1314 [00:11<00:00, 135.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████▎| 1292/1314 [00:11<00:00, 98.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████▎| 1289/1314 [00:11<00:00, 157.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:11<00:00, 115.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 1314/1314 [00:11<00:00, 114.42it/s]\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb.tsv\n",
      "Processing Started...\n",
      "Data Size:  18406\n",
      "number of threads:  7\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 18/2629 [00:00<00:15, 174.02it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  1%|▎                                       | 18/2629 [00:00<00:14, 175.34it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  1%|▎                                       | 19/2629 [00:00<00:14, 184.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▌                                       | 39/2629 [00:00<00:13, 193.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                        | 10/2629 [00:00<00:29, 89.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  1%|▌                                       | 36/2629 [00:00<00:17, 147.10it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  1%|▌                                       | 38/2629 [00:00<00:18, 142.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                       | 22/2629 [00:00<00:25, 101.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                  | 0/2629 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▎                                        | 22/2629 [00:00<00:30, 85.08it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  2%|▊                                       | 51/2629 [00:00<00:22, 114.71it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                       | 11/2629 [00:00<00:23, 109.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|▏                                        | 12/2629 [00:00<00:45, 57.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                        | 33/2629 [00:00<00:26, 99.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▌                                        | 33/2629 [00:00<00:28, 91.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  2%|▉                                       | 59/2629 [00:00<00:24, 104.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 24/2629 [00:00<00:30, 84.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  2%|▉                                       | 64/2629 [00:00<00:23, 109.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                       | 47/2629 [00:00<00:22, 112.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█                                       | 68/2629 [00:00<00:20, 123.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▋                                        | 44/2629 [00:00<00:28, 90.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▎                                        | 22/2629 [00:00<00:30, 85.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▌                                        | 34/2629 [00:00<00:29, 88.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  3%|█▎                                      | 83/2629 [00:00<00:19, 129.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                       | 59/2629 [00:00<00:25, 102.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▊                                        | 54/2629 [00:00<00:28, 88.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                       | 73/2629 [00:00<00:29, 85.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▋                                        | 44/2629 [00:00<00:28, 91.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▎                                       | 81/2629 [00:00<00:25, 98.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 71/2629 [00:00<00:24, 104.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▉                                        | 63/2629 [00:00<00:30, 83.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▍                                      | 97/2629 [00:00<00:23, 108.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▌                                        | 40/2629 [00:00<00:34, 74.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                       | 84/2629 [00:00<00:31, 81.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  3%|█▍                                       | 92/2629 [00:00<00:26, 94.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 97/2629 [00:00<00:16, 150.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|█▏                                       | 74/2629 [00:00<00:29, 87.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "  5%|█▊                                     | 121/2629 [00:00<00:18, 138.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█                                       | 71/2629 [00:00<00:22, 114.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                       | 95/2629 [00:00<00:29, 86.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  4%|█▌                                      | 103/2629 [00:00<00:25, 98.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 114/2629 [00:00<00:16, 155.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▎                                      | 84/2629 [00:00<00:22, 114.09it/s]\n",
      "\n",
      "\n",
      "  3%|█▎                                       | 85/2629 [00:00<00:30, 82.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "  4%|█▌                                      | 105/2629 [00:01<00:29, 86.36it/s]\u001b[A\n",
      "\n",
      "  4%|█▋                                     | 114/2629 [00:01<00:25, 100.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                        | 56/2629 [00:00<00:40, 62.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 130/2629 [00:01<00:17, 141.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  4%|█▌                                     | 107/2629 [00:01<00:21, 117.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▊                                      | 117/2629 [00:01<00:26, 93.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  5%|█▊                                     | 126/2629 [00:01<00:24, 104.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▉                                        | 64/2629 [00:00<00:38, 66.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  6%|██▎                                    | 155/2629 [00:01<00:20, 120.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 145/2629 [00:01<00:18, 131.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 114/2629 [00:01<00:19, 127.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|██                                     | 139/2629 [00:01<00:19, 124.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  5%|██                                     | 141/2629 [00:01<00:21, 116.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|█▏                                       | 77/2629 [00:01<00:31, 81.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▌                                    | 172/2629 [00:01<00:19, 126.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▌                                    | 169/2629 [00:01<00:15, 158.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 128/2629 [00:01<00:19, 130.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 162/2629 [00:01<00:16, 152.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  6%|██▎                                    | 157/2629 [00:01<00:19, 127.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▍                                      | 97/2629 [00:01<00:22, 112.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▏                                    | 150/2629 [00:01<00:15, 156.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▌                                    | 171/2629 [00:01<00:13, 180.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 179/2629 [00:01<00:17, 143.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  7%|██▊                                    | 186/2629 [00:01<00:22, 109.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▋                                     | 117/2629 [00:01<00:18, 133.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▌                                    | 171/2629 [00:01<00:21, 113.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                    | 167/2629 [00:01<00:15, 159.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  8%|██▉                                    | 198/2629 [00:01<00:21, 111.98it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|█▉                                     | 134/2629 [00:01<00:17, 139.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  7%|██▉                                    | 195/2629 [00:01<00:19, 124.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|██▊                                    | 190/2629 [00:01<00:19, 122.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 184/2629 [00:01<00:19, 126.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|██▉                                    | 202/2629 [00:01<00:24, 100.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  8%|███▏                                   | 211/2629 [00:01<00:18, 130.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 230/2629 [00:01<00:16, 144.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|██▉                                    | 198/2629 [00:01<00:19, 121.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███                                     | 205/2629 [00:01<00:24, 99.77it/s]\u001b[A\u001b[A\n",
      "  8%|███▎                                    | 221/2629 [00:01<00:25, 95.25it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                    | 215/2629 [00:01<00:24, 98.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███                                    | 206/2629 [00:01<00:21, 111.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▏                                   | 214/2629 [00:01<00:18, 127.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▍                                   | 234/2629 [00:02<00:23, 102.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 246/2629 [00:02<00:17, 132.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▍                                     | 162/2629 [00:01<00:26, 94.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  8%|███▎                                    | 216/2629 [00:02<00:26, 92.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 220/2629 [00:01<00:21, 111.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▍                                   | 229/2629 [00:01<00:18, 131.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "  9%|███▋                                   | 245/2629 [00:02<00:23, 103.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 245/2629 [00:02<00:20, 115.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|██▋                                    | 179/2629 [00:01<00:22, 110.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  9%|███▍                                    | 226/2629 [00:02<00:26, 90.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 261/2629 [00:02<00:19, 123.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 248/2629 [00:02<00:16, 146.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 10%|███▊                                   | 256/2629 [00:02<00:23, 100.64it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 263/2629 [00:02<00:18, 131.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███                                    | 206/2629 [00:01<00:16, 145.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  9%|███▋                                   | 246/2629 [00:02<00:20, 115.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|████                                   | 274/2629 [00:02<00:21, 109.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                   | 264/2629 [00:02<00:17, 134.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████                                   | 278/2629 [00:02<00:18, 125.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 10%|████                                    | 267/2629 [00:02<00:25, 94.35it/s]\u001b[A\n",
      "\n",
      " 11%|████▏                                  | 286/2629 [00:02<00:22, 105.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▎                                   | 223/2629 [00:02<00:21, 112.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|███▉                                    | 259/2629 [00:02<00:26, 90.40it/s]\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▏                                   | 277/2629 [00:02<00:26, 87.88it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                  | 292/2629 [00:02<00:20, 112.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▊                                    | 254/2629 [00:02<00:30, 77.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 299/2629 [00:02<00:21, 108.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▌                                   | 237/2629 [00:02<00:20, 117.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                    | 270/2629 [00:02<00:26, 89.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|███▉                                    | 262/2629 [00:02<00:30, 78.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▌                                  | 305/2629 [00:02<00:21, 108.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 319/2629 [00:02<00:18, 128.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▊                                   | 253/2629 [00:02<00:18, 126.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 11%|████▌                                   | 296/2629 [00:02<00:27, 85.26it/s]\u001b[A\n",
      "\n",
      " 11%|████▏                                  | 281/2629 [00:02<00:22, 105.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▎                                   | 280/2629 [00:02<00:28, 83.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 334/2629 [00:02<00:17, 131.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████                                   | 278/2629 [00:02<00:15, 155.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 11%|████▍                                  | 296/2629 [00:02<00:20, 116.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 331/2629 [00:02<00:19, 116.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▍                                   | 292/2629 [00:02<00:25, 91.33it/s]\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████▏                                 | 348/2629 [00:02<00:17, 131.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 330/2629 [00:02<00:18, 126.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▍                                  | 296/2629 [00:02<00:16, 143.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 12%|████▌                                  | 309/2629 [00:02<00:19, 119.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▌                                   | 302/2629 [00:02<00:25, 91.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████                                  | 344/2629 [00:02<00:20, 112.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▊                                   | 313/2629 [00:03<00:32, 70.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|████▋                                  | 315/2629 [00:02<00:14, 154.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▎                                 | 362/2629 [00:03<00:20, 111.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▋                                   | 312/2629 [00:03<00:24, 93.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                  | 344/2629 [00:02<00:24, 93.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|████▉                                   | 321/2629 [00:03<00:36, 62.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                  | 356/2629 [00:03<00:25, 89.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|████▉                                   | 322/2629 [00:03<00:26, 87.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|████▉                                  | 332/2629 [00:02<00:17, 131.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▋                                  | 374/2629 [00:03<00:24, 93.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                  | 358/2629 [00:03<00:22, 99.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████                                   | 332/2629 [00:03<00:32, 71.15it/s]\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 348/2629 [00:03<00:17, 131.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▏                                 | 352/2629 [00:03<00:15, 146.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                  | 366/2629 [00:03<00:28, 79.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▌                                 | 373/2629 [00:03<00:20, 108.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████▏                                  | 340/2629 [00:03<00:31, 72.62it/s]\u001b[A\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 366/2629 [00:03<00:15, 143.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▍                                 | 369/2629 [00:03<00:15, 143.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▊                                  | 380/2629 [00:03<00:24, 92.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 15%|██████                                  | 396/2629 [00:03<00:24, 91.56it/s]\u001b[A\u001b[A\n",
      " 13%|█████▎                                  | 352/2629 [00:03<00:27, 84.13it/s]\u001b[A\n",
      "\n",
      "\n",
      " 15%|█████▊                                 | 389/2629 [00:03<00:13, 166.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 386/2629 [00:03<00:21, 105.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                  | 393/2629 [00:03<00:22, 99.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 14%|█████▌                                 | 377/2629 [00:03<00:19, 118.41it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▋                                 | 385/2629 [00:03<00:17, 130.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████                                 | 409/2629 [00:03<00:12, 174.51it/s]\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▌                                  | 366/2629 [00:03<00:23, 96.16it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████▏                                 | 406/2629 [00:03<00:25, 87.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|█████▉                                 | 404/2629 [00:03<00:21, 101.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▍                                 | 420/2629 [00:03<00:22, 99.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 431/2629 [00:03<00:14, 154.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 15%|█████▊                                 | 390/2629 [00:03<00:17, 130.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████                                 | 409/2629 [00:03<00:16, 136.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▏                                | 418/2629 [00:03<00:20, 108.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|██████▎                                | 427/2629 [00:03<00:15, 140.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████▏                                | 413/2629 [00:03<00:14, 156.26it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                 | 431/2629 [00:03<00:22, 97.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▎                                | 424/2629 [00:03<00:15, 140.25it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                | 431/2629 [00:03<00:19, 112.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▋                                 | 441/2629 [00:03<00:22, 97.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 470/2629 [00:03<00:13, 160.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 443/2629 [00:03<00:17, 127.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▎                                 | 412/2629 [00:03<00:22, 96.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▌                                | 440/2629 [00:03<00:15, 145.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▌                                | 443/2629 [00:03<00:19, 112.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 17%|██████▊                                | 456/2629 [00:04<00:19, 110.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▏                               | 487/2629 [00:03<00:13, 154.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|██████▊                                | 459/2629 [00:04<00:14, 153.79it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|██████▊                                | 457/2629 [00:04<00:18, 119.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▍                                 | 423/2629 [00:03<00:23, 93.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 469/2629 [00:04<00:18, 114.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 18%|███████▏                               | 485/2629 [00:04<00:11, 185.40it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                               | 508/2629 [00:03<00:12, 167.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                                | 477/2629 [00:04<00:15, 138.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 18%|███████                                | 475/2629 [00:04<00:14, 145.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|██████▉                                | 470/2629 [00:04<00:19, 112.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▏                               | 481/2629 [00:04<00:21, 100.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▍                               | 504/2629 [00:04<00:12, 167.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▊                                 | 444/2629 [00:04<00:23, 91.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 18%|███████▏                               | 482/2629 [00:04<00:19, 108.89it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▎                               | 492/2629 [00:04<00:18, 116.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▎                               | 490/2629 [00:04<00:17, 119.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▍                                | 492/2629 [00:04<00:21, 98.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 20%|███████▋                               | 522/2629 [00:04<00:12, 165.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|██████▉                                 | 454/2629 [00:04<00:23, 91.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▌                               | 507/2629 [00:04<00:17, 124.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|███████▌                               | 506/2629 [00:04<00:16, 128.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                               | 544/2629 [00:04<00:14, 140.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▌                               | 510/2629 [00:04<00:17, 118.71it/s]\u001b[A\u001b[A\u001b[A\n",
      " 21%|███████▉                               | 539/2629 [00:04<00:13, 159.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████                                 | 466/2629 [00:04<00:22, 97.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                               | 524/2629 [00:04<00:15, 136.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 20%|███████▊                               | 523/2629 [00:04<00:15, 136.48it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▋                                | 505/2629 [00:04<00:23, 92.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▊                               | 523/2629 [00:04<00:18, 114.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 21%|████████▎                              | 563/2629 [00:04<00:11, 178.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████                               | 543/2629 [00:04<00:13, 150.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████                               | 545/2629 [00:04<00:13, 158.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▎                                | 477/2629 [00:04<00:26, 81.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▉                               | 535/2629 [00:04<00:18, 115.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 22%|████████▋                              | 582/2629 [00:04<00:11, 175.07it/s]\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▊                                | 515/2629 [00:04<00:24, 86.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                              | 559/2629 [00:04<00:14, 145.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████                               | 547/2629 [00:04<00:18, 114.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                              | 595/2629 [00:04<00:15, 132.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▍                                | 486/2629 [00:04<00:29, 72.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|████████▉                              | 600/2629 [00:04<00:12, 158.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 20%|███████▉                                | 524/2629 [00:04<00:25, 81.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                              | 574/2629 [00:04<00:15, 129.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████▍                              | 565/2629 [00:05<00:15, 131.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████                              | 615/2629 [00:04<00:13, 145.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████▏                             | 623/2629 [00:05<00:11, 175.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▋                                | 504/2629 [00:04<00:22, 94.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▏                               | 539/2629 [00:04<00:21, 95.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▋                              | 588/2629 [00:04<00:15, 132.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|████████▋                              | 586/2629 [00:05<00:13, 153.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                             | 631/2629 [00:04<00:13, 146.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▋                               | 519/2629 [00:04<00:19, 106.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▎                              | 559/2629 [00:05<00:17, 121.17it/s]\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████▌                             | 642/2629 [00:05<00:11, 167.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▉                              | 602/2629 [00:05<00:15, 132.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 24%|█████████▏                             | 620/2629 [00:05<00:12, 166.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|███████▉                               | 536/2629 [00:04<00:17, 122.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▉                              | 602/2629 [00:05<00:15, 132.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▌                             | 647/2629 [00:05<00:14, 140.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▏                             | 616/2629 [00:05<00:15, 133.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 25%|█████████▊                             | 660/2629 [00:05<00:12, 162.56it/s]\u001b[A\n",
      "\n",
      " 24%|█████████▍                             | 640/2629 [00:05<00:11, 170.89it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▎                              | 558/2629 [00:05<00:14, 146.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▊                             | 663/2629 [00:05<00:13, 145.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|████████▋                              | 587/2629 [00:05<00:16, 121.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                             | 630/2629 [00:05<00:15, 132.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 23%|█████████▏                             | 616/2629 [00:05<00:18, 107.60it/s]\u001b[A\n",
      "\n",
      " 25%|█████████▊                             | 658/2629 [00:05<00:13, 151.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|████████▌                              | 579/2629 [00:05<00:12, 161.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|████████▉                              | 601/2629 [00:05<00:16, 125.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▏                            | 684/2629 [00:05<00:12, 150.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 26%|██████████▎                            | 695/2629 [00:05<00:12, 160.80it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|████████▊                              | 597/2629 [00:05<00:12, 161.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|█████████▉                             | 674/2629 [00:05<00:13, 145.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 23%|█████████                              | 614/2629 [00:05<00:16, 123.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▌                              | 628/2629 [00:05<00:20, 99.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|██████████▌                            | 712/2629 [00:05<00:12, 150.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▍                            | 700/2629 [00:05<00:15, 126.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|█████████▋                              | 639/2629 [00:05<00:21, 91.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████                              | 614/2629 [00:05<00:15, 129.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▉                              | 656/2629 [00:05<00:21, 90.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 714/2629 [00:05<00:15, 124.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▋                             | 655/2629 [00:05<00:18, 105.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 26%|██████████▍                             | 689/2629 [00:05<00:19, 99.12it/s]\u001b[A\u001b[A\n",
      " 28%|██████████▊                            | 728/2629 [00:05<00:16, 113.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▊                            | 727/2629 [00:05<00:15, 122.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▏                             | 666/2629 [00:05<00:23, 82.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|█████████▋                             | 657/2629 [00:05<00:15, 127.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▎                             | 629/2629 [00:05<00:17, 111.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 26%|█████████▉                             | 673/2629 [00:06<00:16, 115.40it/s]\u001b[A\n",
      "\n",
      " 27%|██████████▋                             | 702/2629 [00:05<00:19, 98.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 745/2629 [00:05<00:13, 134.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▎                             | 675/2629 [00:05<00:24, 80.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▏                            | 686/2629 [00:06<00:16, 115.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 27%|██████████▌                            | 715/2629 [00:06<00:18, 102.52it/s]\u001b[A\u001b[A\n",
      " 29%|███████████▏                           | 754/2629 [00:06<00:17, 105.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▊                              | 642/2629 [00:05<00:21, 94.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▍                             | 684/2629 [00:06<00:24, 78.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|██████████▊                            | 727/2629 [00:06<00:18, 105.43it/s]\u001b[A\u001b[A\n",
      " 29%|███████████▎                           | 766/2629 [00:06<00:17, 103.81it/s]\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▌                             | 698/2629 [00:06<00:19, 98.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▌                             | 695/2629 [00:06<00:23, 83.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▌                            | 759/2629 [00:06<00:20, 92.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|█████████▉                              | 653/2629 [00:05<00:22, 87.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▌                            | 711/2629 [00:06<00:18, 102.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▋                             | 704/2629 [00:06<00:24, 79.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▌                             | 695/2629 [00:06<00:21, 89.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▋                            | 771/2629 [00:06<00:22, 83.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▉                             | 722/2629 [00:06<00:19, 97.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|████████████                            | 792/2629 [00:06<00:19, 96.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▋                            | 723/2629 [00:06<00:18, 104.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▋                             | 706/2629 [00:06<00:20, 93.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████▍                            | 750/2629 [00:06<00:22, 82.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|██████████▉                            | 739/2629 [00:06<00:16, 113.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 31%|███████████▉                           | 805/2629 [00:06<00:17, 103.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▏                            | 734/2629 [00:06<00:19, 97.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████▌                            | 760/2629 [00:06<00:22, 81.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▍                             | 682/2629 [00:06<00:23, 84.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████                            | 793/2629 [00:06<00:20, 91.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|██████████▉                             | 716/2629 [00:06<00:23, 80.49it/s]\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▎                           | 761/2629 [00:06<00:14, 132.57it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████                            | 746/2629 [00:06<00:18, 101.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|███████████▋                            | 771/2629 [00:06<00:21, 86.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▌                             | 691/2629 [00:06<00:23, 84.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|███████████▉                           | 807/2629 [00:06<00:17, 101.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████                             | 725/2629 [00:06<00:23, 81.46it/s]\u001b[A\u001b[A\u001b[A\n",
      " 29%|███████████▍                           | 775/2629 [00:06<00:14, 125.71it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▌                            | 757/2629 [00:06<00:19, 95.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▋                             | 700/2629 [00:06<00:22, 85.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|███████████▉                            | 781/2629 [00:06<00:21, 85.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 820/2629 [00:06<00:17, 105.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████▏                            | 734/2629 [00:06<00:24, 76.90it/s]\u001b[A\u001b[A\u001b[A\n",
      " 32%|████████████▌                          | 849/2629 [00:06<00:15, 116.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▋                            | 767/2629 [00:06<00:19, 96.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▊                             | 709/2629 [00:06<00:22, 85.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|████████████                            | 792/2629 [00:06<00:20, 91.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▋                           | 788/2629 [00:07<00:16, 110.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 33%|████████████▉                          | 868/2629 [00:07<00:12, 136.12it/s]\u001b[A\n",
      "\n",
      "\n",
      " 28%|███████████▎                            | 743/2629 [00:06<00:24, 76.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|████████████▏                           | 802/2629 [00:07<00:19, 93.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▋                           | 785/2629 [00:07<00:16, 114.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|██████████▉                             | 718/2629 [00:06<00:23, 81.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 800/2629 [00:07<00:16, 110.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|█████████████                          | 883/2629 [00:07<00:12, 139.82it/s]\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▍                            | 751/2629 [00:07<00:24, 76.36it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▉                           | 801/2629 [00:07<00:14, 124.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████                           | 812/2629 [00:07<00:16, 108.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|████████████▎                           | 812/2629 [00:07<00:22, 82.36it/s]\u001b[A\u001b[A\n",
      " 34%|█████████████▎                         | 898/2629 [00:07<00:12, 139.61it/s]\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▌                            | 760/2629 [00:07<00:23, 79.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 819/2629 [00:07<00:13, 138.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▏                            | 739/2629 [00:07<00:20, 92.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 31%|████████████▌                           | 823/2629 [00:07<00:20, 87.86it/s]\u001b[A\u001b[A\n",
      " 35%|█████████████▌                         | 918/2629 [00:07<00:10, 155.68it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████▌                           | 823/2629 [00:07<00:18, 95.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▋                            | 769/2629 [00:07<00:24, 74.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▍                          | 837/2629 [00:07<00:12, 145.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▍                            | 751/2629 [00:07<00:18, 99.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 32%|████████████▍                          | 842/2629 [00:07<00:15, 114.36it/s]\u001b[A\u001b[A\n",
      " 36%|█████████████▉                         | 939/2629 [00:07<00:09, 169.77it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▋                           | 833/2629 [00:07<00:18, 95.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|███████████▊                            | 777/2629 [00:07<00:25, 71.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|███████████▎                           | 765/2629 [00:07<00:16, 110.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▋                          | 852/2629 [00:07<00:12, 144.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|████████████▊                          | 867/2629 [00:07<00:11, 151.10it/s]\u001b[A\u001b[A\n",
      " 37%|██████████████▎                        | 965/2629 [00:07<00:08, 192.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 847/2629 [00:07<00:16, 106.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 30%|████████████                            | 794/2629 [00:07<00:19, 96.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▌                           | 779/2629 [00:07<00:15, 115.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 867/2629 [00:07<00:12, 139.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|██████████████▌                        | 985/2629 [00:07<00:08, 193.62it/s]\u001b[A\n",
      "\n",
      " 33%|████████████▊                          | 861/2629 [00:07<00:15, 114.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▊                         | 931/2629 [00:07<00:11, 144.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|███████████▊                           | 795/2629 [00:07<00:14, 126.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████                           | 809/2629 [00:07<00:17, 106.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████                          | 884/2629 [00:07<00:11, 146.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 38%|██████████████▌                       | 1005/2629 [00:07<00:08, 194.00it/s]\u001b[A\n",
      "\n",
      " 34%|█████████████                          | 881/2629 [00:07<00:13, 133.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████▏                          | 821/2629 [00:07<00:16, 108.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▍                         | 905/2629 [00:07<00:10, 163.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|████████████                           | 809/2629 [00:07<00:14, 125.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 946/2629 [00:07<00:13, 129.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|█████████████▋                         | 920/2629 [00:07<00:10, 162.61it/s]\u001b[A\u001b[A\n",
      " 34%|█████████████▎                         | 895/2629 [00:07<00:14, 122.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▎                        | 964/2629 [00:07<00:11, 140.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▎                          | 830/2629 [00:07<00:12, 145.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▍                          | 836/2629 [00:07<00:17, 104.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|█████████████▉                         | 938/2629 [00:07<00:10, 161.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 922/2629 [00:07<00:12, 139.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|████████████▌                          | 845/2629 [00:07<00:13, 133.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|████████████▋                          | 852/2629 [00:08<00:15, 116.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|██████████████▏                        | 955/2629 [00:08<00:10, 159.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▍                         | 908/2629 [00:08<00:17, 101.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|███████████████                       | 1044/2629 [00:08<00:12, 124.55it/s]\u001b[A\n",
      "\n",
      "\n",
      " 33%|████████████▊                          | 865/2629 [00:08<00:14, 118.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|██████████████▍                        | 972/2629 [00:08<00:10, 160.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████▏                        | 955/2629 [00:08<00:11, 144.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|████████████▋                          | 859/2629 [00:07<00:14, 118.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▉                         | 979/2629 [00:08<00:17, 92.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|█████████████▉                          | 919/2629 [00:08<00:18, 94.29it/s]\u001b[A\n",
      "\n",
      "\n",
      " 33%|█████████████                          | 878/2629 [00:08<00:14, 119.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▋                        | 994/2629 [00:08<00:09, 174.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|█████████████                          | 877/2629 [00:08<00:13, 133.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▍                        | 972/2629 [00:08<00:11, 145.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|██████████████▏                         | 929/2629 [00:08<00:17, 94.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████                         | 991/2629 [00:08<00:17, 91.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▏                         | 891/2629 [00:08<00:14, 120.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|██████████████▋                       | 1012/2629 [00:08<00:09, 165.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 987/2629 [00:08<00:12, 136.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 945/2629 [00:08<00:15, 110.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▊                      | 1092/2629 [00:08<00:11, 137.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▊                        | 1002/2629 [00:08<00:17, 94.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 34%|█████████████▍                         | 907/2629 [00:08<00:14, 122.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|██████████████▊                       | 1029/2629 [00:08<00:10, 158.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|█████████████▍                         | 906/2629 [00:08<00:13, 130.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 36%|██████████████▏                        | 959/2629 [00:08<00:14, 114.86it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▊                       | 1022/2629 [00:08<00:13, 117.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▍                       | 1001/2629 [00:08<00:13, 123.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 921/2629 [00:08<00:13, 124.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████                       | 1045/2629 [00:08<00:10, 154.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|█████████████▋                         | 926/2629 [00:08<00:11, 148.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▍                     | 1134/2629 [00:08<00:08, 168.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▍                        | 972/2629 [00:08<00:14, 114.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 1019/2629 [00:08<00:11, 135.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|█████████████▊                         | 934/2629 [00:08<00:13, 125.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 40%|███████████████▍                      | 1064/2629 [00:08<00:09, 162.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|█████████████▉                         | 942/2629 [00:08<00:12, 139.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▏                      | 1054/2629 [00:08<00:12, 125.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|██████████████                         | 947/2629 [00:08<00:13, 123.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 1033/2629 [00:08<00:13, 121.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 41%|███████████████▌                      | 1081/2629 [00:08<00:09, 157.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▉                         | 984/2629 [00:08<00:19, 86.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 1068/2629 [00:08<00:13, 116.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████▏                        | 960/2629 [00:08<00:14, 115.86it/s]\u001b[A\u001b[A\u001b[A\n",
      " 44%|████████████████▉                     | 1168/2629 [00:09<00:11, 123.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|██████████████▍                        | 972/2629 [00:08<00:12, 134.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|███████████████▊                      | 1097/2629 [00:09<00:12, 126.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 1081/2629 [00:08<00:12, 119.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▌                       | 1046/2629 [00:09<00:16, 94.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 37%|██████████████▍                        | 972/2629 [00:09<00:15, 105.31it/s]\u001b[A\u001b[A\u001b[A\n",
      " 45%|█████████████████▏                    | 1191/2629 [00:09<00:09, 147.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▋                        | 994/2629 [00:08<00:10, 157.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 42%|████████████████▏                     | 1116/2629 [00:09<00:10, 141.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 1094/2629 [00:08<00:12, 118.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▋                       | 1057/2629 [00:09<00:16, 96.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|██████████████▉                        | 1003/2629 [00:09<00:22, 73.91it/s]\u001b[A\u001b[A\u001b[A\n",
      " 46%|█████████████████▍                    | 1208/2629 [00:09<00:09, 150.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▋                       | 1012/2629 [00:08<00:09, 162.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                       | 1068/2629 [00:09<00:15, 98.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 1107/2629 [00:09<00:13, 109.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▋                       | 1016/2629 [00:09<00:09, 162.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 43%|████████████████▎                     | 1132/2629 [00:09<00:12, 124.44it/s]\u001b[A\u001b[A\n",
      " 47%|█████████████████▊                    | 1231/2629 [00:09<00:08, 170.15it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|██████████████▉                        | 1011/2629 [00:09<00:22, 71.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 1080/2629 [00:09<00:15, 101.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 39%|██████████████▉                       | 1037/2629 [00:09<00:09, 174.54it/s]\u001b[A\u001b[A\u001b[A\n",
      " 48%|██████████████████                    | 1251/2629 [00:09<00:07, 176.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████                        | 1019/2629 [00:09<00:23, 69.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▌                      | 1119/2629 [00:09<00:15, 96.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▊                      | 1091/2629 [00:09<00:15, 102.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▌                     | 1146/2629 [00:09<00:13, 107.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 1056/2629 [00:09<00:09, 173.56it/s]\u001b[A\u001b[A\u001b[A\n",
      " 49%|██████████████████▌                   | 1281/2629 [00:09<00:06, 210.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|███████████████▏                       | 1027/2629 [00:09<00:22, 72.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▊                      | 1130/2629 [00:09<00:15, 98.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 1108/2629 [00:09<00:12, 119.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|████████████████▊                     | 1160/2629 [00:09<00:12, 114.18it/s]\u001b[A\u001b[A\n",
      " 50%|██████████████████▊                   | 1303/2629 [00:09<00:06, 210.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▍                       | 1044/2629 [00:09<00:16, 96.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|███████████████▌                      | 1074/2629 [00:09<00:10, 154.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 1145/2629 [00:09<00:13, 109.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|████████████████▉                     | 1174/2629 [00:09<00:12, 120.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|███████████████▎                      | 1058/2629 [00:09<00:14, 106.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|███████████████▊                      | 1095/2629 [00:09<00:09, 167.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 1157/2629 [00:09<00:13, 109.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▍                     | 1136/2629 [00:09<00:07, 190.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 50%|███████████████████▏                  | 1325/2629 [00:09<00:07, 167.58it/s]\u001b[A\n",
      "\n",
      " 45%|█████████████████▏                    | 1187/2629 [00:09<00:12, 116.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▍                      | 1070/2629 [00:09<00:14, 107.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|████████████████                      | 1113/2629 [00:09<00:09, 160.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 1171/2629 [00:09<00:12, 114.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▋                     | 1157/2629 [00:09<00:07, 190.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 46%|█████████████████▍                    | 1206/2629 [00:09<00:10, 132.75it/s]\u001b[A\u001b[A\n",
      " 51%|███████████████████▍                  | 1344/2629 [00:09<00:07, 165.78it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|███████████████▋                      | 1083/2629 [00:10<00:13, 111.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▎                     | 1130/2629 [00:09<00:09, 153.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 1183/2629 [00:09<00:13, 109.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 46%|█████████████████▋                    | 1221/2629 [00:10<00:10, 133.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████                     | 1177/2629 [00:09<00:08, 170.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|████████████████▊                     | 1161/2629 [00:10<00:12, 118.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|███████████████▊                      | 1096/2629 [00:10<00:13, 114.01it/s]\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▌                     | 1147/2629 [00:10<00:09, 152.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                    | 1195/2629 [00:09<00:13, 104.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|████████████████▉                     | 1173/2629 [00:10<00:12, 113.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▎                    | 1195/2629 [00:09<00:08, 163.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 42%|████████████████                      | 1108/2629 [00:10<00:13, 110.86it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▍                    | 1206/2629 [00:10<00:13, 104.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|█████████████████▋                    | 1227/2629 [00:10<00:07, 197.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|██████████████████                    | 1248/2629 [00:10<00:11, 119.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▏                    | 1187/2629 [00:10<00:12, 113.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 53%|████████████████████▏                 | 1396/2629 [00:10<00:08, 153.71it/s]\u001b[A\n",
      "\n",
      "\n",
      " 44%|████████████████▊                     | 1163/2629 [00:10<00:12, 115.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████                    | 1250/2629 [00:10<00:06, 205.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|████████████████▌                      | 1120/2629 [00:10<00:16, 89.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 54%|████████████████████▍                 | 1418/2629 [00:10<00:07, 169.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████                     | 1217/2629 [00:10<00:18, 77.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|████████████████▊                      | 1130/2629 [00:10<00:18, 81.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▌                    | 1215/2629 [00:10<00:13, 107.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▋                    | 1261/2629 [00:10<00:16, 81.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 1228/2629 [00:10<00:16, 84.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|████████████████▉                      | 1139/2629 [00:10<00:18, 82.46it/s]\u001b[A\u001b[A\u001b[A\n",
      " 55%|█████████████████████                 | 1453/2629 [00:10<00:08, 146.59it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▍                    | 1240/2629 [00:10<00:15, 92.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████                      | 1148/2629 [00:10<00:17, 83.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|█████████████████████▎                | 1471/2629 [00:10<00:07, 154.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 1256/2629 [00:10<00:12, 109.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▊                    | 1271/2629 [00:10<00:19, 69.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▌                     | 1187/2629 [00:10<00:18, 76.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|█████████████████▏                     | 1158/2629 [00:10<00:17, 86.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▍                   | 1272/2629 [00:10<00:11, 116.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▉                   | 1307/2629 [00:10<00:09, 132.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▏                   | 1259/2629 [00:10<00:11, 115.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|█████████████████▎                     | 1167/2629 [00:11<00:16, 87.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▌                   | 1285/2629 [00:10<00:11, 120.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 1197/2629 [00:10<00:21, 68.12it/s]\u001b[A\u001b[A\u001b[A\n",
      " 57%|█████████████████████▍                | 1487/2629 [00:11<00:10, 110.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 1322/2629 [00:10<00:10, 125.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|█████████████████▍                     | 1178/2629 [00:11<00:15, 91.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|███████████████████▏                   | 1293/2629 [00:11<00:17, 75.26it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|██████████████████▊                   | 1304/2629 [00:10<00:09, 136.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▉                     | 1205/2629 [00:11<00:21, 65.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|██████████████████▊                   | 1301/2629 [00:11<00:08, 157.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 1343/2629 [00:10<00:08, 143.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▋                | 1501/2629 [00:11<00:10, 103.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▏                  | 1326/2629 [00:11<00:08, 157.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████                   | 1318/2629 [00:11<00:08, 160.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▋                  | 1363/2629 [00:10<00:08, 156.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 50%|███████████████████▌                   | 1317/2629 [00:11<00:14, 91.44it/s]\u001b[A\u001b[A\n",
      " 58%|█████████████████████▊                | 1513/2629 [00:11<00:11, 100.66it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▍                  | 1344/2629 [00:11<00:07, 162.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|█████████████████▊                     | 1198/2629 [00:11<00:17, 84.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▎                  | 1336/2629 [00:11<00:07, 166.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▋                   | 1329/2629 [00:11<00:13, 97.35it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 1526/2629 [00:11<00:10, 106.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|██████████████████                     | 1220/2629 [00:11<00:23, 59.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|█████████████████▉                     | 1207/2629 [00:11<00:19, 73.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▌                  | 1354/2629 [00:11<00:08, 149.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|███████████████████▉                   | 1340/2629 [00:11<00:13, 92.74it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 1396/2629 [00:11<00:09, 128.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 59%|██████████████████████▊                | 1538/2629 [00:11<00:11, 93.70it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|██████████████████                     | 1215/2629 [00:11<00:19, 73.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 1227/2629 [00:11<00:25, 55.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 1373/2629 [00:11<00:07, 159.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|███████████████████▌                  | 1356/2629 [00:11<00:11, 109.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▋                 | 1434/2629 [00:11<00:06, 183.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▏                    | 1223/2629 [00:11<00:18, 74.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 53%|████████████████████▏                 | 1397/2629 [00:11<00:06, 181.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▎                    | 1233/2629 [00:11<00:25, 54.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 52%|███████████████████▊                  | 1372/2629 [00:11<00:10, 122.46it/s]\u001b[A\u001b[A\n",
      " 59%|██████████████████████▉                | 1549/2629 [00:11<00:12, 87.22it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 1459/2629 [00:11<00:05, 199.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▎                    | 1234/2629 [00:11<00:16, 83.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 1420/2629 [00:11<00:06, 193.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|██████████████████▍                    | 1242/2629 [00:11<00:22, 61.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 53%|████████████████████                  | 1390/2629 [00:11<00:09, 136.79it/s]\u001b[A\u001b[A\n",
      " 59%|███████████████████████▏               | 1559/2629 [00:11<00:11, 89.68it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 1491/2629 [00:11<00:04, 228.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|██████████████████▍                    | 1245/2629 [00:11<00:15, 89.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|████████████████████▉                 | 1448/2629 [00:11<00:05, 216.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▌                    | 1253/2629 [00:11<00:18, 72.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|████████████████████▎                 | 1408/2629 [00:11<00:08, 147.00it/s]\u001b[A\u001b[A\n",
      " 60%|███████████████████████▎               | 1569/2629 [00:12<00:11, 91.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▍                | 1481/2629 [00:11<00:04, 230.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|██████████████████▋                    | 1256/2629 [00:12<00:14, 93.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|██████████████████▊                    | 1267/2629 [00:12<00:15, 87.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|████████████████████▋                 | 1427/2629 [00:12<00:07, 158.73it/s]\u001b[A\u001b[A\n",
      " 60%|███████████████████████▍               | 1579/2629 [00:12<00:12, 87.36it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|█████████████████████▎                | 1471/2629 [00:12<00:06, 183.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 1505/2629 [00:11<00:05, 204.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 1540/2629 [00:11<00:05, 202.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|██████████████████▊                    | 1266/2629 [00:12<00:16, 83.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|██████████████████▉                    | 1277/2629 [00:12<00:16, 82.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|█████████████████████▌                | 1493/2629 [00:12<00:05, 192.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|███████████████████████▌               | 1588/2629 [00:12<00:13, 79.84it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▌               | 1563/2629 [00:11<00:05, 207.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▏                | 1464/2629 [00:12<00:07, 163.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████                    | 1289/2629 [00:12<00:14, 89.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 1527/2629 [00:12<00:05, 188.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 58%|█████████████████████▉                | 1516/2629 [00:12<00:05, 197.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▋               | 1597/2629 [00:12<00:12, 81.39it/s]\u001b[A\n",
      "\n",
      " 49%|███████████████████                    | 1285/2629 [00:12<00:16, 83.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 1585/2629 [00:12<00:05, 186.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|███████████████████▎                   | 1299/2629 [00:12<00:15, 85.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      " 61%|███████████████████████▉               | 1611/2629 [00:12<00:10, 93.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▎               | 1547/2629 [00:12<00:06, 159.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|███████████████████▏                   | 1295/2629 [00:12<00:15, 86.80it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 1605/2629 [00:12<00:05, 186.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████▍                   | 1308/2629 [00:12<00:16, 82.20it/s]\u001b[A\u001b[A\u001b[A\n",
      " 62%|███████████████████████▍              | 1624/2629 [00:12<00:10, 100.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▍                   | 1307/2629 [00:12<00:13, 94.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▌               | 1565/2629 [00:12<00:07, 151.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 1625/2629 [00:12<00:05, 178.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████▌                   | 1319/2629 [00:12<00:14, 88.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|██████████████████████▏               | 1532/2629 [00:12<00:07, 156.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 1581/2629 [00:12<00:06, 152.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████████████████████▊               | 1575/2629 [00:12<00:06, 152.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 62%|████████████████████████▎              | 1635/2629 [00:12<00:12, 82.19it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|███████████████████▌                   | 1317/2629 [00:12<00:15, 82.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|███████████████████▋                   | 1329/2629 [00:12<00:14, 87.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|██████████████████████▍               | 1550/2629 [00:12<00:07, 151.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 1597/2629 [00:12<00:06, 151.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████               | 1599/2629 [00:12<00:05, 173.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▏             | 1673/2629 [00:12<00:04, 205.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|███████████████████▋                   | 1327/2629 [00:12<00:15, 85.16it/s]\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▍              | 1644/2629 [00:12<00:12, 78.12it/s]\u001b[A\n",
      "\n",
      " 60%|██████████████████████▋               | 1571/2629 [00:12<00:06, 164.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 1614/2629 [00:12<00:06, 154.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|███████████████████▊                   | 1339/2629 [00:13<00:13, 93.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▌                  | 1354/2629 [00:12<00:12, 102.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▍              | 1618/2629 [00:12<00:06, 152.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|███████████████████████               | 1593/2629 [00:13<00:05, 178.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▌              | 1634/2629 [00:12<00:06, 163.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▌              | 1653/2629 [00:13<00:13, 70.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 1725/2629 [00:12<00:03, 226.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▊                  | 1367/2629 [00:13<00:11, 106.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 1635/2629 [00:13<00:06, 147.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 1655/2629 [00:12<00:05, 169.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|████████████████████████▋              | 1663/2629 [00:13<00:12, 75.64it/s]\u001b[A\n",
      "\n",
      " 61%|███████████████████████▎              | 1612/2629 [00:13<00:06, 159.76it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▎            | 1748/2629 [00:12<00:04, 212.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|███████████████████▉                  | 1379/2629 [00:13<00:11, 107.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▏                  | 1359/2629 [00:13<00:15, 82.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▉              | 1680/2629 [00:13<00:09, 98.03it/s]\u001b[A\n",
      "\n",
      " 62%|███████████████████████▌              | 1629/2629 [00:13<00:06, 159.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▌            | 1770/2629 [00:13<00:04, 204.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 1390/2629 [00:13<00:11, 107.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▎             | 1678/2629 [00:13<00:05, 177.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|████████████████████▎                  | 1373/2629 [00:13<00:13, 93.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 64%|████████████████████████▍             | 1692/2629 [00:13<00:09, 101.18it/s]\u001b[A\n",
      "\n",
      " 63%|███████████████████████▊              | 1650/2629 [00:13<00:05, 172.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 1793/2629 [00:13<00:04, 204.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 1703/2629 [00:13<00:04, 195.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 1690/2629 [00:13<00:06, 144.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|████████████████████                  | 1392/2629 [00:13<00:10, 117.97it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 1703/2629 [00:13<00:09, 101.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 1814/2629 [00:13<00:04, 202.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████▉             | 1724/2629 [00:13<00:04, 198.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▎                 | 1408/2629 [00:13<00:09, 127.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|████████████████████▍                 | 1414/2629 [00:13<00:12, 101.21it/s]\u001b[A\u001b[A\u001b[A\n",
      " 65%|████████████████████████▊             | 1717/2629 [00:13<00:08, 111.91it/s]\u001b[A\n",
      "\n",
      " 64%|████████████████████████▍             | 1695/2629 [00:13<00:04, 195.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|████████████████████▌                 | 1422/2629 [00:13<00:09, 126.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▌           | 1835/2629 [00:13<00:04, 173.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████             | 1730/2629 [00:13<00:07, 114.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 1745/2629 [00:13<00:05, 160.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|████████████████████▋                 | 1435/2629 [00:13<00:10, 115.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 1739/2629 [00:13<00:06, 127.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|█████████████████████████▊             | 1742/2629 [00:13<00:09, 97.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████▊           | 1854/2629 [00:13<00:05, 149.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▍            | 1763/2629 [00:13<00:05, 145.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████▎                 | 1435/2629 [00:13<00:14, 80.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 66%|█████████████████████████             | 1734/2629 [00:13<00:06, 138.78it/s]\u001b[A\u001b[A\n",
      " 55%|████████████████████▉                 | 1447/2629 [00:14<00:11, 102.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 55%|█████████████████████                 | 1457/2629 [00:13<00:10, 113.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▋            | 1779/2629 [00:13<00:05, 146.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▎            | 1753/2629 [00:13<00:08, 108.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 67%|█████████████████████████▌            | 1765/2629 [00:14<00:08, 101.45it/s]\u001b[A\n",
      "\n",
      " 67%|█████████████████████████▎            | 1750/2629 [00:14<00:06, 130.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▍                | 1487/2629 [00:14<00:07, 160.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|█████████████████████▋                 | 1458/2629 [00:14<00:14, 82.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|██████████████████████████▏            | 1765/2629 [00:14<00:08, 96.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|█████████████████████████▌            | 1769/2629 [00:14<00:06, 139.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 1795/2629 [00:14<00:07, 111.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|█████████████████████▊                | 1505/2629 [00:14<00:07, 146.52it/s]\u001b[A\u001b[A\u001b[A\n",
      " 68%|██████████████████████████▎            | 1776/2629 [00:14<00:10, 82.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|██████████████████████████▎            | 1776/2629 [00:14<00:08, 98.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 1912/2629 [00:14<00:05, 135.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████████████████████▊                 | 1468/2629 [00:14<00:14, 79.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|██████████████████████                | 1525/2629 [00:14<00:07, 157.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 1793/2629 [00:14<00:07, 114.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 1808/2629 [00:14<00:08, 102.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|█████████████████████▌                | 1490/2629 [00:14<00:10, 109.25it/s]\u001b[A\n",
      "\n",
      "\n",
      " 59%|██████████████████████▍               | 1551/2629 [00:14<00:06, 177.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▏           | 1808/2629 [00:14<00:06, 122.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▎         | 1955/2629 [00:14<00:04, 164.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 1820/2629 [00:14<00:07, 102.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|██████████████████████████▋            | 1795/2629 [00:14<00:10, 80.74it/s]\u001b[A\n",
      "\n",
      " 57%|██████████████████████▎                | 1503/2629 [00:14<00:11, 99.17it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 1823/2629 [00:14<00:06, 127.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 1973/2629 [00:14<00:03, 164.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▍           | 1833/2629 [00:14<00:07, 107.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 69%|██████████████████████████▊            | 1811/2629 [00:14<00:08, 95.45it/s]\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▏           | 1811/2629 [00:14<00:07, 105.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▋               | 1570/2629 [00:14<00:07, 135.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▍           | 1825/2629 [00:14<00:07, 106.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 1845/2629 [00:14<00:07, 101.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▍                | 1514/2629 [00:14<00:13, 79.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|███████████████████████████            | 1823/2629 [00:14<00:08, 97.09it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 1850/2629 [00:14<00:06, 114.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 1856/2629 [00:14<00:08, 95.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 70%|███████████████████████████▎           | 1837/2629 [00:14<00:08, 92.97it/s]\u001b[A\n",
      "\n",
      "\n",
      " 60%|██████████████████████▉               | 1586/2629 [00:14<00:09, 111.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████         | 2007/2629 [00:14<00:04, 128.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▏           | 1834/2629 [00:14<00:08, 88.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|██████████████████████▌                | 1524/2629 [00:15<00:15, 71.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 1874/2629 [00:14<00:06, 115.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▏              | 1600/2629 [00:14<00:08, 116.78it/s]\u001b[A\u001b[A\u001b[A\n",
      " 70%|██████████████████████████▊           | 1853/2629 [00:15<00:07, 108.06it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 2021/2629 [00:14<00:04, 129.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|███████████████████████████▍          | 1901/2629 [00:15<00:04, 152.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▎           | 1844/2629 [00:15<00:09, 84.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|███████████████████████▎              | 1615/2629 [00:15<00:08, 123.34it/s]\u001b[A\u001b[A\u001b[A\n",
      " 58%|██████████████████████▋                | 1533/2629 [00:15<00:16, 67.98it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▊           | 1874/2629 [00:14<00:07, 96.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 2035/2629 [00:14<00:04, 128.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████████████████████████▍           | 1853/2629 [00:15<00:09, 85.28it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|███████████████████████▋              | 1639/2629 [00:15<00:06, 150.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▋          | 1918/2629 [00:15<00:04, 148.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 72%|███████████████████████████▏          | 1881/2629 [00:15<00:06, 116.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▊                | 1541/2629 [00:15<00:16, 67.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▌        | 2049/2629 [00:15<00:05, 111.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 72%|███████████████████████████▍          | 1895/2629 [00:15<00:06, 120.99it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████▉          | 1937/2629 [00:15<00:04, 153.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████▉              | 1656/2629 [00:15<00:06, 144.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|██████████████████████▉                | 1550/2629 [00:15<00:15, 71.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▎         | 1955/2629 [00:15<00:04, 158.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▌          | 1908/2629 [00:15<00:06, 119.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████████████████████████▊           | 1872/2629 [00:15<00:09, 83.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|███████████████████████▏               | 1560/2629 [00:15<00:13, 77.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 1909/2629 [00:15<00:08, 89.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 1972/2629 [00:15<00:04, 161.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▌             | 1698/2629 [00:15<00:05, 173.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████████████████████████▉           | 1883/2629 [00:15<00:08, 89.56it/s]\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▉          | 1929/2629 [00:15<00:04, 141.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|███████████████████████▎               | 1569/2629 [00:15<00:13, 76.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▍          | 1919/2629 [00:15<00:07, 91.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|████████████████████████▉             | 1721/2629 [00:15<00:04, 185.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 1989/2629 [00:15<00:04, 156.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 74%|████████████████████████████          | 1944/2629 [00:15<00:04, 140.91it/s]\u001b[A\n",
      "\n",
      " 60%|███████████████████████▍               | 1579/2629 [00:15<00:12, 81.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▉        | 2083/2629 [00:15<00:06, 88.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▌          | 1929/2629 [00:15<00:07, 89.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 1744/2629 [00:15<00:04, 196.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████         | 2013/2629 [00:15<00:03, 178.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▎         | 1960/2629 [00:15<00:04, 143.80it/s]\u001b[A\n",
      "\n",
      " 60%|███████████████████████▌               | 1588/2629 [00:15<00:12, 82.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▏         | 1946/2629 [00:15<00:06, 108.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████        | 2093/2629 [00:15<00:06, 88.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▎        | 2032/2629 [00:15<00:03, 181.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████▌         | 1976/2629 [00:15<00:04, 147.27it/s]\u001b[A\n",
      "\n",
      " 61%|███████████████████████▋               | 1600/2629 [00:15<00:11, 90.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▉            | 1791/2629 [00:15<00:03, 210.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▍       | 2108/2629 [00:15<00:05, 100.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▎         | 1958/2629 [00:15<00:06, 107.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 76%|████████████████████████████▊         | 1997/2629 [00:16<00:03, 164.94it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|███████████████████████▉               | 1610/2629 [00:16<00:12, 84.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|██████████████████████████▎           | 1819/2629 [00:16<00:03, 229.75it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 2075/2629 [00:16<00:02, 192.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▏        | 2015/2629 [00:16<00:03, 163.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 2119/2629 [00:15<00:05, 93.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▊          | 1939/2629 [00:16<00:07, 94.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▏         | 1970/2629 [00:15<00:07, 88.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████▋           | 1847/2629 [00:16<00:03, 242.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████               | 1619/2629 [00:16<00:13, 77.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▎        | 2032/2629 [00:16<00:03, 158.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2129/2629 [00:15<00:05, 91.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|█████████████████████████████▎         | 1980/2629 [00:16<00:07, 90.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▋       | 2119/2629 [00:16<00:02, 197.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████▋        | 2052/2629 [00:16<00:03, 165.80it/s]\u001b[A\n",
      "\n",
      " 62%|████████████████████████▏              | 1627/2629 [00:16<00:13, 75.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|███████████████████████████           | 1872/2629 [00:16<00:03, 216.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 2139/2629 [00:16<00:05, 92.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▉       | 2139/2629 [00:16<00:02, 194.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|████████████████████████▎              | 1642/2629 [00:16<00:10, 92.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▌         | 1990/2629 [00:16<00:07, 80.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 2150/2629 [00:16<00:04, 96.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████          | 1959/2629 [00:16<00:09, 71.02it/s]\u001b[A\u001b[A\n",
      " 79%|█████████████████████████████▉        | 2069/2629 [00:16<00:04, 130.86it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 2159/2629 [00:16<00:02, 179.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████▌              | 1652/2629 [00:16<00:10, 90.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▋         | 1999/2629 [00:16<00:08, 73.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|███████████████████████████▊          | 1921/2629 [00:16<00:03, 193.69it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████▏         | 1967/2629 [00:16<00:09, 69.33it/s]\u001b[A\u001b[A\n",
      " 79%|██████████████████████████████        | 2084/2629 [00:16<00:04, 130.53it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|████████████████████████▋              | 1662/2629 [00:16<00:10, 91.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 2184/2629 [00:16<00:02, 169.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████▎         | 1975/2629 [00:16<00:09, 71.62it/s]\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████▎       | 2101/2629 [00:16<00:03, 140.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▊         | 2007/2629 [00:16<00:09, 66.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▊              | 1672/2629 [00:16<00:10, 87.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|█████████████████████████████▍         | 1985/2629 [00:16<00:08, 76.00it/s]\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▌       | 2117/2629 [00:16<00:03, 143.18it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 2202/2629 [00:16<00:02, 158.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▉         | 2018/2629 [00:16<00:08, 75.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|████████████████████████████          | 1942/2629 [00:16<00:05, 135.12it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|████████████████████████▍             | 1692/2629 [00:16<00:08, 116.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|█████████████████████████████▌         | 1996/2629 [00:16<00:07, 82.92it/s]\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████▊       | 2133/2629 [00:16<00:03, 143.91it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████▏        | 2033/2629 [00:16<00:06, 93.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 2219/2629 [00:16<00:02, 151.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▋             | 1705/2629 [00:17<00:07, 116.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▎         | 1959/2629 [00:16<00:05, 128.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████       | 2148/2629 [00:17<00:03, 140.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|█████████████████████████████▊         | 2007/2629 [00:17<00:07, 84.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 2239/2629 [00:17<00:02, 160.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████▊             | 1717/2629 [00:17<00:07, 114.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|████████████████████████████▌         | 1974/2629 [00:17<00:05, 130.19it/s]\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████▎      | 2164/2629 [00:17<00:03, 143.03it/s]\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████▉         | 2018/2629 [00:17<00:06, 89.69it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▍        | 2055/2629 [00:16<00:06, 93.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████             | 1732/2629 [00:17<00:07, 123.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████      | 2229/2629 [00:16<00:04, 98.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████▋         | 1989/2629 [00:17<00:04, 129.95it/s]\u001b[A\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████▍      | 2179/2629 [00:17<00:03, 135.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████     | 2289/2629 [00:17<00:01, 187.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|██████████████████████████████         | 2028/2629 [00:17<00:07, 85.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▋        | 2065/2629 [00:17<00:06, 90.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|█████████████████████████▏            | 1745/2629 [00:17<00:07, 117.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████▊      | 2204/2629 [00:17<00:02, 166.25it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 2078/2629 [00:17<00:05, 100.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▌     | 2254/2629 [00:17<00:03, 111.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 2309/2629 [00:17<00:01, 176.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 67%|█████████████████████████▍            | 1757/2629 [00:17<00:07, 116.96it/s]\u001b[A\u001b[A\n",
      " 85%|████████████████████████████████▏     | 2228/2629 [00:17<00:02, 185.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████▏       | 2089/2629 [00:17<00:05, 101.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████▊     | 2268/2629 [00:17<00:03, 116.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|██████████████████████████████▍        | 2048/2629 [00:17<00:06, 87.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|█████████████████████████▋            | 1774/2629 [00:17<00:06, 128.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▏        | 2018/2629 [00:17<00:05, 113.17it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▍     | 2248/2629 [00:17<00:02, 184.02it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▎       | 2101/2629 [00:17<00:05, 104.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|█████████████████████████████▊        | 2064/2629 [00:17<00:05, 105.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████▊            | 1788/2629 [00:17<00:06, 121.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 2280/2629 [00:17<00:03, 101.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|██████████████████████████████         | 2030/2629 [00:17<00:05, 99.87it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|████████████████████████████████▊     | 2267/2629 [00:17<00:02, 179.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 2113/2629 [00:17<00:04, 108.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▏       | 2089/2629 [00:17<00:03, 142.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▏   | 2366/2629 [00:17<00:01, 175.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 2292/2629 [00:17<00:03, 104.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|██████████████████████████████▎        | 2041/2629 [00:17<00:05, 99.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████████████████████████▋            | 1801/2629 [00:17<00:08, 99.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▍   | 2384/2629 [00:17<00:01, 170.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|█████████████████████████████████     | 2286/2629 [00:17<00:02, 151.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2124/2629 [00:17<00:05, 89.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 2303/2629 [00:17<00:03, 101.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████▋        | 2053/2629 [00:17<00:05, 104.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▋       | 2119/2629 [00:17<00:03, 144.72it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████▋   | 2402/2629 [00:17<00:01, 166.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▍    | 2315/2629 [00:17<00:02, 105.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████▉        | 2067/2629 [00:17<00:05, 111.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▋       | 2134/2629 [00:17<00:06, 80.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████▊       | 2134/2629 [00:18<00:03, 143.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 2419/2629 [00:18<00:01, 167.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▎    | 2303/2629 [00:18<00:02, 122.53it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|███████████████████████████            | 1822/2629 [00:18<00:08, 90.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████        | 2079/2629 [00:18<00:05, 107.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████       | 2149/2629 [00:18<00:03, 142.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▊       | 2143/2629 [00:17<00:06, 77.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 2438/2629 [00:18<00:01, 172.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 88%|█████████████████████████████████▍    | 2317/2629 [00:18<00:02, 121.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▏           | 1832/2629 [00:18<00:08, 88.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▏       | 2091/2629 [00:18<00:04, 110.22it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|███████████████████████████████▎      | 2168/2629 [00:18<00:02, 154.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 2152/2629 [00:18<00:06, 77.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▍  | 2456/2629 [00:18<00:01, 158.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 89%|█████████████████████████████████▋    | 2333/2629 [00:18<00:02, 130.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▎           | 1842/2629 [00:18<00:09, 85.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████       | 2163/2629 [00:18<00:05, 85.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▏       | 2103/2629 [00:18<00:05, 98.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|███████████████████████████████▌      | 2184/2629 [00:18<00:03, 125.10it/s]\u001b[A\u001b[A\n",
      " 89%|█████████████████████████████████▉    | 2347/2629 [00:18<00:02, 119.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|███████████████████████████▍           | 1851/2629 [00:18<00:09, 83.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▌      | 2181/2629 [00:18<00:04, 110.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████▌       | 2115/2629 [00:18<00:05, 102.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|███████████████████████████████▊      | 2203/2629 [00:18<00:03, 139.77it/s]\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▏   | 2361/2629 [00:18<00:02, 123.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 2473/2629 [00:18<00:01, 113.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▌           | 1861/2629 [00:18<00:08, 86.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████▊       | 2131/2629 [00:18<00:04, 116.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▌      | 2193/2629 [00:18<00:04, 97.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████████████████████████████      | 2221/2629 [00:18<00:02, 147.69it/s]\u001b[A\u001b[A\n",
      " 90%|██████████████████████████████████▎   | 2374/2629 [00:18<00:02, 122.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▋           | 1870/2629 [00:18<00:08, 85.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 2487/2629 [00:18<00:01, 110.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████▉       | 2144/2629 [00:18<00:04, 107.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████████████████████████████▍     | 2241/2629 [00:18<00:02, 160.49it/s]\u001b[A\u001b[A\n",
      " 91%|██████████████████████████████████▌   | 2388/2629 [00:18<00:01, 126.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████▉   | 2416/2629 [00:18<00:01, 135.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 2504/2629 [00:18<00:01, 120.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|███████████████████████████▊           | 1879/2629 [00:18<00:10, 73.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████████████████████████████▋     | 2260/2629 [00:18<00:02, 166.15it/s]\u001b[A\u001b[A\n",
      " 92%|██████████████████████████████████▊   | 2411/2629 [00:18<00:01, 154.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▏  | 2432/2629 [00:18<00:01, 141.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▏      | 2156/2629 [00:18<00:04, 101.51it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▊      | 2214/2629 [00:18<00:05, 82.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████▏      | 2167/2629 [00:18<00:04, 99.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████████████████████████▉           | 1887/2629 [00:19<00:11, 65.97it/s]\u001b[A\u001b[A\n",
      " 92%|███████████████████████████████████   | 2427/2629 [00:19<00:01, 135.05it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 2518/2629 [00:18<00:01, 98.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▎     | 2233/2629 [00:18<00:03, 107.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████▎  | 2447/2629 [00:18<00:01, 118.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████▍      | 2178/2629 [00:19<00:04, 100.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 2294/2629 [00:19<00:02, 144.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▍     | 2245/2629 [00:18<00:03, 110.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████           | 1894/2629 [00:19<00:13, 55.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▍  | 2460/2629 [00:18<00:01, 99.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▍      | 2189/2629 [00:19<00:05, 87.50it/s]\u001b[A\u001b[A\u001b[A\n",
      " 93%|████████████████████████████████████▏  | 2442/2629 [00:19<00:01, 97.34it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 72%|████████████████████████████▏          | 1903/2629 [00:19<00:11, 62.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 2257/2629 [00:19<00:03, 98.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▎    | 2309/2629 [00:19<00:02, 119.52it/s]\u001b[A\u001b[A\n",
      " 94%|███████████████████████████████████▌  | 2460/2629 [00:19<00:01, 112.49it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 2471/2629 [00:19<00:01, 89.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▎          | 1912/2629 [00:19<00:10, 68.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████▉     | 2277/2629 [00:19<00:02, 119.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 2325/2629 [00:19<00:02, 125.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████▉ | 2557/2629 [00:19<00:00, 98.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|████████████████████████████▌          | 1922/2629 [00:19<00:09, 75.82it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 2339/2629 [00:19<00:02, 128.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▏| 2569/2629 [00:19<00:00, 101.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▏    | 2293/2629 [00:19<00:02, 122.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|████████████████████████████▋          | 1931/2629 [00:19<00:08, 78.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|███████████████████████████████████▉  | 2488/2629 [00:19<00:01, 114.54it/s]\n",
      "\n",
      " 90%|██████████████████████████████████    | 2358/2629 [00:19<00:01, 140.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▎| 2580/2629 [00:19<00:00, 101.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████▉      | 2217/2629 [00:19<00:05, 79.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████▉  | 2490/2629 [00:19<00:01, 82.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|████████████████████████████▊          | 1940/2629 [00:19<00:08, 81.06it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 90%|██████████████████████████████████▎   | 2373/2629 [00:19<00:01, 139.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████▌    | 2324/2629 [00:19<00:02, 124.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▍| 2591/2629 [00:19<00:00, 90.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████      | 2226/2629 [00:19<00:05, 70.75it/s]\u001b[A\u001b[A\u001b[A\n",
      " 95%|█████████████████████████████████████  | 2501/2629 [00:19<00:01, 98.62it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████  | 2499/2629 [00:19<00:01, 74.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|████████████████████████████▉          | 1949/2629 [00:19<00:09, 69.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 2602/2629 [00:19<00:00, 94.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|█████████████████████████████████▊    | 2337/2629 [00:19<00:02, 116.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|█████████████████████████████████████▎ | 2512/2629 [00:19<00:01, 99.37it/s]\u001b[A\n",
      "\n",
      "\n",
      " 85%|█████████████████████████████████▏     | 2234/2629 [00:19<00:05, 71.34it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 2507/2629 [00:19<00:01, 67.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████▊   | 2406/2629 [00:20<00:01, 131.57it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 2612/2629 [00:20<00:00, 77.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|█████████████████████████████          | 1957/2629 [00:20<00:12, 52.43it/s]\u001b[A\u001b[A\u001b[A\n",
      " 96%|█████████████████████████████████████▍ | 2523/2629 [00:20<00:01, 77.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 2349/2629 [00:20<00:03, 82.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 2515/2629 [00:19<00:02, 52.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████▉| 2621/2629 [00:20<00:00, 75.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▍     | 2252/2629 [00:20<00:05, 65.55it/s]\u001b[A\u001b[A\u001b[A\n",
      " 96%|█████████████████████████████████████▌ | 2532/2629 [00:20<00:01, 76.86it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:20<00:00, 129.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▍ | 2523/2629 [00:20<00:01, 57.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▉    | 2359/2629 [00:20<00:03, 76.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▌     | 2262/2629 [00:20<00:05, 72.20it/s]\u001b[A\u001b[A\u001b[A\n",
      " 97%|█████████████████████████████████████▊ | 2545/2629 [00:20<00:00, 88.37it/s]\u001b[A\n",
      "\n",
      " 75%|█████████████████████████████▎         | 1977/2629 [00:20<00:10, 63.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▌ | 2535/2629 [00:20<00:01, 71.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▏   | 2368/2629 [00:20<00:03, 78.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|█████████████████████████████████▋     | 2270/2629 [00:20<00:04, 73.32it/s]\u001b[A\u001b[A\u001b[A\n",
      " 97%|█████████████████████████████████████ | 2563/2629 [00:20<00:00, 105.68it/s]\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████████▎  | 2444/2629 [00:20<00:01, 96.71it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▍         | 1985/2629 [00:20<00:10, 62.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▎   | 2380/2629 [00:20<00:03, 82.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▊     | 2281/2629 [00:20<00:04, 75.47it/s]\u001b[A\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████▏| 2575/2629 [00:20<00:00, 103.86it/s]\u001b[A\n",
      "\n",
      " 93%|████████████████████████████████████▍  | 2455/2629 [00:20<00:01, 95.83it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▌         | 1992/2629 [00:20<00:10, 61.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▍   | 2392/2629 [00:20<00:02, 89.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|█████████████████████████████████████▍| 2587/2629 [00:20<00:00, 105.46it/s]\u001b[A\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████▉     | 2289/2629 [00:20<00:04, 73.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 2471/2629 [00:20<00:01, 110.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 76%|█████████████████████████████▋         | 2004/2629 [00:20<00:08, 74.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|███████████████████████████████████▋   | 2402/2629 [00:20<00:02, 89.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|███████████████████████████████████▉  | 2487/2629 [00:20<00:01, 122.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████▍| 2592/2629 [00:20<00:00, 124.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|█████████████████████████████▉         | 2021/2629 [00:20<00:06, 93.53it/s]\u001b[A\n",
      "\n",
      "\n",
      " 87%|██████████████████████████████████     | 2297/2629 [00:20<00:05, 61.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▊   | 2412/2629 [00:20<00:02, 87.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 95%|████████████████████████████████████▏ | 2500/2629 [00:20<00:01, 118.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████▍        | 2035/2629 [00:21<00:05, 103.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 99%|██████████████████████████████████████▋| 2608/2629 [00:21<00:00, 89.90it/s]\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▏    | 2304/2629 [00:20<00:05, 62.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|███████████████████████████████████▉   | 2421/2629 [00:20<00:02, 83.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 96%|████████████████████████████████████▍ | 2519/2629 [00:21<00:00, 133.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████▊| 2620/2629 [00:20<00:00, 118.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████▊| 2618/2629 [00:21<00:00, 85.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████   | 2430/2629 [00:21<00:02, 75.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:20<00:00, 125.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▋ | 2535/2629 [00:21<00:00, 123.74it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:21<00:00, 123.49it/s]\u001b[A\n",
      " 78%|██████████████████████████████▎        | 2046/2629 [00:21<00:07, 73.67it/s]\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▎    | 2317/2629 [00:21<00:05, 53.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▏  | 2438/2629 [00:21<00:02, 70.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 88%|██████████████████████████████████▍    | 2323/2629 [00:21<00:05, 54.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████████████████████████████████ | 2566/2629 [00:21<00:00, 130.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▎  | 2446/2629 [00:21<00:02, 62.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▌    | 2329/2629 [00:21<00:05, 53.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 78%|██████████████████████████████▌        | 2063/2629 [00:21<00:09, 61.85it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████▍  | 2454/2629 [00:21<00:02, 65.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▋    | 2335/2629 [00:21<00:05, 54.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▊        | 2074/2629 [00:21<00:07, 69.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▌  | 2461/2629 [00:21<00:02, 63.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████▊    | 2344/2629 [00:21<00:04, 62.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|██████████████████████████████▉        | 2082/2629 [00:21<00:07, 72.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████▋  | 2471/2629 [00:21<00:02, 72.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████▉    | 2355/2629 [00:21<00:03, 73.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:21<00:00, 119.93it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|███████████████████████████████        | 2090/2629 [00:22<00:07, 68.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████    | 2366/2629 [00:21<00:03, 81.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████        | 2098/2629 [00:22<00:07, 68.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 90%|███████████████████████████████████▎   | 2379/2629 [00:22<00:02, 94.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|█████████████████████████████████████▏ | 2503/2629 [00:21<00:01, 89.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|███████████████████████████████▏       | 2106/2629 [00:22<00:08, 60.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████▎ | 2515/2629 [00:22<00:01, 95.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▍       | 2117/2629 [00:22<00:07, 70.66it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▌ | 2531/2629 [00:22<00:00, 112.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████▌       | 2129/2629 [00:22<00:06, 81.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▊ | 2544/2629 [00:22<00:00, 112.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▊       | 2144/2629 [00:22<00:05, 96.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 97%|████████████████████████████████████▉ | 2558/2629 [00:22<00:00, 118.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████▋  | 2470/2629 [00:22<00:00, 161.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████▉       | 2155/2629 [00:22<00:05, 89.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████▏      | 2167/2629 [00:22<00:04, 93.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████▍| 2586/2629 [00:22<00:00, 113.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████▎ | 2513/2629 [00:22<00:00, 180.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▎      | 2177/2629 [00:23<00:05, 86.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▌| 2598/2629 [00:22<00:00, 99.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|████████████████████████████████▌      | 2191/2629 [00:23<00:04, 98.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|██████████████████████████████████████▋| 2609/2629 [00:22<00:00, 98.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████      | 2216/2629 [00:23<00:03, 137.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:23<00:00, 113.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████▏     | 2231/2629 [00:23<00:02, 134.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:23<00:00, 112.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 2629/2629 [00:24<00:00, 105.33it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_abolish.tsv\n",
      "Processing Started...\n",
      "Data Size:  281\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 30%|████████████▌                             | 12/40 [00:00<00:00, 119.67it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 28%|███████████▊                               | 11/40 [00:00<00:00, 76.41it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▌                              | 11/40 [00:00<00:00, 100.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|███████████▌                              | 11/40 [00:00<00:00, 104.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▊                                | 10/40 [00:00<00:00, 95.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▌          | 30/40 [00:00<00:00, 147.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|██████████████▋                           | 14/40 [00:00<00:00, 137.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 137.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████▋                   | 22/40 [00:00<00:00, 87.04it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████▋                   | 22/40 [00:00<00:00, 92.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|███████████████████████▋                   | 22/40 [00:00<00:00, 82.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▍            | 28/40 [00:00<00:00, 123.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▌          | 30/40 [00:00<00:00, 110.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 107.29it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 127.81it/s]\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████▍       | 33/40 [00:00<00:00, 90.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 110.75it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 92.62it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 104.82it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 108.75it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_abolish.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_abolish.tsv\n",
      "Processing Started...\n",
      "Data Size:  283\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 15%|██████▌                                     | 6/40 [00:00<00:00, 49.69it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 15%|██████▌                                     | 6/40 [00:00<00:00, 42.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 28%|███████████▊                               | 11/40 [00:00<00:00, 87.96it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████▉                                  | 9/40 [00:00<00:00, 79.97it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████▌                             | 12/40 [00:00<00:00, 108.54it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 35%|███████████████                            | 14/40 [00:00<00:00, 60.85it/s]\n",
      " 52%|██████████████████████▌                    | 21/40 [00:00<00:00, 99.26it/s]\u001b[A\n",
      "\n",
      " 75%|███████████████████████████████▌          | 30/40 [00:00<00:00, 140.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▊                               | 11/40 [00:00<00:00, 88.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▊                         | 16/40 [00:00<00:00, 155.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████▍                      | 19/40 [00:00<00:00, 87.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 130.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|██████████████████████████████████▍        | 32/40 [00:00<00:00, 94.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▌        | 32/40 [00:00<00:00, 145.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████▋                   | 22/40 [00:00<00:00, 74.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 70%|██████████████████████████████             | 28/40 [00:00<00:00, 77.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 107.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 84.79it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 137.08it/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 76.43it/s]\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 89.24it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 40/40 [00:00<00:00, 88.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_abolish.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_alter.tsv\n",
      "Processing Started...\n",
      "Data Size:  254\n",
      "number of threads:  7\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 44%|██████████████████▋                       | 16/36 [00:00<00:00, 145.47it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 50%|█████████████████████                     | 18/36 [00:00<00:00, 159.12it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 36%|███████████████▏                          | 13/36 [00:00<00:00, 117.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▎                         | 14/36 [00:00<00:00, 139.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▉                               | 10/36 [00:00<00:00, 94.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 164.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████▋  | 34/36 [00:00<00:00, 122.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 126.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▏                             | 11/36 [00:00<00:00, 84.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████       | 30/36 [00:00<00:00, 149.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 142.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 116.73it/s]\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 148.10it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████              | 24/36 [00:00<00:00, 104.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 103.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 104.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_alter.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_alter.tsv\n",
      "Processing Started...\n",
      "Data Size:  255\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 36%|███████████████▏                          | 13/36 [00:00<00:00, 126.74it/s]\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/36 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 44%|██████████████████▋                       | 16/36 [00:00<00:00, 144.49it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▎                         | 14/36 [00:00<00:00, 130.36it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 75%|███████████████████████████████▌          | 27/36 [00:00<00:00, 130.52it/s]\n",
      "\n",
      " 42%|█████████████████▌                        | 15/36 [00:00<00:00, 142.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████▊                                  | 8/36 [00:00<00:00, 78.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▏                          | 13/36 [00:00<00:00, 119.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 169.75it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▎                         | 14/36 [00:00<00:00, 132.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 121.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 119.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████████████████████████▎                | 22/36 [00:00<00:00, 86.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████▊             | 25/36 [00:00<00:00, 91.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 120.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 117.09it/s]\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 103.52it/s]\n",
      "100%|██████████████████████████████████████████| 36/36 [00:00<00:00, 100.87it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_alter.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_begin.tsv\n",
      "Processing Started...\n",
      "Data Size:  683\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▊                                     | 11/97 [00:00<00:00, 102.30it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  9%|████                                        | 9/97 [00:00<00:00, 89.87it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  8%|███▋                                        | 8/97 [00:00<00:01, 75.08it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████▋                                    | 13/97 [00:00<00:00, 115.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▍                               | 24/97 [00:00<00:00, 117.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|███▏                                        | 7/97 [00:00<00:01, 69.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▉                                   | 18/97 [00:00<00:00, 87.04it/s]\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▊                               | 25/97 [00:00<00:00, 116.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|███████                                    | 16/97 [00:00<00:01, 67.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████▏                                    | 12/97 [00:00<00:00, 111.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▌                          | 36/97 [00:00<00:00, 111.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▍                                  | 19/97 [00:00<00:00, 93.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 30%|████████████▊                              | 29/97 [00:00<00:00, 93.79it/s]\u001b[A\n",
      "\n",
      " 27%|███████████▌                               | 26/97 [00:00<00:00, 78.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|████████████████                          | 37/97 [00:00<00:00, 104.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████████████████████▊                     | 48/97 [00:00<00:00, 110.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▎                             | 30/97 [00:00<00:00, 99.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|██████████▋                                | 24/97 [00:00<00:00, 86.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|█████████████████▎                         | 39/97 [00:00<00:00, 92.77it/s]\u001b[A\n",
      "\n",
      "\n",
      " 53%|██████████████████████                    | 51/97 [00:00<00:00, 116.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|███████████████▉                           | 36/97 [00:00<00:00, 84.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████▍                  | 54/97 [00:00<00:00, 117.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|█████████████████████████▉                | 60/97 [00:00<00:00, 100.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 51%|█████████████████████▋                     | 49/97 [00:00<00:00, 79.19it/s]\u001b[A\n",
      "\n",
      " 46%|███████████████████▉                       | 45/97 [00:00<00:00, 77.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▎              | 63/97 [00:00<00:00, 104.06it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▍         | 75/97 [00:00<00:00, 115.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████▍                   | 53/97 [00:00<00:00, 93.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|█████████████████████████▋                 | 58/97 [00:00<00:00, 79.94it/s]\u001b[A\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▍         | 75/97 [00:00<00:00, 108.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████▋             | 67/97 [00:00<00:00, 89.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████▍                      | 46/97 [00:00<00:00, 80.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████████▌    | 87/97 [00:00<00:00, 99.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████████▎ | 93/97 [00:00<00:00, 128.83it/s]\u001b[A\u001b[A\u001b[A\n",
      " 69%|█████████████████████████████▋             | 67/97 [00:00<00:00, 81.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▎                 | 57/97 [00:00<00:00, 88.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████████        | 79/97 [00:00<00:00, 94.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 118.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████▎          | 73/97 [00:00<00:00, 84.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|█████████████████████████████████▋         | 76/97 [00:00<00:00, 80.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 100.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 99%|█████████████████████████████████████████▌| 96/97 [00:00<00:00, 110.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 108.16it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████████▎      | 82/97 [00:00<00:00, 85.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████▌   | 89/97 [00:00<00:00, 125.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 104.21it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 97/97 [00:01<00:00, 90.45it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|████████████████████████████████████████▎  | 91/97 [00:01<00:00, 85.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 97/97 [00:01<00:00, 83.36it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 97/97 [00:01<00:00, 89.23it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_begin.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_begin.tsv\n",
      "Processing Started...\n",
      "Data Size:  684\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 11%|████▉                                      | 11/97 [00:00<00:00, 91.27it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  8%|███▋                                        | 8/97 [00:00<00:01, 74.10it/s]\u001b[A\n",
      "\n",
      "  7%|███▏                                        | 7/97 [00:00<00:01, 68.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/97 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████▏                                    | 12/97 [00:00<00:00, 113.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▉                                   | 16/97 [00:00<00:00, 159.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▊                               | 25/97 [00:00<00:00, 112.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 19%|███████▉                                   | 18/97 [00:00<00:00, 87.40it/s]\u001b[A\n",
      "\n",
      " 19%|███████▉                                   | 18/97 [00:00<00:00, 92.10it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  9%|████                                        | 9/97 [00:00<00:01, 86.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 31%|████████████▉                             | 30/97 [00:00<00:00, 146.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████▎                           | 33/97 [00:00<00:00, 163.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▌                          | 36/97 [00:00<00:00, 168.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 40%|████████████████▉                         | 39/97 [00:00<00:00, 118.51it/s]\u001b[A\n",
      "\n",
      " 29%|████████████▍                              | 28/97 [00:00<00:00, 91.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▊                                  | 20/97 [00:00<00:00, 91.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 52%|█████████████████████▋                    | 50/97 [00:00<00:00, 161.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▋                    | 50/97 [00:00<00:00, 135.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|████████████████▊                          | 38/97 [00:00<00:00, 86.68it/s]\u001b[A\u001b[A\n",
      " 46%|███████████████████▉                       | 45/97 [00:00<00:00, 99.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▎                             | 30/97 [00:00<00:00, 89.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████▉                   | 53/97 [00:00<00:00, 130.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████             | 67/97 [00:00<00:00, 148.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|████████████████████████████▌             | 66/97 [00:00<00:00, 139.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▍                      | 45/97 [00:00<00:00, 110.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|████████████████████▊                      | 47/97 [00:00<00:00, 80.26it/s]\u001b[A\u001b[A\n",
      " 58%|████████████████████████▊                  | 56/97 [00:00<00:00, 95.51it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|███████████████████████████                | 61/97 [00:00<00:00, 92.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████▌      | 82/97 [00:00<00:00, 143.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████████       | 81/97 [00:00<00:00, 137.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|████████████████████████▋                 | 57/97 [00:00<00:00, 112.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████████████████████████▏                | 59/97 [00:00<00:00, 90.37it/s]\u001b[A\u001b[A\n",
      " 71%|█████████████████████████████▉            | 69/97 [00:00<00:00, 103.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 147.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|████████████████████████████████▍         | 75/97 [00:00<00:00, 105.25it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|█████████████████████████████████████████▏| 95/97 [00:00<00:00, 137.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 141.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 140.25it/s]\n",
      "\n",
      " 87%|████████████████████████████████████▎     | 84/97 [00:00<00:00, 113.47it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 107.68it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 126.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 97/97 [00:00<00:00, 108.37it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 97/97 [00:00<00:00, 99.32it/s]\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_begin.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_block.tsv\n",
      "Processing Started...\n",
      "Data Size:  362\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 14%|██████                                      | 7/51 [00:00<00:00, 63.88it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 16%|██████▉                                     | 8/51 [00:00<00:00, 77.41it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 16%|██████▉                                     | 8/51 [00:00<00:00, 76.44it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████                                      | 7/51 [00:00<00:00, 65.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▊                               | 14/51 [00:00<00:00, 63.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 35%|███████████████▏                           | 18/51 [00:00<00:00, 90.39it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████                                      | 7/51 [00:00<00:00, 68.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 31%|█████████████▍                             | 16/51 [00:00<00:00, 77.03it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▍                             | 16/51 [00:00<00:00, 79.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▊                               | 14/51 [00:00<00:00, 67.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 51%|█████████████████████▉                     | 26/51 [00:00<00:00, 82.55it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▉                                | 12/51 [00:00<00:00, 118.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|████████████████                           | 19/51 [00:00<00:00, 96.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|████████████████████████▍                  | 29/51 [00:00<00:00, 97.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 53%|██████████████████████▊                    | 27/51 [00:00<00:00, 90.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|███████████████████████▉                  | 29/51 [00:00<00:00, 102.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|████████████████████████████████▉         | 40/51 [00:00<00:00, 103.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▏              | 33/51 [00:00<00:00, 115.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 109.86it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 114.49it/s]\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████           | 38/51 [00:00<00:00, 94.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████▏                      | 24/51 [00:00<00:00, 88.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 116.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 106.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████▋              | 34/51 [00:00<00:00, 83.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 79.67it/s]\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 85.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 91.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_block.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_block.tsv\n",
      "Processing Started...\n",
      "Data Size:  363\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▉                                     | 8/51 [00:00<00:00, 73.86it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 22%|█████████                                 | 11/51 [00:00<00:00, 100.75it/s]\u001b[A\n",
      "\n",
      " 27%|███████████▌                              | 14/51 [00:00<00:00, 137.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▌                              | 14/51 [00:00<00:00, 138.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/51 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 39%|████████████████▊                          | 20/51 [00:00<00:00, 97.56it/s]\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▍                                  | 10/51 [00:00<00:00, 91.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████▏                                      | 6/51 [00:00<00:00, 57.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|███████████████████████                   | 28/51 [00:00<00:00, 124.67it/s]\u001b[A\u001b[A\n",
      " 43%|██████████████████▌                        | 22/51 [00:00<00:00, 86.32it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▍                                  | 10/51 [00:00<00:00, 98.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▏              | 33/51 [00:00<00:00, 104.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|███████████████████████                   | 28/51 [00:00<00:00, 110.92it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|████████████████                           | 19/51 [00:00<00:00, 92.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 63%|██████████████████████████▉                | 32/51 [00:00<00:00, 85.38it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████▉                       | 23/51 [00:00<00:00, 114.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████████████████████████▏                | 31/51 [00:00<00:00, 96.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 122.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 86%|█████████████████████████████████████      | 44/51 [00:00<00:00, 96.89it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 101.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 88%|█████████████████████████████████████▉     | 45/51 [00:00<00:00, 96.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 114.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 51/51 [00:00<00:00, 94.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 137.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 101.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 51/51 [00:00<00:00, 107.40it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_block.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_catalyse.tsv\n",
      "Processing Started...\n",
      "Data Size:  195\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████▋                             | 9/27 [00:00<00:00, 83.45it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 26%|███████████▍                                | 7/27 [00:00<00:00, 66.93it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 19%|████████▏                                   | 5/27 [00:00<00:00, 44.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|██████████████▋                             | 9/27 [00:00<00:00, 89.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████▋              | 18/27 [00:00<00:00, 83.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████▍                                | 7/27 [00:00<00:00, 60.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 79.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████████▊           | 20/27 [00:00<00:00, 75.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 31.15it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 88.72it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|██████████████████████▎                    | 14/27 [00:00<00:00, 43.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 51.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 61.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████████▍         | 21/27 [00:00<00:00, 57.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████████▍         | 21/27 [00:00<00:00, 75.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 59.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 63.25it/s]\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 76.51it/s]\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 55.74it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_catalyse.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_catalyse.tsv\n",
      "Processing Started...\n",
      "Data Size:  196\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 21%|█████████▍                                  | 6/28 [00:00<00:00, 57.59it/s]\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 69.49it/s]\u001b[A\n",
      "\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 53.49it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 69.23it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 68.47it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▊                                    | 5/28 [00:00<00:00, 47.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:00<00:00, 89.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 96%|█████████████████████████████████████████▍ | 27/28 [00:00<00:00, 87.34it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 79.52it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 81.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▊                                    | 5/28 [00:00<00:00, 49.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 12/28 [00:00<00:00, 57.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███████████████▎                           | 10/28 [00:00<00:00, 34.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▎                           | 10/28 [00:00<00:00, 55.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 72.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:00<00:00, 55.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 49.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████▎          | 21/28 [00:00<00:00, 79.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 82.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 78.22it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 62.13it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 56.93it/s]\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_catalyse.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_confer.tsv\n",
      "Processing Started...\n",
      "Data Size:  317\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 16%|██████▊                                     | 7/45 [00:00<00:00, 68.30it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      " 16%|██████▊                                     | 7/45 [00:00<00:00, 56.44it/s]\u001b[A\n",
      "\n",
      " 13%|█████▊                                      | 6/45 [00:00<00:00, 59.66it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 31%|█████████████▍                             | 14/45 [00:00<00:00, 55.10it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▉                                        | 4/45 [00:00<00:01, 39.47it/s]\u001b[A\u001b[A\u001b[A\n",
      " 33%|██████████████▎                            | 15/45 [00:00<00:00, 66.11it/s]\u001b[A\n",
      "\n",
      " 29%|████████████▍                              | 13/45 [00:00<00:00, 65.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████                      | 22/45 [00:00<00:00, 56.11it/s]\u001b[A\u001b[A\u001b[A\n",
      " 49%|█████████████████████                      | 22/45 [00:00<00:00, 62.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▊                                      | 6/45 [00:00<00:00, 55.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|███████████████████                        | 20/45 [00:00<00:00, 49.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                               | 12/45 [00:00<00:00, 45.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▊                | 28/45 [00:00<00:00, 57.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|███████████████████                        | 20/45 [00:00<00:00, 57.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|█████████████████████                      | 22/45 [00:00<00:00, 49.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                               | 12/45 [00:00<00:00, 46.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▊                                      | 6/45 [00:00<00:00, 56.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|██████████████████████████████▌            | 32/45 [00:00<00:00, 53.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████▏    | 40/45 [00:00<00:00, 57.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████▏                        | 19/45 [00:00<00:00, 54.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▊                | 28/45 [00:00<00:00, 64.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                               | 12/45 [00:00<00:00, 57.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 60.84it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 56.94it/s]\n",
      "\n",
      "\n",
      " 98%|██████████████████████████████████████████ | 44/45 [00:00<00:00, 67.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 61.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████▊                  | 26/45 [00:00<00:00, 56.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████                       | 21/45 [00:00<00:00, 68.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 78%|█████████████████████████████████▍         | 35/45 [00:00<00:00, 59.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|███████████████████████████▋               | 29/45 [00:00<00:00, 70.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 56.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 60.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████▎      | 38/45 [00:00<00:00, 76.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 60.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 70.28it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_confer.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_confer.tsv\n",
      "Processing Started...\n",
      "Data Size:  319\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 20%|████████▊                                   | 9/45 [00:00<00:00, 85.78it/s]\n",
      "\n",
      "\n",
      " 20%|████████▊                                   | 9/45 [00:00<00:00, 81.82it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 13%|█████▊                                      | 6/45 [00:00<00:00, 55.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▊                                    | 8/45 [00:00<00:00, 72.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/45 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 38%|████████████████▏                          | 17/45 [00:00<00:00, 80.89it/s]\u001b[A\n",
      "\n",
      " 40%|█████████████████▏                         | 18/45 [00:00<00:00, 67.94it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▍                              | 13/45 [00:00<00:00, 62.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▊                                   | 9/45 [00:00<00:00, 89.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████▏                         | 18/45 [00:00<00:00, 87.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 13%|█████▊                                      | 6/45 [00:00<00:00, 57.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 71%|█████████████████████████████▊            | 32/45 [00:00<00:00, 103.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|████████████████████████▊                  | 26/45 [00:00<00:00, 67.73it/s]\u001b[A\u001b[A\u001b[A\n",
      " 58%|████████████████████████▊                  | 26/45 [00:00<00:00, 72.20it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|████████████████████████████▉             | 31/45 [00:00<00:00, 106.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                               | 12/45 [00:00<00:00, 55.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 96.17it/s]\u001b[A\u001b[A\n",
      " 73%|███████████████████████████████▌           | 33/45 [00:00<00:00, 62.92it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|███████████████████                        | 20/45 [00:00<00:00, 63.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▊                 | 27/45 [00:00<00:00, 56.80it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████████▏  | 42/45 [00:00<00:00, 92.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 89.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████▏    | 40/45 [00:00<00:00, 60.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 67.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 86.58it/s]\n",
      "\n",
      "\n",
      "\n",
      " 73%|███████████████████████████████▌           | 33/45 [00:00<00:00, 45.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 60.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████▏    | 40/45 [00:00<00:00, 51.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 65.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 45/45 [00:00<00:00, 53.92it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_confer.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_decrease.tsv\n",
      "Processing Started...\n",
      "Data Size:  195\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 99.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 73.41it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 88.67it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 96.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|███████████████████████████████████        | 22/27 [00:00<00:00, 84.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████▋                             | 9/27 [00:00<00:00, 88.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████████▎            | 19/27 [00:00<00:00, 73.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 74%|███████████████████████████████▊           | 20/27 [00:00<00:00, 76.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 78.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 81%|███████████████████████████████████        | 22/27 [00:00<00:00, 99.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 70.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 103.83it/s]\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 74.26it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████▋                      | 13/27 [00:00<00:00, 60.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 69.18it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 82.95it/s]\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 84.07it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_decrease.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_decrease.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 25%|███████████                                 | 7/28 [00:00<00:00, 64.18it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 32%|██████████████▏                             | 9/28 [00:00<00:00, 88.34it/s]\u001b[A\u001b[A\n",
      " 14%|██████▎                                     | 4/28 [00:00<00:00, 37.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 57.56it/s]\u001b[A\u001b[A\u001b[A\n",
      " 50%|█████████████████████▌                     | 14/28 [00:00<00:00, 71.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 64%|███████████████████████████▋               | 18/28 [00:00<00:00, 68.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▉                       | 13/28 [00:00<00:00, 63.98it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:00<00:00, 66.65it/s]\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:00<00:00, 74.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 70.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 77.02it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 65.28it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 68.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▋            | 20/28 [00:00<00:00, 55.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 61%|██████████████████████████                 | 17/28 [00:00<00:00, 79.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 61.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:00<00:00, 88.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 82.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 90.59it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 89.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_decrease.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_delete.tsv\n",
      "Processing Started...\n",
      "Data Size:  411\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 19%|████████▏                                  | 11/58 [00:00<00:00, 99.17it/s]\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      " 24%|██████████▏                               | 14/58 [00:00<00:00, 136.31it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 16%|██████▊                                     | 9/58 [00:00<00:00, 86.71it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 38%|███████████████▉                          | 22/58 [00:00<00:00, 102.09it/s]\n",
      "\n",
      "\n",
      " 10%|████▌                                       | 6/58 [00:00<00:00, 57.59it/s]\u001b[A\u001b[A\u001b[A\n",
      " 62%|██████████████████████████                | 36/58 [00:00<00:00, 183.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/58 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████                                      | 8/58 [00:00<00:00, 76.62it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 31%|█████████████▎                             | 18/58 [00:00<00:00, 72.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▌                              | 16/58 [00:00<00:00, 150.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 95%|███████████████████████████████████████▊  | 55/58 [00:00<00:00, 174.28it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 173.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▎                             | 18/58 [00:00<00:00, 84.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 48%|████████████████████▊                      | 28/58 [00:00<00:00, 82.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████████▉           | 43/58 [00:00<00:00, 92.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▋                    | 30/58 [00:00<00:00, 154.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 29/58 [00:00<00:00, 87.60it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 47%|████████████████████                       | 27/58 [00:00<00:00, 86.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 91%|███████████████████████████████████████▎   | 53/58 [00:00<00:00, 91.64it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████▋             | 40/58 [00:00<00:00, 92.98it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▋                | 36/58 [00:00<00:00, 86.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████▍   | 53/58 [00:00<00:00, 149.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 58/58 [00:00<00:00, 95.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 146.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 90%|█████████████████████████████████████▋    | 52/58 [00:00<00:00, 100.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 58/58 [00:00<00:00, 99.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 58/58 [00:00<00:00, 126.89it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 58/58 [00:00<00:00, 84.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 58/58 [00:00<00:00, 87.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_delete.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_delete.tsv\n",
      "Processing Started...\n",
      "Data Size:  413\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 19%|███████▊                                  | 11/59 [00:00<00:00, 108.22it/s]\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      " 19%|████████                                   | 11/59 [00:00<00:00, 93.17it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 37%|███████████████▋                          | 22/59 [00:00<00:00, 107.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▊                                  | 11/59 [00:00<00:00, 108.02it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 36%|███████████████▎                           | 21/59 [00:00<00:00, 88.83it/s]\u001b[A\n",
      "\n",
      " 37%|████████████████                           | 22/59 [00:00<00:00, 98.47it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/59 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 56%|███████████████████████▍                  | 33/59 [00:00<00:00, 101.11it/s]\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▍                                       | 6/59 [00:00<00:00, 59.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|█████████████████                         | 24/59 [00:00<00:00, 112.86it/s]\u001b[A\u001b[A\u001b[A\n",
      " 56%|████████████████████████                   | 33/59 [00:00<00:00, 93.23it/s]\u001b[A\n",
      "\n",
      " 56%|███████████████████████▍                  | 33/59 [00:00<00:00, 100.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▍                                       | 6/59 [00:00<00:01, 49.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████           | 44/59 [00:00<00:00, 93.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▋                | 36/59 [00:00<00:00, 106.42it/s]\u001b[A\u001b[A\u001b[A\n",
      " 75%|████████████████████████████████           | 44/59 [00:00<00:00, 96.09it/s]\u001b[A\n",
      "\n",
      " 75%|████████████████████████████████           | 44/59 [00:00<00:00, 94.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|██████████▏                                | 14/59 [00:00<00:00, 61.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████                              | 18/59 [00:00<00:00, 81.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|██████████████████▏                        | 25/59 [00:00<00:00, 87.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 104.77it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 100.65it/s]\n",
      "\n",
      "\n",
      " 93%|████████████████████████████████████████   | 55/59 [00:00<00:00, 96.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                         | 24/59 [00:00<00:00, 73.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 59/59 [00:00<00:00, 118.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 59/59 [00:00<00:00, 96.86it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 64%|███████████████████████████▋               | 38/59 [00:00<00:00, 97.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████████▍              | 39/59 [00:00<00:00, 91.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|████████████████████████▊                  | 34/59 [00:00<00:00, 79.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 59/59 [00:00<00:00, 97.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████▎        | 47/59 [00:00<00:00, 96.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 59/59 [00:00<00:00, 97.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 59/59 [00:00<00:00, 86.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_delete.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_develop.tsv\n",
      "Processing Started...\n",
      "Data Size:  62\n",
      "number of threads:  7\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 241.11it/s]\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 132.13it/s]\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 111.10it/s]\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 109.94it/s]\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 80.48it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|████████████████████████████▏                | 5/8 [00:00<00:00, 48.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 47.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 55.53it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_develop.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_develop.tsv\n",
      "Processing Started...\n",
      "Data Size:  62\n",
      "number of threads:  7\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 157.14it/s]\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 183.83it/s]\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 180.47it/s]\n",
      "100%|████████████████████████████████████████████| 8/8 [00:00<00:00, 125.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 70.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                     | 0/8 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 71.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:00<00:00, 53.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_develop.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_disrupt.tsv\n",
      "Processing Started...\n",
      "Data Size:  119\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 59%|█████████████████████████▎                 | 10/17 [00:00<00:00, 94.23it/s]\n",
      " 76%|████████████████████████████████          | 13/17 [00:00<00:00, 125.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 138.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 47%|████████████████████▋                       | 8/17 [00:00<00:00, 77.20it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 116.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 126.53it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|█████████████████████████████▋            | 12/17 [00:00<00:00, 110.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 76.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 120.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 95.48it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 97.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_disrupt.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_disrupt.tsv\n",
      "Processing Started...\n",
      "Data Size:  120\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 88%|█████████████████████████████████████     | 15/17 [00:00<00:00, 141.79it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 88%|█████████████████████████████████████     | 15/17 [00:00<00:00, 147.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 151.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 134.80it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 53%|███████████████████████▎                    | 9/17 [00:00<00:00, 89.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████████████████████▋                       | 8/17 [00:00<00:00, 78.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 65%|███████████████████████████▏              | 11/17 [00:00<00:00, 105.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 85.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/17 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 104.31it/s]\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 17/17 [00:00<00:00, 75.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▎                 | 10/17 [00:00<00:00, 88.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 133.78it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 17/17 [00:00<00:00, 101.34it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_disrupt.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_eliminate.tsv\n",
      "Processing Started...\n",
      "Data Size:  191\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 89.76it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 98.43it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 75.54it/s]\u001b[A\n",
      "\n",
      "\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 76.62it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 87.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|███████████████████████████████████        | 22/27 [00:00<00:00, 79.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 90.85it/s]\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 78%|█████████████████████████████████▍         | 21/27 [00:00<00:00, 70.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 78.46it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 81.11it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▉                           | 10/27 [00:00<00:00, 97.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 83.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|███████████████████████████████████████████| 27/27 [00:00<00:00, 91.35it/s]\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 119.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 202.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_eliminate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_eliminate.tsv\n",
      "Processing Started...\n",
      "Data Size:  192\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 56%|███████████████████████▎                  | 15/27 [00:00<00:00, 129.96it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 67%|████████████████████████████              | 18/27 [00:00<00:00, 170.34it/s]\u001b[A\n",
      "\n",
      " 41%|█████████████████▌                         | 11/27 [00:00<00:00, 96.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 67%|████████████████████████████              | 18/27 [00:00<00:00, 169.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 190.93it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/27 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 187.95it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 130.54it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 130.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████                         | 11/27 [00:00<00:00, 103.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 145.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 199.82it/s]\n",
      "100%|██████████████████████████████████████████| 27/27 [00:00<00:00, 141.21it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_eliminate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_encode.tsv\n",
      "Processing Started...\n",
      "Data Size:  196\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 61%|█████████████████████████▍                | 17/28 [00:00<00:00, 163.29it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 100.72it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 160.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|██████████████████████▌                   | 15/28 [00:00<00:00, 133.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 109.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 117.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|███████████                                 | 7/28 [00:00<00:00, 61.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 114.87it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 126.73it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████▊         | 22/28 [00:00<00:00, 86.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 133.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 113.53it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 92.72it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▌                  | 16/28 [00:00<00:00, 73.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 80.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_encode.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_encode.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 39%|████████████████▉                          | 11/28 [00:00<00:00, 99.40it/s]\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 32%|██████████████▏                             | 9/28 [00:00<00:00, 82.76it/s]\u001b[A\n",
      "\n",
      " 61%|█████████████████████████▍                | 17/28 [00:00<00:00, 169.73it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████████▌       | 23/28 [00:00<00:00, 110.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 157.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 106.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 79%|█████████████████████████████████         | 22/28 [00:00<00:00, 102.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████                     | 14/28 [00:00<00:00, 128.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 103.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████████▌       | 23/28 [00:00<00:00, 111.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 98.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 119.73it/s]\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 114.85it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 110.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_encode.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_express.tsv\n",
      "Processing Started...\n",
      "Data Size:  395\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▎                                 | 11/56 [00:00<00:00, 108.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 32%|█████████████▌                            | 18/56 [00:00<00:00, 172.89it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 18%|███████▋                                   | 10/56 [00:00<00:00, 99.61it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|███████                                     | 9/56 [00:00<00:00, 89.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|███████                                     | 9/56 [00:00<00:00, 83.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▎                                 | 11/56 [00:00<00:00, 108.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▉                          | 22/56 [00:00<00:00, 98.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 36%|███████████████▎                           | 20/56 [00:00<00:00, 97.90it/s]\u001b[A\u001b[A\n",
      " 64%|███████████████████████████               | 36/56 [00:00<00:00, 147.62it/s]\u001b[A\n",
      "\n",
      "\n",
      " 36%|███████████████                           | 20/56 [00:00<00:00, 101.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▌                         | 22/56 [00:00<00:00, 106.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████▊                       | 25/56 [00:00<00:00, 124.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▌                  | 32/56 [00:00<00:00, 91.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 57%|████████████████████████                  | 32/56 [00:00<00:00, 105.69it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 149.63it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████                  | 32/56 [00:00<00:00, 109.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 68%|████████████████████████████▌             | 38/56 [00:00<00:00, 129.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|█████████████████████████████████          | 43/56 [00:00<00:00, 95.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████████          | 43/56 [00:00<00:00, 97.12it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▎         | 43/56 [00:00<00:00, 100.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████   | 52/56 [00:00<00:00, 123.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 123.47it/s]\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 124.61it/s]\n",
      " 95%|████████████████████████████████████████▋  | 53/56 [00:00<00:00, 92.63it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 56/56 [00:00<00:00, 91.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████████▋  | 53/56 [00:00<00:00, 87.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 56/56 [00:00<00:00, 96.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 56/56 [00:00<00:00, 90.04it/s]\n",
      "100%|███████████████████████████████████████████| 56/56 [00:00<00:00, 96.02it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_express.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_express.tsv\n",
      "Processing Started...\n",
      "Data Size:  397\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 21%|█████████▏                                 | 12/56 [00:00<00:00, 91.22it/s]\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 54%|██████████████████████▌                   | 30/56 [00:00<00:00, 135.90it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 20%|████████▍                                  | 11/56 [00:00<00:00, 93.67it/s]\u001b[A\n",
      "\n",
      " 11%|████▋                                       | 6/56 [00:00<00:00, 56.21it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/56 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▋                                       | 6/56 [00:00<00:00, 55.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|███████                                     | 9/56 [00:00<00:00, 80.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 45/56 [00:00<00:00, 133.67it/s]\u001b[A\u001b[A\u001b[A\n",
      " 39%|████████████████▉                          | 22/56 [00:00<00:00, 98.86it/s]\u001b[A\n",
      "\n",
      " 27%|███████████▌                               | 15/56 [00:00<00:00, 72.22it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████▌                                      | 7/56 [00:00<00:00, 57.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 30%|█████████████                              | 17/56 [00:00<00:00, 85.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███████████████▎                           | 20/56 [00:00<00:00, 86.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 124.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████▋                      | 27/56 [00:00<00:00, 92.58it/s]\u001b[A\u001b[A\n",
      " 61%|█████████████████████████▍                | 34/56 [00:00<00:00, 101.87it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▊                    | 29/56 [00:00<00:00, 100.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▎                           | 20/56 [00:00<00:00, 89.23it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 55%|███████████████████████▊                   | 31/56 [00:00<00:00, 93.76it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|██████████████████████▎                    | 29/56 [00:00<00:00, 91.97it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 45/56 [00:00<00:00, 122.15it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▋            | 40/56 [00:00<00:00, 98.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|███████████████████████                    | 30/56 [00:00<00:00, 87.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 80%|██████████████████████████████████▌        | 45/56 [00:00<00:00, 86.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▌          | 42/56 [00:00<00:00, 103.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 107.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 106.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████▎          | 42/56 [00:00<00:00, 98.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|██████████████████████████████████████████▏| 55/56 [00:00<00:00, 89.77it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 103.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 56/56 [00:00<00:00, 91.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 56/56 [00:00<00:00, 96.53it/s]\n",
      "100%|██████████████████████████████████████████| 56/56 [00:00<00:00, 102.33it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_express.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_generate.tsv\n",
      "Processing Started...\n",
      "Data Size:  370\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 21%|████████▉                                 | 11/52 [00:00<00:00, 105.86it/s]\n",
      " 19%|████████▎                                  | 10/52 [00:00<00:00, 97.50it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 23%|█████████▋                                | 12/52 [00:00<00:00, 109.32it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|██████████▌                               | 13/52 [00:00<00:00, 123.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▉                                 | 11/52 [00:00<00:00, 108.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/52 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 48%|████████████████████▏                     | 25/52 [00:00<00:00, 124.81it/s]\n",
      " 44%|██████████████████▌                       | 23/52 [00:00<00:00, 115.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                  | 11/52 [00:00<00:00, 93.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 46%|███████████████████▍                      | 24/52 [00:00<00:00, 113.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 54%|██████████████████████▌                   | 28/52 [00:00<00:00, 137.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████▌      | 44/52 [00:00<00:00, 152.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 150.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████▍                  | 29/52 [00:00<00:00, 139.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 156.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████             | 36/52 [00:00<00:00, 101.63it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 155.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 92%|██████████████████████████████████████▊   | 48/52 [00:00<00:00, 115.77it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 117.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 175.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 132.08it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 52/52 [00:00<00:00, 107.53it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_generate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_generate.tsv\n",
      "Processing Started...\n",
      "Data Size:  371\n",
      "number of threads:  7\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 103.69it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 17%|███████▍                                    | 9/53 [00:00<00:00, 81.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 17%|███████▍                                    | 9/53 [00:00<00:00, 80.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 42%|█████████████████▍                        | 22/53 [00:00<00:00, 211.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▌                                | 12/53 [00:00<00:00, 114.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▍                            | 17/53 [00:00<00:00, 169.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|██████████████████▏                       | 23/53 [00:00<00:00, 107.87it/s]\u001b[A\n",
      "\n",
      " 42%|█████████████████▍                        | 22/53 [00:00<00:00, 100.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|███████████████████                       | 24/53 [00:00<00:00, 118.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 214.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████████████████████▍                    | 27/53 [00:00<00:00, 129.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████            | 38/53 [00:00<00:00, 192.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|███████████████████████████▋              | 35/53 [00:00<00:00, 111.64it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 165.62it/s]\u001b[A\u001b[A\n",
      " 64%|██████████████████████████▉               | 34/53 [00:00<00:00, 107.04it/s]\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 185.45it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 136.87it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▋          | 40/53 [00:00<00:00, 109.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 106.72it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 127.94it/s]\n",
      "100%|███████████████████████████████████████████| 53/53 [00:00<00:00, 99.67it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_generate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_inhibit.tsv\n",
      "Processing Started...\n",
      "Data Size:  339\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 27%|███████████▍                              | 13/48 [00:00<00:00, 127.99it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 23%|█████████▋                                | 11/48 [00:00<00:00, 109.96it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▎                                    | 8/48 [00:00<00:00, 78.76it/s]\u001b[A\u001b[A\u001b[A\n",
      " 19%|████████▎                                   | 9/48 [00:00<00:00, 83.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 69%|████████████████████████████▉             | 33/48 [00:00<00:00, 164.54it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▋                                | 11/48 [00:00<00:00, 108.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|███████████████████████████▏              | 31/48 [00:00<00:00, 159.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▋                                | 11/48 [00:00<00:00, 106.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 173.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|████████████████▏                          | 18/48 [00:00<00:00, 85.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▋                               | 13/48 [00:00<00:00, 58.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 52%|█████████████████████▉                    | 25/48 [00:00<00:00, 122.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████▋                  | 27/48 [00:00<00:00, 134.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▉                 | 29/48 [00:00<00:00, 96.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 141.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▋                       | 22/48 [00:00<00:00, 70.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 56%|████████████████████████▏                  | 27/48 [00:00<00:00, 78.14it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████▉      | 41/48 [00:00<00:00, 130.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████▉        | 39/48 [00:00<00:00, 96.84it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 123.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▉                | 30/48 [00:00<00:00, 72.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 124.28it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 48/48 [00:00<00:00, 94.44it/s]\n",
      "100%|███████████████████████████████████████████| 48/48 [00:00<00:00, 90.16it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 48/48 [00:00<00:00, 80.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_inhibit.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_inhibit.tsv\n",
      "Processing Started...\n",
      "Data Size:  341\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/48 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                              | 13/48 [00:00<00:00, 124.01it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 31%|█████████████▏                            | 15/48 [00:00<00:00, 144.02it/s]\u001b[A\n",
      "\n",
      " 29%|████████████▎                             | 14/48 [00:00<00:00, 138.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|█████████████████▌                        | 20/48 [00:00<00:00, 193.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████▍                                     | 7/48 [00:00<00:00, 66.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 12%|█████▌                                      | 6/48 [00:00<00:00, 57.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████                            | 16/48 [00:00<00:00, 159.70it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|██████████████████████▊                   | 26/48 [00:00<00:00, 103.06it/s]\u001b[A\u001b[A\n",
      " 62%|██████████████████████████▎               | 30/48 [00:00<00:00, 106.07it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|███████████████████████████████████       | 40/48 [00:00<00:00, 169.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▍                       | 21/48 [00:00<00:00, 103.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 163.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 166.54it/s]\n",
      " 77%|████████████████████████████████▍         | 37/48 [00:00<00:00, 100.96it/s]\n",
      " 88%|████████████████████████████████████▊     | 42/48 [00:00<00:00, 105.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████▎        | 38/48 [00:00<00:00, 131.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 151.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 107.35it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 108.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 48/48 [00:00<00:00, 126.75it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 48/48 [00:00<00:00, 99.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_inhibit.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_initiate.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 43%|██████████████████                        | 12/28 [00:00<00:00, 109.97it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 36%|███████████████▎                           | 10/28 [00:00<00:00, 94.54it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 109.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 76.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 25%|███████████                                 | 7/28 [00:00<00:00, 67.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|██████████████▏                             | 9/28 [00:00<00:00, 85.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 82%|███████████████████████████████████▎       | 23/28 [00:00<00:00, 96.45it/s]\u001b[A\n",
      "\n",
      " 79%|█████████████████████████████████         | 22/28 [00:00<00:00, 100.70it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 92.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████▏             | 19/28 [00:00<00:00, 88.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 107.11it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 96.56it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████         | 22/28 [00:00<00:00, 106.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 112.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████▊      | 24/28 [00:00<00:00, 74.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 77.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 93.71it/s]\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 72.12it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_initiate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_initiate.tsv\n",
      "Processing Started...\n",
      "Data Size:  197\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 29%|████████████▌                               | 8/28 [00:00<00:00, 74.25it/s]\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 103.53it/s]\u001b[A\n",
      "\n",
      " 39%|████████████████▌                         | 11/28 [00:00<00:00, 104.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▌                  | 16/28 [00:00<00:00, 75.58it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/28 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|███████████████████▌                      | 13/28 [00:00<00:00, 124.52it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|██████████████▏                             | 9/28 [00:00<00:00, 81.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 93%|███████████████████████████████████████   | 26/28 [00:00<00:00, 123.97it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 125.39it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 114.72it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 86.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 25%|███████████                                 | 7/28 [00:00<00:00, 64.53it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 127.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 28/28 [00:00<00:00, 125.83it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|███████████████████████                    | 15/28 [00:00<00:00, 71.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 88.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 28/28 [00:00<00:00, 81.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_initiate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_lead.tsv\n",
      "Processing Started...\n",
      "Data Size:  492\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 16%|██████▊                                    | 11/70 [00:00<00:00, 95.94it/s]\n",
      "  6%|██▌                                         | 4/70 [00:00<00:01, 37.91it/s]\u001b[A\n",
      "\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 108.67it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 102.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 95.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 31%|█████████████▏                            | 22/70 [00:00<00:00, 105.27it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 16%|██████▊                                    | 11/70 [00:00<00:01, 44.12it/s]\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▎                              | 20/70 [00:00<00:00, 95.50it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 30%|████████████▉                              | 21/70 [00:00<00:00, 61.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                 | 15/70 [00:00<00:00, 144.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▌                             | 22/70 [00:00<00:00, 83.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|████████████████████▎                      | 33/70 [00:00<00:00, 94.11it/s]\u001b[A\u001b[A\n",
      " 31%|█████████████▌                             | 22/70 [00:00<00:00, 65.46it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                        | 29/70 [00:00<00:00, 140.80it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 30/70 [00:00<00:00, 81.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|███████████████████                        | 31/70 [00:00<00:00, 72.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████                        | 30/70 [00:00<00:00, 139.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|████████████████████▉                      | 34/70 [00:00<00:00, 82.54it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▍               | 44/70 [00:00<00:00, 142.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 81%|██████████████████████████████████▏       | 57/70 [00:00<00:00, 131.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████▉                   | 39/70 [00:00<00:00, 70.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 56%|███████████████████████▉                   | 39/70 [00:00<00:00, 78.56it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 124.13it/s]\u001b[A\n",
      "\n",
      "\n",
      " 76%|████████████████████████████████▌          | 53/70 [00:00<00:00, 83.44it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████████▍      | 59/70 [00:00<00:00, 137.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████████▍      | 59/70 [00:00<00:00, 137.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|██████████████████████████████             | 49/70 [00:00<00:00, 78.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 137.49it/s]\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 139.89it/s]\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████     | 62/70 [00:00<00:00, 83.24it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 90.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 92.19it/s]\n",
      " 83%|███████████████████████████████████▋       | 58/70 [00:00<00:00, 73.19it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 86.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 76.80it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_lead.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_lead.tsv\n",
      "Processing Started...\n",
      "Data Size:  493\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 10%|████▍                                       | 7/70 [00:00<00:00, 67.57it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 17%|███████▏                                  | 12/70 [00:00<00:00, 119.67it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 16%|██████▊                                    | 11/70 [00:00<00:00, 99.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 96.05it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▊                                  | 13/70 [00:00<00:00, 124.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▍                              | 19/70 [00:00<00:00, 187.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 27%|███████████▋                               | 19/70 [00:00<00:00, 90.58it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 101.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▎                              | 20/70 [00:00<00:00, 91.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▏                         | 27/70 [00:00<00:00, 131.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|████████████▉                              | 21/70 [00:00<00:00, 75.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████▏                         | 28/70 [00:00<00:00, 80.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 61%|█████████████████████████▊                | 43/70 [00:00<00:00, 122.15it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 30/70 [00:00<00:00, 93.41it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|██████████████████████▊                   | 38/70 [00:00<00:00, 129.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|███████████████████                        | 31/70 [00:00<00:00, 81.39it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|████████████████████████▌                 | 41/70 [00:00<00:00, 124.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|██████████████████████▋                    | 37/70 [00:00<00:00, 81.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 57%|████████████████████████▌                  | 40/70 [00:00<00:00, 93.10it/s]\u001b[A\u001b[A\u001b[A\n",
      " 80%|█████████████████████████████████▌        | 56/70 [00:00<00:00, 109.75it/s]\u001b[A\n",
      "\n",
      " 57%|████████████████████████▌                  | 40/70 [00:00<00:00, 82.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 74%|███████████████████████████████▏          | 52/70 [00:00<00:00, 110.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████████▎              | 46/70 [00:00<00:00, 77.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 83%|██████████████████████████████████▊       | 58/70 [00:00<00:00, 121.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▋            | 50/70 [00:00<00:00, 92.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████████████████████████████             | 49/70 [00:00<00:00, 83.88it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 93%|███████████████████████████████████████   | 65/70 [00:00<00:00, 116.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 97%|█████████████████████████████████████████▊ | 68/70 [00:00<00:00, 99.42it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 108.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 121.35it/s]\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 121.56it/s]\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 117.71it/s]\n",
      "\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████▊      | 60/70 [00:00<00:00, 84.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 94.03it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 87.07it/s]\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 87.75it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_lead.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_lose.tsv\n",
      "Processing Started...\n",
      "Data Size:  286\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 48%|███████████████████▉                      | 19/40 [00:00<00:00, 186.11it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/40 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 50%|█████████████████████                     | 20/40 [00:00<00:00, 190.08it/s]\u001b[A\n",
      "\n",
      "\n",
      " 18%|███████▋                                    | 7/40 [00:00<00:00, 67.38it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 35%|██████████████▋                           | 14/40 [00:00<00:00, 132.27it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▌                              | 11/40 [00:00<00:00, 105.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|█████████████████▊                        | 17/40 [00:00<00:00, 159.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████████████████▊                         | 16/40 [00:00<00:00, 151.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 164.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 163.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████                   | 22/40 [00:00<00:00, 101.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 95%|███████████████████████████████████████▉  | 38/40 [00:00<00:00, 117.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 125.92it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 156.66it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 82%|██████████████████████████████████▋       | 33/40 [00:00<00:00, 111.43it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 126.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 114.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 128.96it/s]\n",
      "100%|██████████████████████████████████████████| 40/40 [00:00<00:00, 106.03it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_lose.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_lose.tsv\n",
      "Processing Started...\n",
      "Data Size:  287\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 34%|██████████████▎                           | 14/41 [00:00<00:00, 134.98it/s]\n",
      " 34%|██████████████▎                           | 14/41 [00:00<00:00, 137.02it/s]\u001b[A\n",
      "\n",
      " 44%|██████████████████▍                       | 18/41 [00:00<00:00, 173.55it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 32%|█████████████▎                            | 13/41 [00:00<00:00, 129.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▎                            | 13/41 [00:00<00:00, 120.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▎                            | 13/41 [00:00<00:00, 128.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                        | 17/41 [00:00<00:00, 165.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|████████████████████████████▋             | 28/41 [00:00<00:00, 119.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 178.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 168.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 144.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 132.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 166.43it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 136.03it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 130.51it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_lose.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_modify.tsv\n",
      "Processing Started...\n",
      "Data Size:  166\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 90.96it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 178.13it/s]\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 109.94it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 94.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▌                | 14/23 [00:00<00:00, 118.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 148.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 100.41it/s]\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 87.26it/s]\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 116.51it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 97.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 101.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_modify.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_modify.tsv\n",
      "Processing Started...\n",
      "Data Size:  167\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 52%|█████████████████████▉                    | 12/23 [00:00<00:00, 116.26it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 70%|█████████████████████████████▏            | 16/23 [00:00<00:00, 150.84it/s]\u001b[A\n",
      "\n",
      " 61%|█████████████████████████▌                | 14/23 [00:00<00:00, 136.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████▌                      | 11/23 [00:00<00:00, 91.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 152.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 138.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 109.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████████▏ | 22/23 [00:00<00:00, 107.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 109.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 92.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 120.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 81.84it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_modify.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_mutate.tsv\n",
      "Processing Started...\n",
      "Data Size:  244\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 44%|██████████████████▌                       | 15/34 [00:00<00:00, 145.52it/s]\n",
      " 35%|██████████████▊                           | 12/34 [00:00<00:00, 113.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/34 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 32%|█████████████▉                             | 11/34 [00:00<00:00, 92.75it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▌                       | 15/34 [00:00<00:00, 133.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 21%|█████████                                   | 7/34 [00:00<00:00, 63.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|█████████████████████████████████████     | 30/34 [00:00<00:00, 123.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▋                              | 10/34 [00:00<00:00, 98.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 71%|█████████████████████████████▋            | 24/34 [00:00<00:00, 105.00it/s]\u001b[A\n",
      "\n",
      " 65%|███████████████████████████▊               | 22/34 [00:00<00:00, 92.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 34/34 [00:00<00:00, 123.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 34/34 [00:00<00:00, 144.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███████████████▏                           | 12/34 [00:00<00:00, 55.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 99.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 98.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|█████████████████████████████              | 23/34 [00:00<00:00, 73.82it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 34/34 [00:00<00:00, 108.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 86.67it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 34/34 [00:00<00:00, 64.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_mutate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_mutate.tsv\n",
      "Processing Started...\n",
      "Data Size:  245\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 34%|██████████████▍                           | 12/35 [00:00<00:00, 117.41it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 31%|█████████████▌                             | 11/35 [00:00<00:00, 89.35it/s]\u001b[A\n",
      "\n",
      " 34%|██████████████▍                           | 12/35 [00:00<00:00, 112.50it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████      | 30/35 [00:00<00:00, 153.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/35 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▊                                   | 7/35 [00:00<00:00, 65.83it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 35/35 [00:00<00:00, 149.49it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████      | 30/35 [00:00<00:00, 150.39it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 63%|███████████████████████████                | 22/35 [00:00<00:00, 89.10it/s]\u001b[A\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 15/35 [00:00<00:00, 69.18it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████▎                                | 9/35 [00:00<00:00, 82.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 35/35 [00:00<00:00, 133.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|█████                                       | 4/35 [00:00<00:00, 32.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 91%|███████████████████████████████████████▎   | 32/35 [00:00<00:00, 91.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 93.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 57%|████████████████████████▌                  | 20/35 [00:00<00:00, 94.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▋            | 25/35 [00:00<00:00, 80.98it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████▋                            | 12/35 [00:00<00:00, 55.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 84.90it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 35/35 [00:00<00:00, 106.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 76.43it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 35/35 [00:00<00:00, 81.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_mutate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_proliferate.tsv\n",
      "Processing Started...\n",
      "Data Size:  162\n",
      "number of threads:  7\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 52%|█████████████████████▉                    | 12/23 [00:00<00:00, 115.50it/s]\u001b[A\u001b[A\n",
      " 52%|█████████████████████▉                    | 12/23 [00:00<00:00, 106.23it/s]\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 108.00it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 57%|███████████████████████▋                  | 13/23 [00:00<00:00, 126.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 153.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 137.99it/s]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 133.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 104.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 96%|████████████████████████████████████████▏ | 22/23 [00:00<00:00, 102.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 103.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 91.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 105.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_proliferate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_proliferate.tsv\n",
      "Processing Started...\n",
      "Data Size:  163\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 52%|█████████████████████▉                    | 12/23 [00:00<00:00, 107.74it/s]\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 99.53it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 133.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 121.06it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 131.42it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 73.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████████▌     | 20/23 [00:00<00:00, 175.96it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 168.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 123.77it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▉             | 16/23 [00:00<00:00, 74.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 101.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 95.65it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_proliferate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_recognize.tsv\n",
      "Processing Started...\n",
      "Data Size:  291\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 37%|███████████████▎                          | 15/41 [00:00<00:00, 134.46it/s]\u001b[A\n",
      "\n",
      " 41%|█████████████████▍                        | 17/41 [00:00<00:00, 169.86it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▎                            | 13/41 [00:00<00:00, 115.59it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▋               | 26/41 [00:00<00:00, 118.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 12/41 [00:00<00:00, 112.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 73%|██████████████████████████████▋           | 30/41 [00:00<00:00, 143.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▎                          | 15/41 [00:00<00:00, 149.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|██████████████████████████████████▊       | 34/41 [00:00<00:00, 133.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 63%|██████████████████████████▋               | 26/41 [00:00<00:00, 121.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▊        | 33/41 [00:00<00:00, 158.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 133.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 135.89it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 158.54it/s]\n",
      " 93%|███████████████████████████████████████▊   | 38/41 [00:00<00:00, 98.61it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|██████████████████████████████▋           | 30/41 [00:00<00:00, 113.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 133.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 117.10it/s]\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 93.78it/s]\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 113.87it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_recognize.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_recognize.tsv\n",
      "Processing Started...\n",
      "Data Size:  293\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 49%|████████████████████▍                     | 20/41 [00:00<00:00, 195.88it/s]\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|███████████████▎                          | 15/41 [00:00<00:00, 137.35it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/41 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▌                                   | 8/41 [00:00<00:00, 76.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 22%|█████████▋                                  | 9/41 [00:00<00:00, 88.18it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 24%|██████████▍                                | 10/41 [00:00<00:00, 98.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 98%|████████████████████████████████████████▉ | 40/41 [00:00<00:00, 156.88it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 145.92it/s]\n",
      "\n",
      " 71%|█████████████████████████████▋            | 29/41 [00:00<00:00, 103.85it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▌                               | 11/41 [00:00<00:00, 90.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 41%|█████████████████▊                         | 17/41 [00:00<00:00, 81.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 54%|██████████████████████▌                   | 22/41 [00:00<00:00, 105.23it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|█████████████████▍                        | 17/41 [00:00<00:00, 167.93it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|████████████████████▉                      | 20/41 [00:00<00:00, 79.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 98%|████████████████████████████████████████▉ | 40/41 [00:00<00:00, 105.52it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 105.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▍            | 29/41 [00:00<00:00, 97.17it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 125.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 193.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▍            | 29/41 [00:00<00:00, 81.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████████▉  | 39/41 [00:00<00:00, 95.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 94.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 41/41 [00:00<00:00, 109.11it/s]\n",
      "100%|███████████████████████████████████████████| 41/41 [00:00<00:00, 97.09it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_recognize.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_result.tsv\n",
      "Processing Started...\n",
      "Data Size:  496\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 94.11it/s]\u001b[A\n",
      "\n",
      " 16%|██████▊                                    | 11/70 [00:00<00:00, 77.54it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 33%|█████████████▊                            | 23/70 [00:00<00:00, 109.53it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/70 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 30%|████████████▌                             | 21/70 [00:00<00:00, 102.55it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 33%|██████████████▏                            | 23/70 [00:00<00:00, 98.46it/s]\n",
      "\n",
      "\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 105.60it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 14%|██████▏                                    | 10/70 [00:00<00:00, 98.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 19%|███████▊                                  | 13/70 [00:00<00:00, 127.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|████████████████████▍                     | 34/70 [00:00<00:00, 108.37it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▌                                   | 11/70 [00:00<00:00, 107.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 47%|███████████████████▊                      | 33/70 [00:00<00:00, 105.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 49%|████████████████████▉                      | 34/70 [00:00<00:00, 87.73it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                              | 20/70 [00:00<00:00, 94.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 66%|███████████████████████████▌              | 46/70 [00:00<00:00, 111.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▌                          | 26/70 [00:00<00:00, 117.41it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████████████████████▌                    | 36/70 [00:00<00:00, 111.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▍                        | 30/70 [00:00<00:00, 95.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▌                             | 22/70 [00:00<00:00, 82.36it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 63%|███████████████████████████                | 44/70 [00:00<00:00, 86.18it/s]\u001b[A\u001b[A\n",
      " 83%|██████████████████████████████████▊       | 58/70 [00:00<00:00, 112.90it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▏                | 42/70 [00:00<00:00, 128.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▍            | 49/70 [00:00<00:00, 114.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|██████████████████████▊                   | 38/70 [00:00<00:00, 111.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 114.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████▊         | 55/70 [00:00<00:00, 89.31it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 79%|█████████████████████████████████         | 55/70 [00:00<00:00, 117.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████▌  | 66/70 [00:00<00:00, 125.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████     | 62/70 [00:00<00:00, 87.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 122.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 129.25it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 93.00it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 70/70 [00:00<00:00, 86.30it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 107.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 70/70 [00:00<00:00, 115.76it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_result.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_result.tsv\n",
      "Processing Started...\n",
      "Data Size:  497\n",
      "number of threads:  7\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  8%|███▋                                        | 6/71 [00:00<00:01, 57.05it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 13%|█████▌                                      | 9/71 [00:00<00:00, 81.10it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 15%|██████▌                                   | 11/71 [00:00<00:00, 101.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 24%|██████████▎                                | 17/71 [00:00<00:00, 87.05it/s]\n",
      " 31%|█████████████                             | 22/71 [00:00<00:00, 104.79it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▎                                       | 7/71 [00:00<00:01, 63.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|██████████▉                                | 18/71 [00:00<00:00, 80.95it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 37%|███████████████▍                          | 26/71 [00:00<00:00, 128.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▎                       | 31/71 [00:00<00:00, 107.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|████████████████████▋                     | 35/71 [00:00<00:00, 113.10it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▋                                 | 16/71 [00:00<00:00, 77.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▊                                 | 15/71 [00:00<00:00, 149.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|████████████████▎                          | 27/71 [00:00<00:00, 70.36it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 31%|█████████████▎                             | 22/71 [00:00<00:00, 91.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 68%|████████████████████████████▍             | 48/71 [00:00<00:00, 115.43it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 59%|█████████████████████████▍                 | 42/71 [00:00<00:00, 96.75it/s]\n",
      "\n",
      "\n",
      " 55%|███████████████████████▌                   | 39/71 [00:00<00:00, 94.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|█████████████████▋                        | 30/71 [00:00<00:00, 125.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|█████████████████████▏                     | 35/71 [00:00<00:00, 70.87it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 46%|███████████████████▉                       | 33/71 [00:00<00:00, 94.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|███████████████████████▌                   | 39/71 [00:00<00:00, 96.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 121.42it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 124.62it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▋                | 44/71 [00:00<00:00, 98.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 109.64it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▌            | 50/71 [00:00<00:00, 100.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 77%|█████████████████████████████████▎         | 55/71 [00:00<00:00, 82.05it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▋        | 57/71 [00:00<00:00, 108.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████▍   | 65/71 [00:00<00:00, 136.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 135.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 106.98it/s]\n",
      "\n",
      "\n",
      " 90%|██████████████████████████████████████▊    | 64/71 [00:00<00:00, 79.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 71/71 [00:00<00:00, 106.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 71/71 [00:00<00:00, 75.11it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_result.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_skip.tsv\n",
      "Processing Started...\n",
      "Data Size:  79\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████████        | 9/11 [00:00<00:00, 84.71it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 45%|████████████████████                        | 5/11 [00:00<00:00, 48.86it/s]\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 100.49it/s]\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 67.32it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 120.27it/s]\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 51.05it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 90.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 130.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 71.22it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_skip.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_skip.tsv\n",
      "Processing Started...\n",
      "Data Size:  80\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 116.57it/s]\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 107.03it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████████        | 9/11 [00:00<00:00, 83.15it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 76.31it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 84.42it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:00<00:00, 180.64it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|████████████████████████████████████        | 9/11 [00:00<00:00, 83.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 65.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 11/11 [00:00<00:00, 76.02it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_skip.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_splice.tsv\n",
      "Processing Started...\n",
      "Data Size:  390\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▏                             | 16/55 [00:00<00:00, 140.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  9%|████                                        | 5/55 [00:00<00:01, 46.58it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  2%|▊                                           | 1/55 [00:00<00:06,  8.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  4%|█▌                                          | 2/55 [00:00<00:03, 16.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 13%|█████▌                                      | 7/55 [00:00<00:00, 53.22it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▊                                           | 1/55 [00:00<00:06,  8.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|███████████████████████▋                  | 31/55 [00:00<00:00, 126.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 27%|███████████▋                               | 15/55 [00:00<00:00, 75.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▋                               | 15/55 [00:00<00:00, 76.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 38%|████████████████▍                          | 21/55 [00:00<00:00, 97.61it/s]\u001b[A\n",
      "\n",
      " 24%|██████████▏                                | 13/55 [00:00<00:00, 64.77it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|████████▌                                  | 11/55 [00:00<00:00, 54.44it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▌        | 44/55 [00:00<00:00, 112.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 47%|████████████████████▎                      | 26/55 [00:00<00:00, 90.20it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████████████████████▍                    | 28/55 [00:00<00:00, 100.54it/s]\u001b[A\u001b[A\n",
      " 62%|█████████████████████████▉                | 34/55 [00:00<00:00, 109.86it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 33%|██████████████                             | 18/55 [00:00<00:00, 59.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 44%|██████████████████▊                        | 24/55 [00:00<00:00, 70.77it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████▏                         | 22/55 [00:00<00:00, 65.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 80%|█████████████████████████████████▌        | 44/55 [00:00<00:00, 123.55it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 105.28it/s]\n",
      " 80%|█████████████████████████████████▌        | 44/55 [00:00<00:00, 122.26it/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 121.76it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 111.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████████▏              | 36/55 [00:00<00:00, 92.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 102.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 69%|█████████████████████████████▋             | 38/55 [00:00<00:00, 80.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|████████████████████████████████████▋      | 47/55 [00:00<00:00, 97.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████           | 41/55 [00:00<00:00, 72.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 75.89it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|██████████████████████████████████████▎    | 49/55 [00:00<00:00, 62.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 66.08it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 64.27it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_splice.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_splice.tsv\n",
      "Processing Started...\n",
      "Data Size:  390\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 16%|███████▏                                    | 9/55 [00:00<00:00, 88.58it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 24%|█████████▉                                | 13/55 [00:00<00:00, 124.10it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/55 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 13%|█████▌                                      | 7/55 [00:00<00:00, 68.81it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 33%|██████████████                             | 18/55 [00:00<00:00, 80.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  9%|████                                        | 5/55 [00:00<00:01, 46.29it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▊                                   | 10/55 [00:00<00:00, 89.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▊                                       | 6/55 [00:00<00:00, 59.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|████████████████████▌                     | 27/55 [00:00<00:00, 123.91it/s]\u001b[A\n",
      "\n",
      " 29%|████████████▌                              | 16/55 [00:00<00:00, 74.13it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 49%|█████████████████████                      | 27/55 [00:00<00:00, 80.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 75%|███████████████████████████████▎          | 41/55 [00:00<00:00, 129.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 22%|█████████▍                                 | 12/55 [00:00<00:00, 52.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|█████████████████▏                         | 22/55 [00:00<00:00, 88.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 45%|███████████████████▌                       | 25/55 [00:00<00:00, 74.07it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 44%|██████████████████▊                        | 24/55 [00:00<00:00, 67.60it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 67%|████████████████████████████▉              | 37/55 [00:00<00:00, 86.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 127.33it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|███████████████████▌                       | 25/55 [00:00<00:00, 83.60it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████████▉       | 46/55 [00:00<00:00, 85.05it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████████████████████████                  | 32/55 [00:00<00:00, 67.68it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 64%|███████████████████████████▎               | 35/55 [00:00<00:00, 87.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████▊         | 43/55 [00:00<00:00, 119.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▌                | 34/55 [00:00<00:00, 66.99it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████▏       | 45/55 [00:00<00:00, 87.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 76%|████████████████████████████████▊          | 42/55 [00:00<00:00, 75.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 55/55 [00:00<00:00, 103.48it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 93.20it/s]\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 79.72it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|██████████████████████████████████▍        | 44/55 [00:00<00:00, 77.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 87.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 95%|████████████████████████████████████████▋  | 52/55 [00:00<00:00, 81.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 75.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 55/55 [00:00<00:00, 78.07it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_splice.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_transcribe.tsv\n",
      "Processing Started...\n",
      "Data Size:  799\n",
      "number of threads:  7\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 14%|█████▊                                   | 16/114 [00:00<00:00, 155.73it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 12%|█████                                    | 14/114 [00:00<00:00, 138.94it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 14%|█████▊                                   | 16/114 [00:00<00:00, 143.86it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|████                                      | 11/114 [00:00<00:01, 88.75it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 28%|███████████▌                             | 32/114 [00:00<00:00, 155.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                      | 11/114 [00:00<00:01, 94.62it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▊                             | 33/114 [00:00<00:00, 149.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 18%|███████▎                                  | 20/114 [00:00<00:01, 90.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|████████                                  | 22/114 [00:00<00:01, 88.83it/s]\u001b[A\u001b[A\n",
      " 42%|█████████████████▎                       | 48/114 [00:00<00:00, 140.30it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 24%|█████████▋                               | 27/114 [00:00<00:00, 129.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 43%|█████████████████▌                       | 49/114 [00:00<00:00, 145.35it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 29%|████████████▏                             | 33/114 [00:00<00:00, 95.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████                               | 30/114 [00:00<00:00, 90.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 34%|██████████████▎                           | 39/114 [00:00<00:00, 99.31it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▌                                | 26/114 [00:00<00:01, 85.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 55%|██████████████████████▋                  | 63/114 [00:00<00:00, 128.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|███████████████████████▋                 | 66/114 [00:00<00:00, 147.54it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 35%|██████████████▋                           | 40/114 [00:00<00:00, 94.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|███████████████▊                          | 43/114 [00:00<00:00, 93.29it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 32%|█████████████▋                            | 37/114 [00:00<00:00, 93.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 44%|██████████████████▍                       | 50/114 [00:00<00:00, 96.04it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 68%|███████████████████████████▋             | 77/114 [00:00<00:00, 117.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 75%|██████████████████████████████▉          | 86/114 [00:00<00:00, 162.23it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████▊                       | 51/114 [00:00<00:00, 99.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|█████████████████▋                        | 48/114 [00:00<00:00, 99.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|████████████████████▏                    | 56/114 [00:00<00:00, 104.48it/s]\u001b[A\u001b[A\n",
      " 53%|██████████████████████                    | 60/114 [00:00<00:00, 95.24it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|██████████████████████████▉              | 75/114 [00:00<00:00, 153.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 61%|█████████████████████████▏               | 70/114 [00:00<00:00, 114.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 78%|████████████████████████████████         | 89/114 [00:00<00:00, 101.48it/s]\u001b[A\u001b[A\u001b[A\n",
      " 61%|█████████████████████████▊                | 70/114 [00:00<00:00, 91.23it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████████████████████████████▋        | 91/114 [00:00<00:00, 135.86it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▏               | 71/114 [00:00<00:00, 97.40it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 72%|█████████████████████████████▍           | 82/114 [00:00<00:00, 116.04it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 67%|███████████████████████████▎             | 76/114 [00:00<00:00, 117.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 138.81it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|████████████████████████████████████▊   | 105/114 [00:00<00:00, 134.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 83%|██████████████████████████████████▏      | 95/114 [00:00<00:00, 118.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|█████████████████████████████▊            | 81/114 [00:00<00:00, 94.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|██████████████████████████████████▌      | 96/114 [00:00<00:00, 137.92it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 133.25it/s]\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:01<00:00, 109.73it/s]\n",
      "\n",
      "\n",
      " 96%|██████████████████████████████████████▌ | 110/114 [00:00<00:00, 121.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:01<00:00, 110.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:01<00:00, 112.92it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|████████████████████████████████████▎    | 101/114 [00:01<00:00, 90.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|█████████████████████████████████████████| 114/114 [00:01<00:00, 95.08it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████| 114/114 [00:01<00:00, 94.84it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_transcribe.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_transcribe.tsv\n",
      "Processing Started...\n",
      "Data Size:  801\n",
      "number of threads:  7\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 13%|█████▍                                   | 15/114 [00:00<00:00, 132.79it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▊                                   | 16/114 [00:00<00:00, 154.66it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  9%|███▋                                      | 10/114 [00:00<00:01, 99.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 10%|████                                      | 11/114 [00:00<00:01, 89.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                   | 0/114 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  8%|███▍                                       | 9/114 [00:00<00:01, 83.90it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 25%|██████████▍                              | 29/114 [00:00<00:00, 129.08it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████                                      | 11/114 [00:00<00:01, 91.66it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 28%|███████████▌                             | 32/114 [00:00<00:00, 138.06it/s]\u001b[A\n",
      "\n",
      "\n",
      " 19%|███████▉                                 | 22/114 [00:00<00:00, 106.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 19%|████████                                  | 22/114 [00:00<00:00, 93.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|███▉                                     | 11/114 [00:00<00:00, 107.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 16%|██████▋                                   | 18/114 [00:00<00:01, 85.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▊                              | 30/114 [00:00<00:00, 141.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 37%|███████████████                          | 42/114 [00:00<00:00, 116.76it/s]\u001b[A\n",
      "\n",
      "\n",
      " 29%|███████████▊                             | 33/114 [00:00<00:00, 101.16it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 28%|███████████▊                              | 32/114 [00:00<00:00, 94.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 27%|███████████▏                             | 31/114 [00:00<00:00, 160.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████                               | 30/114 [00:00<00:00, 96.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 41%|████████████████▉                        | 47/114 [00:00<00:00, 152.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 47%|███████████████████▍                     | 54/114 [00:00<00:00, 104.52it/s]\u001b[A\n",
      "\n",
      "\n",
      " 39%|████████████████▏                         | 44/114 [00:00<00:00, 93.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████                           | 41/114 [00:00<00:00, 97.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 42%|█████████████████▎                       | 48/114 [00:00<00:00, 141.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 37%|███████████████▍                          | 42/114 [00:00<00:00, 82.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 59%|████████████████████████                 | 67/114 [00:00<00:00, 169.50it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████▎                     | 55/114 [00:00<00:00, 95.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 45%|██████████████████▊                       | 51/114 [00:00<00:00, 95.73it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|███████████████████████▉                  | 65/114 [00:00<00:00, 95.13it/s]\u001b[A\n",
      "\n",
      " 48%|████████████████████▎                     | 55/114 [00:00<00:00, 96.11it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 58%|███████████████████████▋                 | 66/114 [00:00<00:00, 147.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|██████████████████████████████▌          | 85/114 [00:00<00:00, 157.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 58%|████████████████████████▎                 | 66/114 [00:00<00:00, 98.81it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 60%|████████████████████████▍                | 68/114 [00:00<00:00, 106.14it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 54%|██████████████████████▍                   | 61/114 [00:00<00:00, 91.27it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 66%|███████████████████████████▋              | 75/114 [00:00<00:00, 90.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 77%|███████████████████████████████▋         | 88/114 [00:00<00:00, 103.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 89%|███████████████████████████████████▊    | 102/114 [00:00<00:00, 143.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 68%|████████████████████████████             | 78/114 [00:00<00:00, 105.08it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████████████████████████████▎          | 85/114 [00:00<00:00, 92.46it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|██████████████████████████████████▌      | 96/114 [00:00<00:00, 130.75it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 87%|████████████████████████████████████▍     | 99/114 [00:00<00:00, 99.74it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 62%|██████████████████████████▏               | 71/114 [00:00<00:00, 75.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 138.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 82%|█████████████████████████████████▍       | 93/114 [00:00<00:00, 110.70it/s]\u001b[A\u001b[A\n",
      " 83%|███████████████████████████████████       | 95/114 [00:00<00:00, 87.33it/s]\n",
      " 98%|███████████████████████████████████████▎| 112/114 [00:00<00:00, 107.21it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 138.58it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|████████████████████████████████████████| 114/114 [00:00<00:00, 114.93it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 71%|█████████████████████████████▊            | 81/114 [00:00<00:00, 80.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 94%|██████████████████████████████████████▍  | 107/114 [00:01<00:00, 93.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:01<00:00, 105.58it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|████████████████████████████████████████| 114/114 [00:01<00:00, 100.35it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|█████████████████████████████████████████| 114/114 [00:01<00:00, 96.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|████████████████████████████████████▍     | 99/114 [00:01<00:00, 84.51it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|█████████████████████████████████████████| 114/114 [00:01<00:00, 89.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_transcribe.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_transform.tsv\n",
      "Processing Started...\n",
      "Data Size:  375\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 21%|████████▉                                  | 11/53 [00:00<00:00, 72.73it/s]\n",
      " 19%|████████                                   | 10/53 [00:00<00:00, 83.60it/s]\u001b[A\n",
      "\n",
      " 15%|██████▋                                     | 8/53 [00:00<00:00, 76.58it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 57%|███████████████████████▊                  | 30/53 [00:00<00:00, 129.12it/s]\n",
      " 40%|█████████████████                          | 21/53 [00:00<00:00, 95.65it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 38%|████████████████▏                          | 20/53 [00:00<00:00, 99.22it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 100.87it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 85%|███████████████████████████████████▋      | 45/53 [00:00<00:00, 130.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 60%|█████████████████████████▎                | 32/53 [00:00<00:00, 101.16it/s]\u001b[A\n",
      "\n",
      " 60%|█████████████████████████▎                | 32/53 [00:00<00:00, 105.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 129.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 106.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 42%|█████████████████▊                         | 22/53 [00:00<00:00, 96.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 47%|███████████████████▊                      | 25/53 [00:00<00:00, 113.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████████        | 43/53 [00:00<00:00, 100.45it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 43%|██████████████████▏                       | 23/53 [00:00<00:00, 112.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 81%|██████████████████████████████████▉        | 43/53 [00:00<00:00, 98.80it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▎                | 32/53 [00:00<00:00, 160.59it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▉                 | 32/53 [00:00<00:00, 95.71it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 53/53 [00:00<00:00, 98.46it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 131.30it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▍         | 41/53 [00:00<00:00, 137.04it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 94%|███████████████████████████████████████▌  | 50/53 [00:00<00:00, 167.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|███████████████████████████████████████████| 53/53 [00:00<00:00, 95.56it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 134.68it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 53/53 [00:00<00:00, 87.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_transform.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_transform.tsv\n",
      "Processing Started...\n",
      "Data Size:  377\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 28%|███████████▉                              | 15/53 [00:00<00:00, 147.35it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 102.61it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 21%|████████▋                                 | 11/53 [00:00<00:00, 103.97it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      " 19%|████████                                   | 10/53 [00:00<00:00, 94.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/53 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 34%|██████████████▎                           | 18/53 [00:00<00:00, 178.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 49%|████████████████████▌                     | 26/53 [00:00<00:00, 126.83it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 20/53 [00:00<00:00, 181.24it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 49%|████████████████████▌                     | 26/53 [00:00<00:00, 123.37it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|█████████████████                          | 21/53 [00:00<00:00, 98.09it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|███████████                               | 14/53 [00:00<00:00, 137.32it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 167.67it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 75%|███████████████████████████████▋          | 40/53 [00:00<00:00, 188.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 74%|██████████████████████████████▉           | 39/53 [00:00<00:00, 124.01it/s]\u001b[A\u001b[A\n",
      " 74%|██████████████████████████████▉           | 39/53 [00:00<00:00, 114.27it/s]\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 178.21it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 180.56it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 128.52it/s]\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 117.77it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 170.14it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 53/53 [00:00<00:00, 112.65it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_transform.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_translate.tsv\n",
      "Processing Started...\n",
      "Data Size:  678\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 14%|█████▋                                    | 13/96 [00:00<00:00, 117.76it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 14%|█████▋                                    | 13/96 [00:00<00:00, 122.76it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      " 12%|█████▎                                    | 12/96 [00:00<00:00, 112.37it/s]\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 11%|████▊                                     | 11/96 [00:00<00:00, 107.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|████▍                                      | 10/96 [00:00<00:00, 96.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▎                             | 28/96 [00:00<00:00, 130.36it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 28%|███████████▊                              | 27/96 [00:00<00:00, 130.35it/s]\u001b[A\u001b[A\n",
      "  8%|███▋                                        | 8/96 [00:00<00:01, 78.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 23%|█████████▊                                 | 22/96 [00:00<00:00, 97.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|██▊                                         | 6/96 [00:00<00:01, 58.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 17%|███████▏                                   | 16/96 [00:00<00:01, 66.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|██████████████████▊                       | 43/96 [00:00<00:00, 139.30it/s]\u001b[A\u001b[A\n",
      " 44%|██████████████████▍                       | 42/96 [00:00<00:00, 112.12it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 36/96 [00:00<00:00, 113.25it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 26%|██████████▉                               | 25/96 [00:00<00:00, 134.01it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 21%|████████▉                                  | 20/96 [00:00<00:01, 55.15it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 29%|████████████▌                              | 28/96 [00:00<00:00, 84.94it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 57%|████████████████████████                  | 55/96 [00:00<00:00, 113.98it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 51%|█████████████████████▍                    | 49/96 [00:00<00:00, 119.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 43%|█████████████████▉                        | 41/96 [00:00<00:00, 145.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 59%|████████████████████████▉                 | 57/96 [00:00<00:00, 122.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 29%|████████████▌                              | 28/96 [00:00<00:01, 63.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▌                          | 37/96 [00:00<00:00, 84.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 78%|████████████████████████████████▊         | 75/96 [00:00<00:00, 151.56it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▍                | 58/96 [00:00<00:00, 154.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▎            | 67/96 [00:00<00:00, 106.31it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 46%|███████████████████▋                       | 44/96 [00:00<00:00, 77.74it/s]\u001b[A\u001b[A\u001b[A\n",
      " 95%|███████████████████████████████████████▊  | 91/96 [00:00<00:00, 132.48it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 48%|████████████████████▌                      | 46/96 [00:00<00:00, 68.68it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 77%|████████████████████████████████▍         | 74/96 [00:00<00:00, 129.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 126.38it/s]\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 78/96 [00:00<00:00, 86.51it/s]\n",
      "\n",
      "\n",
      " 56%|████████████████████████▏                  | 54/96 [00:00<00:00, 82.47it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 84%|███████████████████████████████████▍      | 81/96 [00:00<00:00, 101.63it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 110.88it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 66%|████████████████████████████▏              | 63/96 [00:00<00:00, 83.28it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 92%|██████████████████████████████████████▌   | 88/96 [00:00<00:00, 109.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 100.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 105.58it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 118.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 75%|████████████████████████████████▎          | 72/96 [00:00<00:00, 83.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 84%|████████████████████████████████████▎      | 81/96 [00:00<00:00, 99.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 88.74it/s]\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 91.35it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_translate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_translate.tsv\n",
      "Processing Started...\n",
      "Data Size:  678\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  8%|███▋                                        | 8/96 [00:00<00:01, 68.23it/s]\n",
      "  4%|█▊                                          | 4/96 [00:00<00:02, 36.14it/s]\u001b[A\n",
      "\n",
      "  2%|▉                                           | 2/96 [00:00<00:05, 18.30it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 18%|███████▌                                   | 17/96 [00:00<00:01, 77.91it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      " 11%|████▉                                      | 11/96 [00:00<00:01, 42.79it/s]\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 10%|████▍                                      | 10/96 [00:00<00:00, 89.57it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/96 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 11%|████▉                                      | 11/96 [00:00<00:01, 78.37it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      " 26%|███████████▏                               | 25/96 [00:00<00:01, 70.18it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  7%|███▏                                        | 7/96 [00:00<00:01, 66.47it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 17%|███████▏                                   | 16/96 [00:00<00:01, 48.14it/s]\u001b[A\u001b[A\n",
      " 24%|██████████▎                                | 23/96 [00:00<00:01, 72.27it/s]\u001b[A\n",
      "\n",
      "\n",
      " 26%|██████████▉                               | 25/96 [00:00<00:00, 105.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 34%|██████████████▊                            | 33/96 [00:00<00:00, 72.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 25%|██████████▊                                | 24/96 [00:00<00:01, 58.84it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▋                           | 35/96 [00:00<00:00, 88.22it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 38%|███████████████▊                          | 36/96 [00:00<00:00, 106.88it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 28%|████████████                               | 27/96 [00:00<00:00, 77.72it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 45%|███████████████████▎                       | 43/96 [00:00<00:00, 79.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 33%|██████████████▎                            | 32/96 [00:00<00:00, 65.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 36%|███████████████▎                          | 35/96 [00:00<00:00, 112.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 52%|█████████████████████▉                    | 50/96 [00:00<00:00, 106.26it/s]\u001b[A\n",
      "\n",
      "\n",
      " 51%|█████████████████████▍                    | 49/96 [00:00<00:00, 114.30it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 39%|████████████████▌                          | 37/96 [00:00<00:00, 85.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 56%|████████████████████████▏                  | 54/96 [00:00<00:00, 88.33it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 53%|██████████████████████▎                   | 51/96 [00:00<00:00, 129.99it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 45%|███████████████████▎                       | 43/96 [00:00<00:00, 77.23it/s]\u001b[A\u001b[A\n",
      " 68%|████████████████████████████▍             | 65/96 [00:00<00:00, 118.73it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 50%|█████████████████████▌                     | 48/96 [00:00<00:00, 91.79it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▎            | 67/96 [00:00<00:00, 127.10it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 73%|██████████████████████████████▋           | 70/96 [00:00<00:00, 109.21it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████▏           | 69/96 [00:00<00:00, 147.28it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 55%|███████████████████████▋                   | 53/96 [00:00<00:00, 84.13it/s]\u001b[A\u001b[A\n",
      " 81%|██████████████████████████████████▏       | 78/96 [00:00<00:00, 116.35it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 60%|█████████████████████████▉                 | 58/96 [00:00<00:00, 91.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 86%|████████████████████████████████████▎     | 83/96 [00:00<00:00, 114.27it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 65%|███████████████████████████▊               | 62/96 [00:00<00:00, 84.78it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 88%|████████████████████████████████████▊     | 84/96 [00:00<00:00, 131.09it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 54%|███████████████████████▎                   | 52/96 [00:00<00:00, 79.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 90.79it/s]\u001b[A\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 91.14it/s]\n",
      "\n",
      "\n",
      " 74%|███████████████████████████████▊           | 71/96 [00:01<00:00, 69.52it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 71%|██████████████████████████████▍            | 68/96 [00:00<00:00, 67.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 97%|█████████████████████████████████████████▋ | 93/96 [00:00<00:00, 91.61it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 96/96 [00:00<00:00, 108.91it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 96/96 [00:00<00:00, 98.37it/s]\n",
      "\n",
      "\n",
      " 82%|███████████████████████████████████▍       | 79/96 [00:01<00:00, 68.53it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      " 79%|██████████████████████████████████         | 76/96 [00:01<00:00, 64.38it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 72%|██████████████████████████████▉            | 69/96 [00:00<00:00, 69.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 99%|██████████████████████████████████████████▌| 95/96 [00:01<00:00, 89.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 73.83it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 86.52it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 96/96 [00:01<00:00, 76.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_translate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testa_truncate.tsv\n",
      "Processing Started...\n",
      "Data Size:  161\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 94.77it/s]/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 97.39it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 93.33it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 87%|█████████████████████████████████████▍     | 20/23 [00:00<00:00, 94.90it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 114.65it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 92.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 115.62it/s]\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 96.90it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 98.26it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 114.05it/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 84.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_truncate.json\n",
      "Loading raw data for task conllsrl from ../data/coNLL_tsv/ner_coNLL_testb_truncate.tsv\n",
      "Processing Started...\n",
      "Data Size:  161\n",
      "number of threads:  7\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 43%|██████████████████▋                        | 10/23 [00:00<00:00, 76.29it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|                                                    | 0/23 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      " 39%|█████████████████▏                          | 9/23 [00:00<00:00, 81.59it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 48%|████████████████████                      | 11/23 [00:00<00:00, 102.04it/s]\u001b[A\u001b[A\u001b[ATruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 35%|███████████████▎                            | 8/23 [00:00<00:00, 71.42it/s]\u001b[A\u001b[A\u001b[A\u001b[A/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "\n",
      " 96%|█████████████████████████████████████████▏ | 22/23 [00:00<00:00, 96.93it/s]\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 99.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 89.19it/s]\n",
      "\n",
      "\n",
      " 91%|██████████████████████████████████████▎   | 21/23 [00:00<00:00, 103.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 102.83it/s]\n",
      " 22%|█████████▌                                  | 5/23 [00:00<00:00, 42.55it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "100%|██████████████████████████████████████████| 23/23 [00:00<00:00, 103.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 70%|█████████████████████████████▉             | 16/23 [00:00<00:00, 70.43it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 65%|████████████████████████████               | 15/23 [00:00<00:00, 70.48it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 73.02it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 71.27it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "100%|███████████████████████████████████████████| 23/23 [00:00<00:00, 72.39it/s]\n",
      "Data Processing done for conllsrl. File saved at ../data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testb_truncate.json\n"
     ]
    }
   ],
   "source": [
    "#!python ../data_preparation.py --task_file 'tasks_file_SRL.yml' --data_dir 'coNLL_data' --max_seq_len 50\n",
    "!python ../data_preparation.py --task_file tasks_file_SRL.yml --data_dir ../data/coNLL_tsv --max_seq_len 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train.py \\\n",
    "    --data_dir 'content/data/bert-base-uncased_prepared_data' \\\n",
    "    --task_file 'tasks_file_SRL.yml' \\\n",
    "    --out_dir 'conll_ner_pos_bert_base' \\\n",
    "    --epochs 10 \\\n",
    "    --train_batch_size 32 \\\n",
    "    --eval_batch_size 32 \\\n",
    "    --grad_accumulation_steps 1 \\\n",
    "    --log_per_updates 50 \\\n",
    "    --max_seq_len 50 \\\n",
    "    --eval_while_train \\\n",
    "    --test_while_train \\\n",
    "    --silent\n",
    "    \n",
    "# python ../train.py --data_dir ../data/coNLL_tsv/bert-base-uncased_prepared_data --task_file tasks_file_SRL.yml --out_dir ../output/ --epochs 10 --train_batch_size 32 --eval_batch_size 32 --grad_accumulation_steps 32 --log_per_updates 50 --max_seq_len 50 --eval_while_train --test_while_train --silent\n",
    "\n",
    "# python ./train.py --data_dir ./data/coNLL_tsv/bert-base-uncased_prepared_data --task_file tasks_file_SRL.yml --out_dir ../output/ --epochs 10 --train_batch_size 32 --eval_batch_size 32 --grad_accumulation_steps 32 --log_per_updates 50 --max_seq_len 50 --eval_while_train --test_while_train --silent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python ../train.py --data_dir ../data/coNLL_tsv/dmis-lab/biobert-base-cased-v1.2_prepared_data --task_file tasks_file_SRL.yml --out_dir ../output/ --epochs 10 --train_batch_size 32 --eval_batch_size 32 --grad_accumulation_steps 32 --log_per_updates 50 --max_seq_len 50 --eval_while_train --test_while_train --silent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from infer_pipeline import inferPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "pipe = inferPipeline(modelPath='../output/multi_task_model_9_204.pt', maxSeqLen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'embedding.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# run embedding from original biobert (cha duoi terminal)\n",
    "!python embedding.py --data_dir ./data/coNLL_tsv/bert-base-uncased_prepared_data --transform_file word_represent/embedding.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
