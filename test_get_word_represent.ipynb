{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## calculate f1 score\n"
      ],
      "metadata": {
        "id": "eOYt_7ZcnOq7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCyN0fe-2gh4",
        "outputId": "20be8f01-52b7-4268-924b-4ba0f2261263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data: type: <class 'list'>\n",
            "prediction: ['O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', '[CLS]', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "label: ['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-A2', 'I-A2', 'O', 'B-A1', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\n",
            "lineTok: ['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-A2', 'I-A2', 'O', 'B-A1', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\n",
            "lineLab: ['O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', '[CLS]', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "prediction_new: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "label_new: ['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-A2', 'I-A2', 'O', 'O', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\n",
            "new1: [['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-A2', 'I-A2', 'O', 'O', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']]\n",
            "result_f1: 0.75\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import ast\n",
        "\n",
        "\n",
        "data=[]\n",
        "prediction_new = []\n",
        "label_new = []\n",
        "\n",
        "# Read the file and extract the prediction and label columns\n",
        "line = \"17625\t['O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', '[CLS]', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O']\t['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-A2', 'I-A2', 'O', 'B-A1', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\"\n",
        "\n",
        "\n",
        "uid, prediction, label = line.strip().split(\"\\t\")\n",
        "data.append((prediction.strip(\"[]\"), label.strip(\"[]\")))\n",
        "\n",
        "print(f\"data: type: {type(data)}\")\n",
        "print(f\"prediction: {prediction}\")\n",
        "print(f\"label: {label}\")\n",
        "# convert list to string\n",
        "predictions_data = [d[0] for d in data]\n",
        "labels_data = [d[1] for d in data]\n",
        "\n",
        "lineTok = ast.literal_eval(label)\n",
        "lineLab = ast.literal_eval(prediction)\n",
        "\n",
        "print(f\"lineTok: {lineTok}\")\n",
        "print(f\"lineLab: {lineLab}\")\n",
        "for (Tok, Lab) in zip(lineTok, lineLab):\n",
        "\n",
        "    if Lab in ['[CLS]','[SEP]', 'X']: # replace non-text tokens with O. These will not be evaluated.\n",
        "        prediction_new.append('O')\n",
        "        label_new.append('O')\n",
        "        continue\n",
        "    if(Lab == \"B-V\"):\n",
        "        prediction_new.append(\"V\")\n",
        "    else:\n",
        "        prediction_new.append(Lab)\n",
        "        label_new.append(Tok)\n",
        "\n",
        "print(f\"prediction_new: {prediction_new}\")\n",
        "print(f\"label_new: {label_new}\")\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.metrics import recall_score as class_recall_score\n",
        "\n",
        "new1 = [label_new]\n",
        "print(f\"new1: {new1}\")\n",
        "new2 = [prediction_new]\n",
        "\n",
        "result_f1 = f1_score(label_new, prediction_new,average=\"micro\")\n",
        "\n",
        "print(f\"result_f1: {result_f1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KTEOLJG2gh8"
      },
      "outputs": [],
      "source": [
        "data = []\n",
        "labels = []\n",
        "predictions = []\n",
        "\n",
        "filePath = \"./output/conllsrl_test_predictions_29.tsv\"\n",
        "with open(filePath, \"r\") as f:\n",
        "    for line in f:\n",
        "        # delete the first line\n",
        "        if \"uid\" in line:\n",
        "            continue\n",
        "        uid, prediction, label = line.strip().split(\"\\t\")\n",
        "        labels.append(label)\n",
        "        predictions.append(prediction)\n",
        "        data.append((prediction.strip(\"[]\"), label.strip(\"[]\")))\n",
        "\n",
        "print(\"prediction: \", type(data))\n",
        "# apply this conversion to all the elements in the list\n",
        "lineToks = [ast.literal_eval(label) for label in labels]\n",
        "lineLabs = [ast.literal_eval(prediction) for prediction in predictions]\n",
        "\n",
        "trueLabels = [] # labels\n",
        "predictLabels = [] # predictions\n",
        "\n",
        "for lineTok, lineLab in zip(lineToks, lineLabs):\n",
        "    if lineLab in ['[CLS]','[SEP]', 'X']: # replace non-text tokens with O. These will not be evaluated.\n",
        "        predictLabels.append('O')\n",
        "        trueLabels.append('O')\n",
        "        continue\n",
        "    if(lineLab == \"B-V\"):\n",
        "        predictLabels.append(\"V\")\n",
        "    else:\n",
        "        predictLabels.append(lineLab)\n",
        "        trueLabels.append(lineTok)\n",
        "\n",
        "# flatten the list of lists into a single list\n",
        "trueLabels = [item for sublist in trueLabels for item in sublist]\n",
        "predictLabels = [item for sublist in predictLabels for item in sublist]\n",
        "\n",
        "result_f1 = f1_score(trueLabels, predictLabels,average=\"micro\")\n",
        "\n",
        "print(f\"result_f1: {result_f1}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zoRdkGZ2gh8"
      },
      "source": [
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXi3test2giA"
      },
      "source": [
        "##test original model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "\n",
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "import logging\n",
        "#logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# dmis-lab/biobert-base-cased-v1.2\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=True,truncation=True)"
      ],
      "metadata": {
        "id": "1iAWCwPKnw54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KgEnfAgw2giA",
        "outputId": "0cd777f2-631e-409c-d8b6-2f24c6919bb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('bert-base-uncased',\n",
        "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        "                                  )\n",
        "\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGnSsgem2giA",
        "outputId": "85cb4a74-3523-473b-92a1-275cab350c02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
              "          [-0.2659,  0.0911, -0.2904,  ..., -0.0518,  0.2286, -0.0701],\n",
              "          [-0.1257, -0.1021,  0.0349,  ..., -0.6787,  0.5009,  0.8158],\n",
              "          ...,\n",
              "          [ 0.7358,  0.3943,  0.0779,  ..., -0.6939, -0.3449, -0.0302],\n",
              "          [ 0.0593, -0.3172,  0.0352,  ...,  0.1207, -0.4333, -0.0917],\n",
              "          [-0.4895,  0.1848,  0.3578,  ..., -0.3979, -0.0418, -0.2135]]]),\n",
              " tensor([[[ 0.1778,  0.0206,  0.0094,  ..., -0.0476,  0.1028,  0.1027],\n",
              "          [-0.0802,  0.1250, -0.0769,  ...,  0.0508,  0.6060, -0.4218],\n",
              "          [ 0.0118,  0.0407, -0.3726,  ..., -0.9866,  0.8263,  0.6549],\n",
              "          ...,\n",
              "          [ 1.3002,  0.2144,  0.6183,  ..., -0.4371, -0.7979, -0.0119],\n",
              "          [ 0.0541, -0.2116,  0.2216,  ...,  0.2839, -0.3027, -0.3254],\n",
              "          [-0.2223,  0.1883,  0.2541,  ..., -0.5151,  0.3750, -0.1689]]]),\n",
              " tensor([[[ 0.1000, -0.2102, -0.0491,  ..., -0.0036, -0.0153,  0.0920],\n",
              "          [ 0.1070,  0.0310, -0.0383,  ...,  0.1757,  0.5379, -0.5025],\n",
              "          [-0.4677, -0.1140, -0.6522,  ..., -0.6893,  0.5559,  0.6513],\n",
              "          ...,\n",
              "          [ 1.4899,  0.2015,  0.2708,  ..., -0.4878, -0.8894,  0.1279],\n",
              "          [-0.2356, -0.3374,  0.2868,  ...,  0.4137, -0.3636, -0.1264],\n",
              "          [-0.2123, -0.1183,  0.2831,  ..., -0.2227,  0.3136, -0.2272]]]),\n",
              " tensor([[[ 0.0913, -0.1521,  0.0206,  ...,  0.0441,  0.0177,  0.1688],\n",
              "          [ 0.2949, -0.2286,  0.0739,  ...,  0.3620,  0.4095, -0.4206],\n",
              "          [-0.5660,  0.0311, -0.4741,  ..., -0.6570,  0.2359,  0.3800],\n",
              "          ...,\n",
              "          [ 1.6304,  0.0805,  0.3639,  ...,  0.1897, -0.7057, -0.1135],\n",
              "          [-0.5962, -0.5119,  0.4456,  ...,  0.2535, -0.3452, -0.3619],\n",
              "          [-0.0840, -0.0748,  0.1502,  ...,  0.0036,  0.0364, -0.0296]]]),\n",
              " tensor([[[ 0.1308, -0.4171, -0.2265,  ...,  0.0093,  0.1710,  0.4688],\n",
              "          [ 0.7472, -0.6520, -0.1213,  ...,  0.4984,  0.5750, -0.5272],\n",
              "          [-0.4281, -0.1668, -0.6851,  ..., -0.5059,  0.2981,  0.1352],\n",
              "          ...,\n",
              "          [ 1.5880,  0.4639,  0.9496,  ..., -0.2060, -0.3216,  0.1162],\n",
              "          [-0.9922, -0.9053,  0.5452,  ..., -0.5974, -0.4009, -0.3770],\n",
              "          [-0.0496, -0.0633,  0.0282,  ..., -0.0344,  0.0543,  0.0094]]]),\n",
              " tensor([[[-0.0401, -0.6772, -0.2631,  ..., -0.1030,  0.1882,  0.5832],\n",
              "          [ 0.5853, -0.2338, -0.4639,  ...,  0.5538,  0.8530, -0.0719],\n",
              "          [-0.1421,  0.2495, -0.6938,  ..., -0.7652,  0.3814,  0.1770],\n",
              "          ...,\n",
              "          [ 1.3585,  0.5003,  0.4463,  ...,  0.2012, -0.2145, -0.2209],\n",
              "          [-1.2394, -1.1005, -0.0339,  ..., -0.4816,  0.0291, -0.2719],\n",
              "          [-0.0261, -0.0508,  0.0321,  ...,  0.0149,  0.0094, -0.0249]]]),\n",
              " tensor([[[-0.0022, -0.7320, -0.5563,  ..., -0.2419, -0.0488,  0.6129],\n",
              "          [ 0.4891, -0.1354,  0.0799,  ...,  0.3091,  0.5820,  0.1732],\n",
              "          [-0.0553,  0.2430, -0.6071,  ..., -0.6998,  0.1863,  0.4275],\n",
              "          ...,\n",
              "          [ 1.4751,  0.2119,  0.0343,  ...,  0.2152, -0.0498, -0.0389],\n",
              "          [-1.0641, -0.7787,  0.1300,  ..., -0.9448,  0.0993, -0.1893],\n",
              "          [ 0.0137, -0.0488,  0.0087,  ...,  0.0038, -0.0285, -0.0387]]]),\n",
              " tensor([[[-0.4215, -0.6558, -0.4080,  ...,  0.2058,  0.1265,  0.6528],\n",
              "          [ 0.4407,  0.1792,  0.1771,  ...,  0.3474,  0.3758,  0.3490],\n",
              "          [-0.1292,  0.5487, -0.2287,  ..., -0.6784,  0.3514,  0.3932],\n",
              "          ...,\n",
              "          [ 1.2759, -0.0954,  0.7991,  ...,  0.3725,  0.2268, -0.1196],\n",
              "          [-1.3146, -1.1533,  0.1938,  ..., -0.7630,  0.3502, -0.0445],\n",
              "          [ 0.0213, -0.0171,  0.0328,  ..., -0.0043,  0.0215, -0.0388]]]),\n",
              " tensor([[[-6.2872e-01, -9.5742e-01, -3.6671e-01,  ..., -5.3258e-02,\n",
              "           -8.3488e-02,  6.7811e-01],\n",
              "          [ 2.2675e-01,  1.1865e-01,  3.0752e-01,  ..., -3.8185e-04,\n",
              "            3.2448e-01,  5.2462e-01],\n",
              "          [ 5.2309e-02,  3.3923e-01, -3.2009e-01,  ..., -9.4057e-01,\n",
              "           -9.4748e-02,  4.9101e-01],\n",
              "          ...,\n",
              "          [ 9.7363e-01, -5.1410e-01,  4.9835e-01,  ...,  4.5157e-01,\n",
              "            2.3260e-01, -7.4291e-02],\n",
              "          [-1.6793e+00, -1.3679e+00, -1.4466e-01,  ..., -3.4760e-01,\n",
              "           -1.1710e-01,  3.8453e-01],\n",
              "          [ 1.1299e-02, -5.4262e-02,  6.1458e-02,  ..., -3.5914e-02,\n",
              "           -2.2708e-02, -6.6156e-02]]]),\n",
              " tensor([[[-8.6242e-01, -5.2936e-01, -3.9180e-01,  ..., -2.4324e-01,\n",
              "           -6.4761e-02,  3.9209e-01],\n",
              "          [-3.5406e-04, -1.3004e-01,  3.1452e-02,  ..., -3.6318e-01,\n",
              "            5.0899e-01,  4.0565e-01],\n",
              "          [ 5.1928e-02,  4.0393e-01, -3.8411e-01,  ..., -9.6746e-01,\n",
              "           -7.9551e-02,  2.1188e-01],\n",
              "          ...,\n",
              "          [ 7.6887e-01, -3.9365e-01,  3.3451e-01,  ...,  2.8272e-01,\n",
              "           -1.3738e-01, -1.7344e-01],\n",
              "          [-1.5394e+00, -1.2286e+00, -6.3953e-01,  ..., -4.2061e-01,\n",
              "           -8.1443e-02,  2.4542e-01],\n",
              "          [ 4.1034e-02, -4.4493e-03,  1.2100e-02,  ..., -9.1969e-02,\n",
              "           -7.9203e-02, -2.3721e-02]]]),\n",
              " tensor([[[-1.1514, -0.5259, -0.1192,  ..., -0.2088, -0.1232,  0.3985],\n",
              "          [-0.2426, -0.4775,  0.0828,  ..., -0.3819,  0.5210,  0.4782],\n",
              "          [ 0.0374,  0.3941, -0.0896,  ..., -0.7586, -0.0356,  0.1636],\n",
              "          ...,\n",
              "          [ 0.4842, -0.5226,  0.3116,  ...,  0.4109, -0.1251,  0.0495],\n",
              "          [-1.2405, -1.0392, -0.2224,  ..., -0.1516,  0.0933,  0.6412],\n",
              "          [-0.0053,  0.0219, -0.0689,  ...,  0.0448, -0.0341,  0.0050]]]),\n",
              " tensor([[[-0.8665, -0.3595, -0.0880,  ..., -0.1060, -0.1043,  0.4725],\n",
              "          [-0.1574, -0.4977, -0.2502,  ..., -0.6825,  0.0433,  1.0496],\n",
              "          [ 0.2523,  0.5281, -0.2205,  ..., -0.5759, -0.2972,  0.3076],\n",
              "          ...,\n",
              "          [ 0.3775, -0.2958,  0.1795,  ...,  0.2023, -0.2887,  0.2988],\n",
              "          [-0.7912, -0.9862, -0.3685,  ...,  0.1868, -0.0372,  0.4220],\n",
              "          [ 0.0238,  0.0193, -0.0410,  ...,  0.0264, -0.0201,  0.0124]]]),\n",
              " tensor([[[-0.4771,  0.0626, -0.0724,  ...,  0.1989,  0.2751,  0.5593],\n",
              "          [-0.2376, -0.2702, -0.1184,  ..., -0.1776,  0.3517,  0.6783],\n",
              "          [-0.0287,  0.3490, -0.1473,  ..., -0.0835,  0.0473,  0.3525],\n",
              "          ...,\n",
              "          [ 0.0606, -0.1812,  0.0246,  ...,  0.1825, -0.0116,  0.4373],\n",
              "          [-0.3593, -0.4834, -0.2196,  ...,  0.3202,  0.3126,  0.2966],\n",
              "          [ 0.2160,  0.2671, -0.2992,  ...,  0.5929, -0.4620,  0.0946]]]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    outputs2 = model(tokens_tensor2, segments_tensors2)\n",
        "    hidden_states = outputs[2]\n",
        "    hidden_states2 = outputs2[2]\n",
        "outputs.hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBpssiG_2giB"
      },
      "outputs": [],
      "source": [
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "token_embeddings2 = torch.stack(hidden_states2, dim=0)\n",
        "\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings2 = torch.squeeze(token_embeddings2, dim=1)\n",
        "# Swap dimensions 0 and 1.\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "token_embeddings2 = token_embeddings2.permute(1,0,2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MVBzRbX2giB"
      },
      "outputs": [],
      "source": [
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat = []\n",
        "token_vecs_cat2 = []\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last\n",
        "    # four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "\n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "for token in token_embeddings2:\n",
        "    cat_vec2 = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "    token_vecs_cat2.append(cat_vec2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cv8bg9hl2giB"
      },
      "source": [
        "## test cosine similarity\n",
        "\n",
        "```python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWo0QJkV2giB"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity_2_tensors(tensor1, tensor2):\n",
        "\n",
        "    # Compute the dot product\n",
        "    dot_product = torch.dot(tensor1, tensor2)\n",
        "\n",
        "    # Compute the L2 (Euclidean) norms\n",
        "    norm_tensor1 = torch.norm(tensor1)\n",
        "    norm_tensor2 = torch.norm(tensor2)\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = dot_product / (norm_tensor1 * norm_tensor2)\n",
        "\n",
        "    return similarity\n",
        "\n",
        "def cosine_similarity(sen1, sen2):\n",
        "    assert len(sen1) == len(sen2), \"Sentence lengths are not equal\"\n",
        "\n",
        "    res_vec = []\n",
        "    for word in range(len(sen1)):\n",
        "        res_vec.append(cosine_similarity_2_tensors(sen1[word], sen2[word]))\n",
        "    return res_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEgdiJGP2giC",
        "outputId": "53f4952e-62d5-413b-a10d-7fcc5135fd19"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(0.9724),\n",
              " tensor(0.9487),\n",
              " tensor(0.9855),\n",
              " tensor(0.9867),\n",
              " tensor(0.9746),\n",
              " tensor(0.9765),\n",
              " tensor(0.9757),\n",
              " tensor(0.9840),\n",
              " tensor(0.9805),\n",
              " tensor(0.9894),\n",
              " tensor(0.9533),\n",
              " tensor(0.9677),\n",
              " tensor(0.9812),\n",
              " tensor(0.9790),\n",
              " tensor(0.9275),\n",
              " tensor(0.9729),\n",
              " tensor(0.9666),\n",
              " tensor(0.9850),\n",
              " tensor(0.9230),\n",
              " tensor(0.5345),\n",
              " tensor(0.9140),\n",
              " tensor(0.9237),\n",
              " tensor(0.6716),\n",
              " tensor(0.6131),\n",
              " tensor(0.5775),\n",
              " tensor(0.5866),\n",
              " tensor(0.5695),\n",
              " tensor(0.8508),\n",
              " tensor(0.9433),\n",
              " tensor(0.9849)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_similarity_res = cosine_similarity(token_vecs_cat, token_vecs_cat2)\n",
        "cosine_similarity_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zutRSstp2giC"
      },
      "source": [
        "## test cosine module similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URyA5uED2giC"
      },
      "outputs": [],
      "source": [
        "def cosine_module_2_tensors(tensor1, tensor2):\n",
        "    cosine = cosine_similarity_2_tensors(tensor1, tensor2)\n",
        "    module = 1 - torch.abs(torch.norm(tensor1) - torch.norm(tensor2))/(torch.norm(tensor1) + torch.norm(tensor2))\n",
        "\n",
        "    cosine_module = 1/2 * (cosine + module)\n",
        "\n",
        "    return cosine_module\n",
        "\n",
        "def cosine_module(sen1, sen2):\n",
        "    assert len(sen1) == len(sen2), \"Sentence lengths are not equal\"\n",
        "\n",
        "    res_vec = []\n",
        "    for word in range(len(sen1)):\n",
        "        res_vec.append(cosine_module_2_tensors(sen1[word], sen2[word]))\n",
        "    return res_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2Ge9ugc2giC",
        "outputId": "91d96794-f84f-436a-cdb6-6e1116978464"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor(0.9729),\n",
              " tensor(0.9686),\n",
              " tensor(0.9924),\n",
              " tensor(0.9926),\n",
              " tensor(0.9818),\n",
              " tensor(0.9778),\n",
              " tensor(0.9816),\n",
              " tensor(0.9894),\n",
              " tensor(0.9820),\n",
              " tensor(0.9931),\n",
              " tensor(0.9692),\n",
              " tensor(0.9798),\n",
              " tensor(0.9903),\n",
              " tensor(0.9868),\n",
              " tensor(0.9493),\n",
              " tensor(0.9828),\n",
              " tensor(0.9830),\n",
              " tensor(0.9907),\n",
              " tensor(0.9526),\n",
              " tensor(0.6996),\n",
              " tensor(0.9545),\n",
              " tensor(0.9525),\n",
              " tensor(0.8316),\n",
              " tensor(0.7971),\n",
              " tensor(0.7316),\n",
              " tensor(0.7650),\n",
              " tensor(0.7807),\n",
              " tensor(0.9096),\n",
              " tensor(0.9647),\n",
              " tensor(0.9920)]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cosine_module_res = cosine_module(token_vecs_cat, token_vecs_cat2)\n",
        "cosine_module_res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSaYD_K12giC"
      },
      "source": [
        "## test finetuned model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNN-ZPnhn8GV",
        "outputId": "2545dd5b-1a46-4ffa-eebe-21b0e49d4eaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/callmetandat/SRL-for-BioBERT.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVYgO8pO4gVE",
        "outputId": "d8a4e953-e68e-4cb9-9da5-cbd8e5f2880a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SRL-for-BioBERT'...\n",
            "remote: Enumerating objects: 1649, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 1649 (delta 58), reused 12 (delta 5), pack-reused 1558\u001b[K\n",
            "Receiving objects: 100% (1649/1649), 32.74 MiB | 4.80 MiB/s, done.\n",
            "Resolving deltas: 100% (1125/1125), done.\n",
            "Updating files: 100% (416/416), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxFRBern6Np4",
        "outputId": "607a8605-132d-413d-c1b2-e5115c61c676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m623.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=d563dfb5c45822e6ed392738b4acd6effc09d7b494215778dea63874929ca112\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#making and loading model\n",
        "import torch\n",
        "import sys\n",
        "import os\n",
        "import logging\n",
        "sys.path.insert(1, '/content/SRL-for-BioBERT/')\n",
        "import matplotlib.pyplot as plt\n",
        "from models.model import multiTaskModel\n",
        "from transformers import BertTokenizer, BertModel, BertConfig\n",
        "from utils.data_utils import TaskType, NLP_MODELS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297,
          "referenced_widgets": [
            "4804c4589afc49739b5c43ede4a3652b",
            "445b0aeb6c7f40d1bd2405cf0d0052a4",
            "4a811d419e344ef6a6e8495b7d16864c",
            "a2ac28066b734214abcd13563b6584a1",
            "deef01942ad8419aae2c6439d52887c0",
            "668cc46696594381b263450c65482f1b",
            "efac05718880470faaf1c3430830bfc1",
            "e67d8d8dc585483f9adb95ab95d39015",
            "068b2d66354f4651a8940e724c1f8e3c",
            "5af8a5fcb2fa45a6a624fe85545d108b",
            "21603ac8ca884cb3a2e07699a3e6451f",
            "acf1bdb8f65f4536a2ecf46e17f8c1c5",
            "d8e80c2db07d45d6b87bbcebbad7b073",
            "ea47994dcbd34688bef534389d2cf3fe",
            "7a9c573700f148ca9d324c355047da29",
            "862028ec5cfd417dbc8687467b6f8b39",
            "693900f497be4f92baee6b0d72934217",
            "398e0fbaf2c043ddaeb7f17d5a6040ad",
            "7b962bc68faf470eac179339d9b935de",
            "adbe6ec8bf03480a9374dc2db0b417e9",
            "7df99403ee3c41af80122bb6af9da374",
            "4f937f0d9a724d89a65175715b4fb129",
            "51e27a876ebd44df8dce90f9305fa594",
            "47b47e0f90ce4fb2a5fe44730b2f8d3a",
            "f27d1014c69a4f26b7ba216e44268ed3",
            "200c2b0b0e3f49b1a74723d4e9a0bef3",
            "833597568ee64670bb47e6a9396e7742",
            "33278585265b433a91ac09dcf86d8cf8",
            "c9234589906e4d428729ec70c30e69a0",
            "a5403f766a6045ae96dfbbd3715634fb",
            "e61f7b838d63401fa5eaadc391689e8f",
            "f0d24e82c1d141768c1f0abb4d7d6e7f",
            "67a9c561f4634f9bae20d8bde670d1f0",
            "907c397ea4104408be8a820171c02717",
            "a4df8a3d705845e69a4e08bd6eda33fb",
            "c8aff94fc41f4e2dbbaddf03b74af00c",
            "79faf8456ae347a89f4008b41b8b73e5",
            "a364d61d3128454c99e94a105e794af3",
            "949724225c804b5a9fc0f1d1a45d362e",
            "433da48382f3481fad43153240225a67",
            "03f7d0ee0e6144c88583ff06eb55483b",
            "2c6cbf5ddfbb4933a6c7594e4559ae2e",
            "863547bac2424dab9b80cc222905fee0",
            "af2de6db785144b78d5a5bb4fe5be8e6"
          ]
        },
        "id": "jnfhC6-CpEF4",
        "outputId": "67b37730-6e51-4457-a74c-d1f93cfe7c12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4804c4589afc49739b5c43ede4a3652b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "acf1bdb8f65f4536a2ecf46e17f8c1c5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51e27a876ebd44df8dce90f9305fa594"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.11k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "907c397ea4104408be8a820171c02717"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dmis-lab/biobert-base-cased-v1.2\n",
        "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=True,truncation=True)\n"
      ],
      "metadata": {
        "id": "YGFqiNHYqKW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"the a/t-rich mut sequence indicates that normal splicing was abolished by a g-to-a transition at the first nucleotide of intron 2.\"\n",
        "text1 = \"torc induction was abolished by deletion of the distal tor box (box1), which interrupt this open reading frame.\"\n",
        "text2 = \"torc induction was abolished by deletion of the distal tor box (box3), when demolish this writing frame.\"\n",
        "\n",
        "# Tokenize our sentence with the BERT tokenizer.\n",
        "tokenized_text = tokenizer.tokenize(\"[CLS] \" + text1 + \" [SEP]\")\n",
        "tokenized_text2 = tokenizer.tokenize(\"[CLS] \" + text2 + \" [SEP]\")\n",
        "\n",
        "# Map the token strings to their vocabulary indeces.\n",
        "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)\n",
        "\n",
        "segments_ids = [1] * len(tokenized_text)\n",
        "segments_ids2 = [1] * len(tokenized_text2)\n",
        "\n",
        "tokens_tensor = torch.tensor([indexed_tokens], device='cuda:0')\n",
        "segments_tensors = torch.tensor([segments_ids], device='cuda:0')\n",
        "\n",
        "tokens_tensor2 = torch.tensor([indexed_tokens2], device='cuda:0')\n",
        "segments_tensors2 = torch.tensor([segments_ids2], device='cuda:0')"
      ],
      "metadata": {
        "id": "XWgSnCrEqEcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6UyaGL62giC",
        "outputId": "17d5e7c3-c30f-41ca-ac6b-9cf46c9c5864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 15])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "\n",
        "# Load pre-trained model (weights)\n",
        "\n",
        "loadedDict = torch.load('/content/drive/MyDrive/output_SRL_model/multi_task_model_8_367.pt', map_location=torch.device('cuda'))\n",
        "\n",
        "taskParams = loadedDict['task_params']\n",
        "\n",
        "modelName =taskParams.modelType.name.lower()\n",
        "_, _ , tokenizerClass, defaultName = NLP_MODELS[modelName]\n",
        "configName = taskParams.modelConfig\n",
        "\n",
        "#making tokenizer for model\n",
        "tokenizer = tokenizerClass.from_pretrained(configName)\n",
        "\n",
        "allParams = {}\n",
        "allParams['task_params'] = taskParams\n",
        "allParams['gpu'] = torch.cuda.is_available()\n",
        "# dummy values\n",
        "allParams['num_train_steps'] = 10\n",
        "allParams['warmup_steps'] = 0\n",
        "allParams['learning_rate'] = 2e-5\n",
        "allParams['epsilon'] = 1e-8\n",
        "\n",
        "\n",
        "model = multiTaskModel(allParams)\n",
        "model.load_multi_task_model(loadedDict)\n",
        "\n",
        "\n",
        "attention_masks = torch.tensor([[1] * 28], device='cuda:0')\n",
        "with torch.no_grad():\n",
        "\n",
        "    output = model.network(tokens_tensor, segments_tensors, attention_masks, 0, 'conllsrl')\n",
        "\n",
        "output[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvGtbwue2giC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4ad2174-236e-4a5a-e2b1-61c96787a7a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<models.model.multiTaskModel object at 0x7bd115a64fd0>\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUVlYP8G2giC"
      },
      "outputs": [],
      "source": [
        "token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "token_embeddings.size()\n",
        "\n",
        "# Stores the token vectors, with shape [22 x 3,072]\n",
        "token_vecs_cat = []\n",
        "\n",
        "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "# For each token in the sentence...\n",
        "for token in token_embeddings:\n",
        "\n",
        "    # `token` is a [12 x 768] tensor\n",
        "\n",
        "    # Concatenate the vectors (that is, append them together) from the last four layers.\n",
        "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "\n",
        "    # Use `cat_vec` to represent `token`.\n",
        "    token_vecs_cat.append(cat_vec)\n",
        "\n",
        "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
        "print(token_vecs_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uisaDuCC2giD",
        "outputId": "2308a815-d10c-4dd4-f194-c23097b06267"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "taskName :  odict_values(['conllsrl'])\n",
            "allTasksList :  [{'data_task_id': 0, 'data_': [{'uid': 0, 'label': [12, 2, 13, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'token_id': [101, 1045, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'type_id': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}], 'data_task_type': <TaskType.NER: 3>, 'data_task_name': 'conllsrl'}]\n",
            "inferDataLoader :  <torch.utils.data.dataloader.DataLoader object at 0x7fa01171aeb0>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n"
          ]
        }
      ],
      "source": [
        "text = [\"in addition, deletion of the distal tor box (box1) abolished torc induction whereas the presence of a dna fragment starting three bases upstream from box1 suffices for normal torc expression.\"]\n",
        "import sys\n",
        "sys.path.insert(1, '../')\n",
        "from infer_pipeline import inferPipeline\n",
        "from utils.data_utils import TaskType\n",
        "pipe = inferPipeline(modelPath='./output/multi_task_model_8_367.pt', maxSeqLen=50)\n",
        "\n",
        "data = pipe.infer(text, ['conllsrl'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEDEYh4F2giD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "\n",
        "def read_data(readPath):\n",
        "\n",
        "    with open(readPath, 'r', encoding = 'utf-8') as file:\n",
        "        taskData = []\n",
        "        for i, line in enumerate(file):\n",
        "            sample = json.loads(line)\n",
        "            taskData.append(sample)\n",
        "\n",
        "    return taskData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_I3ep2-2giD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from models.model import multiTaskModel\n",
        "\n",
        "def get_embedding_finetuned(dataDir, readFile, wrtDir):\n",
        "    data = read_data(os.path.join(dataDir, readFile))\n",
        "\n",
        "    # Load finetuned model\n",
        "    loadedDict = torch.load('../output/multi_task_model_9_13050.pt', map_location=torch.device('cpu'))\n",
        "\n",
        "    taskParams = loadedDict['task_params']\n",
        "\n",
        "    allParams = {}\n",
        "    allParams['task_params'] = taskParams\n",
        "    allParams['gpu'] = torch.cuda.is_available()\n",
        "    # dummy values\n",
        "    allParams['num_train_steps'] = 10\n",
        "    allParams['warmup_steps'] = 0\n",
        "    allParams['learning_rate'] = 2e-5\n",
        "    allParams['epsilon'] = 1e-8\n",
        "\n",
        "\n",
        "    model = multiTaskModel(allParams)\n",
        "    model.load_multi_task_model(loadedDict)\n",
        "\n",
        "    for i, line in enumerate(data):\n",
        "        tokens_id = line['token_id']\n",
        "        segments_id = line['type_id']\n",
        "        u_id = line['uid']\n",
        "        attention_mask = line['mask']\n",
        "\n",
        "        # Convert inputs to PyTorch tensors\n",
        "        tokens_tensor = torch.tensor([tokens_id])\n",
        "\n",
        "        segments_tensors = torch.tensor([segments_id])\n",
        "\n",
        "        print(\"Processed {} rows...\".format(i))\n",
        "        with torch.no_grad():\n",
        "            outputs = model.network(tokens_tensor, segments_tensors, attention_mask, 0, 'conllsrl')\n",
        "            print(\"\")\n",
        "            hidden_states = outputs[1][2]\n",
        "            print(\"done {} rows...\".format(i))\n",
        "        # `hidden_states` is a Python list.\n",
        "        # Each layer in the list is a torch tensor.\n",
        "        # `token_vecs` is a tensor with shape [50 x 768]\n",
        "\n",
        "        ## WORD EMBEDDING\n",
        "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "        token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "        token_embeddings.size()\n",
        "\n",
        "        # Stores the token vectors, with shape [22 x 3,072]\n",
        "        token_vecs_cat = []\n",
        "\n",
        "        # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "        # For each token in the sentence...\n",
        "        for token in token_embeddings:\n",
        "            # `token` is a [12 x 768] tensor\n",
        "\n",
        "            # Concatenate the vectors (that is, append them together) from the last four layers.\n",
        "            # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
        "            cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "\n",
        "            # Use `cat_vec` to represent `token`.\n",
        "            token_vecs_cat.append(cat_vec)\n",
        "\n",
        "        features = {\n",
        "                'uid': u_id,\n",
        "                'vec': token_vecs_cat}\n",
        "        # write u_id and token_vecs_cat to file\n",
        "        with open(os.path.join(wrtDir, 'finetuned_vecs_{}.pkl'.format(readFile.split('.')[0])), 'wb') as vecs_wri:\n",
        "            pickle.dump(features, vecs_wri)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymHbdXnx2giD",
        "outputId": "77a2f11c-95db-40e3-fbb1-9decde6f85cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "dataDir = '/mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/data/coNLL_tsv/bert-base-uncased_prepared_data/'\n",
        "readFile = 'ner_conll_testa_abolish.json'\n",
        "wriDir = 'test_get_embedding_finetuned'\n",
        "vec_finetuned = get_embedding_finetuned(dataDir, readFile, wriDir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9j9OSdqF2giD"
      },
      "source": [
        "# calculate cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkdeQVLM2giD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "def read_json_file(dirPath, wrtDir):\n",
        "    files = []\n",
        "    for path in os.listdir(dirPath):\n",
        "        if os.path.isfile(os.path.join(dirPath, path)):\n",
        "            files.append(path)\n",
        "\n",
        "\n",
        "    for file in files:\n",
        "        with open(os.path.join(dirPath, file), 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "\n",
        "        vec_origin = get_embedding(data)\n",
        "        vec_finetuned = get_embedding_finetuned(data)\n",
        "        cosine = cosine_similarity(vec_origin, vec_finetuned)\n",
        "        cosine_module = cosine_module(vec_origin, vec_finetuned)\n",
        "\n",
        "        features = {'uid': data['uid'], 'cosine': cosine, 'cosine_module': cosine_module}\n",
        "        with open(os.path.join(wrtDir, 'vecs_{}.pkl'.format(file.split('.')[0])), 'wb') as vecs_wri:\n",
        "            pickle.dump(features, vecs_wri)\n",
        "    return data\n",
        "\n",
        "data = read_json_file('./word_vecs_output/')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzHBQeDj2giD",
        "outputId": "99f982a8-f656-4b7d-e4e0-fe39420727a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data shape:  280\n",
            "outputs:  3\n",
            "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
            "Number of batches: 1\n",
            "Number of tokens: 50\n",
            "Number of hidden units: 768\n",
            "      Type of hidden_states:  <class 'tuple'>\n",
            "Tensor shape for each layer:  torch.Size([1, 50, 768])\n",
            "Our final sentence embedding vector of shape: torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertConfig, BertModel, BertTokenizer\n",
        "\n",
        "data = read_data('/mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_abolish.json')\n",
        "\n",
        "print(\"data shape: \", len(data))  # 280\n",
        "tokens_id = data[0]['token_id']\n",
        "segments_id = data[0]['type_id']\n",
        "\n",
        "\n",
        "# Convert inputs to PyTorch tensors\n",
        "tokens_tensor = torch.tensor([tokens_id])\n",
        "segments_tensors = torch.tensor([segments_id])\n",
        "\n",
        "# Load pre-trained model (weights)\n",
        "model = BertModel.from_pretrained('dmis-lab/biobert-base-cased-v1.2',\n",
        "                                output_hidden_states = True # Whether the model returns all hidden-states.\n",
        "                                )\n",
        "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    outputs = model(tokens_tensor, segments_tensors)\n",
        "    print(\"outputs: \", len(outputs)) # 2\n",
        "    hidden_states = outputs[2]\n",
        "\n",
        "\n",
        "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")  #13\n",
        "layer_i = 0\n",
        "\n",
        "print (\"Number of batches:\", len(hidden_states[layer_i])) #1\n",
        "batch_i = 0\n",
        "\n",
        "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i])) #50\n",
        "token_i = 0\n",
        "\n",
        "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))     # 768\n",
        "\n",
        "\n",
        "# `hidden_states` is a Python list.\n",
        "print('      Type of hidden_states: ', type(hidden_states)) # <class 'tuple'>\n",
        "\n",
        "# Each layer in the list is a torch tensor.\n",
        "print('Tensor shape for each layer: ', hidden_states[0].size()) # torch.Size([1, 50, 768])\n",
        "\n",
        "\n",
        "## Sentence Vectors\n",
        "# `hidden_states` has shape [13 x 1 x 50 x 768]\n",
        "\n",
        "# `token_vecs` is a tensor with shape [50 x 768]\n",
        "token_vecs = hidden_states[-2][0]\n",
        "\n",
        "# Calculate the average of all 22 token vectors.\n",
        "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size()) # torch.Size([768])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlmoBZM12giE",
        "outputId": "1f2882a6-7202-4f26-df22-fe85b8d03bc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "token_vecs_cat:  2\n",
            "['22110', '22111', '22112', '22113', '22114', '22115', '22116', '22117', '22118', '22119', '22120', '22121', '22122', '22123', '22124', '22125', '22126', '22127', '22128', '22129', '22130', '22131', '22132', '22133', '22134', '22135', '22136', '22137', '22138', '22139', '22140', '22141']\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "with open('models/outputs.pkl', 'rb') as f:\n",
        "    token_vecs_cat = pickle.load(f)\n",
        "\n",
        "print(\"token_vecs_cat: \", len(token_vecs_cat)) # 50\n",
        "print(token_vecs_cat['uid']) # (3072,)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5P8B54V2giE"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "# Example of target with class indices\n",
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.empty(3, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)\n",
        "print(output.backward())\n",
        "\n",
        "# Example of target with class probabilities\n",
        "input = torch.randn(3, 5, requires_grad=True)\n",
        "target = torch.randn(3, 5).softmax(dim=1)\n",
        "output = loss(input, target)\n",
        "print(output.shape)\n",
        "print(output.backward())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syr_ne2i2giE"
      },
      "source": [
        "# read pickle file for test word present in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6TbpbP72giE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "data_file = './vecs_ner_conll_testa_alter.pkl'\n",
        "with open(data_file, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjfYtwid2giE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data_file = './vecs_ner_conll_testa_abolish.pkl'\n",
        "with open(data_file, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "data['vec']\n",
        "df = pd.DataFrame(data['vec'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxo4qTKy2giE",
        "outputId": "6a528a41-9e47-48d2-8e72-b2a7a6c77f23"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50, 3072)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyFlYcyb2giE"
      },
      "source": [
        "# test get word embedding from biobert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biB_QqUs2giE"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "file = './data/coNLL_tsv/dmis-lab/biobert-base-cased-v1.2_prepared_data/ner_conll_testa_abolish.json'\n",
        "def read_data(readPath):\n",
        "\n",
        "    with open(readPath, 'r', encoding = 'utf-8') as file:\n",
        "        taskData = []\n",
        "        for i, line in enumerate(file):\n",
        "            sample = json.loads(line)\n",
        "            taskData.append(sample)\n",
        "\n",
        "    return taskData\n",
        "data = read_data(file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DSPvA6qG2giF"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "bertmodel = BertModel.from_pretrained('dmis-lab/biobert-base-cased-v1.2', output_hidden_states =True)\n",
        "\n",
        "def get_embedding(line):\n",
        "    '''\n",
        "    get word presentation from origin biobert model\n",
        "    input:json file in coNLL_tsv/dmis-lab/biobert-base-cased-v1.2_prepared_data\n",
        "    output: word presentation with shape for each word [3072]\n",
        "    '''\n",
        "    tokens_id = line['token_id']\n",
        "    segments_id = line['type_id']\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([tokens_id])\n",
        "\n",
        "    segments_tensors = torch.tensor([segments_id])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = bertmodel(tokens_tensor, segments_tensors)\n",
        "\n",
        "        hidden_states = outputs[2]\n",
        "\n",
        "    ## WORD EMBEDDING\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # Stores the token vectors, with shape [22 x 3,072]\n",
        "    token_vecs_cat = []\n",
        "\n",
        "    # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
        "\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:                  # `token` is a [12 x 768] tensor\n",
        "\n",
        "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0) # last four layers\n",
        "\n",
        "        token_vecs_cat.append(cat_vec) #cat_vec is 3072\n",
        "    return token_vecs_cat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo3mbSsq2giQ"
      },
      "source": [
        "# test get word embedding from finetuned biobert model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBGpZMQ12giQ",
        "outputId": "6279aed5-ac56-48ae-82f5-5c53050336c7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Load finetuned model\n",
        "loadedDict = torch.load('./output/multi_task_model_0_1305.pt') #, map_location=torch.device('cpu'))\n",
        "\n",
        "taskParams = loadedDict['task_params']\n",
        "\n",
        "allParams = {}\n",
        "allParams['task_params'] = taskParams\n",
        "allParams['gpu'] = torch.cuda.is_available()\n",
        "# dummy values\n",
        "allParams['num_train_steps'] = 10\n",
        "allParams['warmup_steps'] = 0\n",
        "allParams['learning_rate'] = 2e-5\n",
        "allParams['epsilon'] = 1e-8\n",
        "\n",
        "finetuned_model = multiTaskModel(allParams)\n",
        "finetuned_model.load_multi_task_model(loadedDict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woEprT2C2giR",
        "outputId": "51e1d76c-e0e7-4be3-d675-db997665c7dd"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'torch.device' object has no attribute 'cuda'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfinetuned_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_to_cuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/models/model.py:193\u001b[0m, in \u001b[0;36m_to_cuda\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    191\u001b[0m     y \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mcuda(non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    192\u001b[0m     y\u001b[38;5;241m.\u001b[39mrequires_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'torch.device' object has no attribute 'cuda'"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "finetuned_model._to_cuda(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvi8TyGC2giR"
      },
      "outputs": [],
      "source": [
        "from models.model import multiTaskModel\n",
        "import torch\n",
        "def get_embedding_finetuned(finetuned_model, line):\n",
        "\n",
        "    tokens_id = line['token_id']\n",
        "    segments_id = line['type_id']\n",
        "\n",
        "    attention_mask = torch.tensor([line['mask']])\n",
        "\n",
        "    # Convert inputs to PyTorch tensors\n",
        "    tokens_tensor = torch.tensor([tokens_id])\n",
        "\n",
        "    segments_tensors = torch.tensor([segments_id])\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = finetuned_model.network(tokens_tensor, segments_tensors, attention_mask, 0, 'conllsrl')\n",
        "        print(outputs.shape)   # torch.Size([1, 50, 15])\n",
        "        print(outputs)\n",
        "        hidden_states = outputs[0][2]\n",
        "\n",
        "    ## WORD EMBEDDING\n",
        "    token_embeddings = torch.stack(hidden_states, dim=0)\n",
        "    token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "    token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "    # Stores the token vectors, with shape [22 x 3,072]\n",
        "    token_vecs_cat = []\n",
        "\n",
        "    # For each token in the sentence...\n",
        "    for token in token_embeddings:\n",
        "\n",
        "        cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
        "\n",
        "        # Use `cat_vec` to represent `token`.\n",
        "        token_vecs_cat.append(cat_vec)\n",
        "\n",
        "    return token_vecs_cat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CwsictQF2giR",
        "outputId": "08117648-49dc-4549-a3da-4c0ec972a924"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 50, 15])\n",
            "tensor([[[-1.1846e+00, -6.8459e-01,  9.8238e-01,  6.8634e-02, -9.1011e-02,\n",
            "          -1.5405e+00, -7.6124e-01, -1.1030e+00, -8.5586e-02, -1.5470e+00,\n",
            "          -1.0949e+00,  1.5951e-01,  8.3361e+00,  9.6597e-01, -7.1799e-01],\n",
            "         [ 3.1445e+00, -2.4696e-01,  4.4184e+00, -3.0287e+00,  3.9902e+00,\n",
            "           8.4581e-01, -1.1889e+00, -2.3679e+00, -1.2814e+00,  1.6745e+00,\n",
            "          -1.1275e+00, -1.0425e+00, -2.8933e+00, -2.6966e+00, -1.9981e+00],\n",
            "         [ 2.4267e+00,  1.9791e+00,  2.6731e+00, -3.5098e+00,  9.7528e-01,\n",
            "           1.9944e+00, -1.3995e+00, -2.4866e+00, -1.3075e+00,  7.7378e-01,\n",
            "           9.7236e-01, -1.4114e+00, -3.1437e+00, -2.9934e+00,  9.4210e-01],\n",
            "         [-1.1750e+00, -6.8287e-01,  8.9483e-01, -1.6155e+00, -7.0446e-01,\n",
            "          -5.0873e-01, -7.1245e-01, -1.3488e+00, -3.1651e-01, -7.8965e-01,\n",
            "          -1.1418e-01, -1.0203e+00,  7.1724e-02, -1.0655e+00,  8.2317e+00],\n",
            "         [ 1.0061e+00,  2.3499e+00,  7.0568e-01, -3.1166e+00,  4.0577e-01,\n",
            "           3.4072e+00, -1.8339e+00, -2.2042e+00, -1.1205e+00, -2.5126e-01,\n",
            "           2.7246e+00, -1.9117e+00, -3.3632e+00, -3.1401e+00,  2.6791e+00],\n",
            "         [-1.2497e+00,  6.4263e-01,  2.0584e+00, -2.3291e+00, -2.6896e-01,\n",
            "           1.4146e+00, -1.3668e+00, -1.4874e+00, -7.1975e-01, -1.7051e+00,\n",
            "           1.5876e-02, -1.6110e+00, -1.5535e+00, -2.3312e+00,  7.5506e+00],\n",
            "         [-1.8740e+00,  1.0609e+00,  1.8375e+00, -1.8785e+00, -1.6929e-01,\n",
            "           1.1380e+00, -1.4475e+00, -1.4854e+00, -6.0792e-01, -2.1786e+00,\n",
            "           2.0943e-01, -1.4766e+00, -9.5216e-01, -2.0918e+00,  7.4708e+00],\n",
            "         [ 5.6794e-01,  2.1863e+00,  1.8852e+00, -3.3888e+00,  1.7235e+00,\n",
            "           3.2239e+00, -2.1385e+00, -2.5460e+00, -1.1246e+00, -2.6564e-01,\n",
            "           1.2541e+00, -1.8701e+00, -3.5730e+00, -3.2399e+00,  2.8242e+00],\n",
            "         [-1.3102e+00, -5.0667e-01,  1.9549e+00, -1.5572e+00,  1.0364e-01,\n",
            "          -3.1388e-01, -1.2224e+00, -1.6404e+00, -5.3710e-01, -1.8556e+00,\n",
            "          -6.5733e-01, -9.7081e-01, -5.3515e-01, -6.9184e-01,  7.9988e+00],\n",
            "         [-8.4183e-01,  3.0745e+00,  5.7480e+00, -3.1236e+00, -2.4274e-01,\n",
            "           4.1152e+00, -2.2239e+00, -1.6845e+00, -9.1816e-01, -1.2409e+00,\n",
            "          -6.0773e-02, -2.1505e+00, -2.6652e+00, -3.0206e+00, -1.0740e-01],\n",
            "         [-2.0022e+00,  2.1236e+00,  7.3404e+00, -2.2249e+00, -1.6533e-01,\n",
            "           1.4098e+00, -1.9466e+00, -1.1113e+00, -5.4786e-01, -1.7715e+00,\n",
            "          -5.3499e-01, -1.4704e+00, -1.6364e+00, -2.3697e+00,  4.3385e-01],\n",
            "         [ 3.1475e-01,  2.2802e+00,  6.8508e+00, -2.7673e+00, -1.0894e+00,\n",
            "           2.0994e+00, -1.5752e+00, -1.7379e+00, -9.4763e-01, -1.2593e+00,\n",
            "           1.9659e-01, -1.5620e+00, -2.6035e+00, -2.8592e+00, -8.0651e-01],\n",
            "         [ 2.1560e-01,  1.6083e+00,  5.5406e+00, -3.4100e+00,  1.1100e+00,\n",
            "           4.0793e+00, -2.0043e+00, -1.6675e+00, -1.0016e+00, -1.4517e+00,\n",
            "           4.9587e-01, -2.2244e+00, -3.1058e+00, -3.3691e+00, -1.8338e-01],\n",
            "         [ 6.1366e-01,  2.6325e+00,  2.2572e+00, -3.3777e+00,  5.3892e-01,\n",
            "           3.2722e+00, -2.3763e+00, -2.2571e+00, -1.1070e+00, -4.2146e-01,\n",
            "           1.8490e+00, -2.0732e+00, -3.4091e+00, -3.3128e+00,  2.8820e+00],\n",
            "         [-1.4675e+00, -1.6150e+00,  2.0607e+00, -1.2302e+00, -4.8284e-01,\n",
            "          -1.2756e+00, -6.6912e-01, -1.2258e+00, -5.0913e-01, -1.3790e+00,\n",
            "          -2.0461e-01, -8.3766e-01, -1.4658e-01, -1.0786e-01,  7.9903e+00],\n",
            "         [-9.8444e-01, -1.1374e+00,  2.0928e+00, -9.4348e-01,  6.8992e-02,\n",
            "          -1.2153e+00, -7.3125e-01, -1.4706e+00, -8.3234e-01, -1.5283e+00,\n",
            "          -5.0836e-01, -8.4228e-01, -6.6113e-01, -2.0416e-01,  7.9094e+00],\n",
            "         [-2.4335e-01,  1.1040e+00,  7.7086e+00, -2.6017e+00, -8.5950e-01,\n",
            "           5.9614e-01, -1.8905e+00, -1.1939e+00, -8.9730e-01, -1.5245e+00,\n",
            "           1.5713e-01, -1.4408e+00, -2.3336e+00, -2.2558e+00, -3.0738e-02],\n",
            "         [-9.3296e-01, -1.5858e+00,  9.3589e-03,  8.5287e+00, -1.6862e-02,\n",
            "          -1.5404e+00, -7.2454e-01, -2.1495e-01, -1.8511e-02, -6.7071e-01,\n",
            "           1.2036e-01, -2.2750e-03,  8.4758e-01,  3.1123e-01, -1.6306e+00],\n",
            "         [-6.2348e-01, -1.7464e-03,  1.9549e+00, -1.6992e+00,  4.3041e-01,\n",
            "           3.4564e-01, -1.3549e+00, -2.1009e+00, -7.5753e-01, -1.5857e+00,\n",
            "           1.8093e-01, -1.4486e+00, -1.5512e+00, -1.5272e+00,  7.7868e+00],\n",
            "         [-7.6536e-01,  2.5452e+00,  6.6264e+00, -2.6505e+00, -1.7716e+00,\n",
            "           2.0787e+00, -2.0179e+00, -1.0138e+00, -7.3849e-01, -1.1307e+00,\n",
            "           1.4028e+00, -1.7781e+00, -3.1148e+00, -2.5664e+00,  3.2034e-01],\n",
            "         [ 2.2807e+00,  2.0918e+00,  2.1908e+00, -3.4808e+00,  5.7348e-01,\n",
            "           1.9177e+00, -1.6342e+00, -2.1140e+00, -1.2631e+00,  1.9514e-01,\n",
            "           1.3062e+00, -1.4827e+00, -3.2251e+00, -3.0516e+00,  2.1064e+00],\n",
            "         [ 1.8892e+00,  2.2717e+00,  1.7981e+00, -3.5201e+00,  8.0968e-01,\n",
            "           2.6287e+00, -2.1832e+00, -2.3295e+00, -1.3121e+00,  9.4948e-02,\n",
            "           1.6674e+00, -1.7816e+00, -3.4830e+00, -3.0980e+00,  2.6624e+00],\n",
            "         [-7.8905e-01,  6.4353e-01,  1.6802e+00, -2.4421e+00, -2.7459e-01,\n",
            "           1.5942e+00, -1.3395e+00, -1.7297e+00, -6.5169e-01, -1.4251e+00,\n",
            "           4.2575e-01, -1.5678e+00, -1.7436e+00, -2.3537e+00,  7.4066e+00],\n",
            "         [ 1.4357e+00,  2.7573e+00,  5.6147e+00, -3.1531e+00, -1.2254e+00,\n",
            "           2.9837e+00, -2.1547e+00, -1.8862e+00, -1.0736e+00, -9.3084e-01,\n",
            "           6.6835e-01, -1.7407e+00, -3.3634e+00, -2.9234e+00,  4.1287e-02],\n",
            "         [-8.6705e-01,  9.9889e-01,  1.9836e+00, -2.6461e+00,  4.8108e-02,\n",
            "           1.9747e+00, -1.5416e+00, -1.6530e+00, -5.4787e-01, -1.4710e+00,\n",
            "           2.2633e-01, -1.6159e+00, -2.0135e+00, -2.8327e+00,  7.0737e+00],\n",
            "         [ 2.5276e+00,  1.9011e+00,  2.0799e+00, -3.3967e+00,  8.4896e-01,\n",
            "           1.6880e+00, -1.2674e+00, -2.1170e+00, -1.2445e+00,  6.9708e-01,\n",
            "           8.5915e-01, -1.4145e+00, -2.9988e+00, -3.0042e+00,  1.7506e+00],\n",
            "         [-1.0805e+00,  3.4260e-01,  4.1058e+00, -2.5562e+00, -4.1758e-01,\n",
            "          -1.0322e+00, -1.1725e+00, -1.6348e+00, -5.8246e-01, -3.2230e-01,\n",
            "           6.8034e-01, -1.4710e+00, -2.3139e+00, -2.5802e+00,  5.8065e+00],\n",
            "         [-8.8332e-01,  2.9661e+00,  3.1932e+00, -3.4912e+00, -2.7881e-01,\n",
            "           3.2329e+00, -2.5849e+00, -1.3796e+00, -5.9697e-01, -1.3010e+00,\n",
            "           3.6163e+00, -1.9470e+00, -3.4468e+00, -2.8176e+00,  1.2348e+00],\n",
            "         [ 3.0227e+00,  1.9007e+00,  2.9020e+00, -3.6823e+00,  1.3014e+00,\n",
            "           2.6538e+00, -1.5738e+00, -1.9721e+00, -1.4465e+00,  8.2613e-01,\n",
            "           7.8170e-01, -1.5842e+00, -3.5303e+00, -3.5005e+00,  1.8103e-01],\n",
            "         [-6.0976e-01,  4.3689e+00,  2.9924e+00, -3.0622e+00,  5.8534e-01,\n",
            "           3.1664e+00, -2.2543e+00, -1.7318e+00, -1.3530e-01, -7.2461e-01,\n",
            "           1.6948e+00, -2.1618e+00, -3.3744e+00, -3.3517e+00, -1.5180e-04],\n",
            "         [-6.6001e-01,  3.9976e+00,  1.1443e+00, -3.2730e+00,  1.7859e+00,\n",
            "           3.3398e+00, -2.3521e+00, -1.2364e+00, -2.4322e-01, -6.1840e-01,\n",
            "           1.8422e+00, -1.6151e+00, -3.0871e+00, -3.0105e+00,  5.7836e-01],\n",
            "         [-1.9031e+00,  9.7334e-01,  1.3929e+00, -1.8405e+00, -4.7910e-01,\n",
            "           3.3965e-02, -1.2525e+00, -1.4455e+00, -4.5531e-01, -1.6028e+00,\n",
            "           5.1719e-01, -1.2139e+00, -1.1465e+00, -1.1082e+00,  7.8674e+00],\n",
            "         [-5.9493e-01,  1.1499e+00,  2.5725e+00, -2.3849e+00,  1.4140e-01,\n",
            "           1.3453e+00, -1.4420e+00, -2.0855e+00, -8.2319e-01, -1.0098e+00,\n",
            "          -1.4500e-01, -1.4948e+00, -1.8986e+00, -2.6271e+00,  7.1033e+00],\n",
            "         [-1.5292e+00,  1.6296e-01,  1.5404e+00, -2.1407e+00,  2.2163e-02,\n",
            "           1.5392e+00, -1.6800e+00, -1.7777e+00, -3.4614e-01, -2.3369e+00,\n",
            "           1.4836e+00, -1.3764e+00, -1.8751e+00, -1.1014e+00,  6.6007e+00],\n",
            "         [-1.4560e+00,  3.2872e+00,  3.9698e+00, -3.2407e+00,  1.5563e-01,\n",
            "           3.8267e+00, -2.7926e+00, -1.3142e+00,  1.7563e-01, -1.8031e+00,\n",
            "           1.9479e+00, -2.0393e+00, -3.4520e+00, -2.9530e+00,  2.9239e-01],\n",
            "         [ 6.6295e-01,  3.5855e+00,  1.2530e+00, -3.0343e+00, -1.0684e-01,\n",
            "           3.3000e+00, -2.0985e+00, -1.6020e+00, -9.4530e-01, -2.9953e-01,\n",
            "           2.0290e+00, -1.7443e+00, -2.9312e+00, -3.1548e+00,  1.8555e+00],\n",
            "         [-9.6828e-01,  8.6343e-02,  7.5711e-01, -1.4244e+00, -5.8577e-01,\n",
            "          -3.0535e-01, -7.8120e-01, -1.1499e+00, -6.5377e-01, -1.4577e+00,\n",
            "          -5.7932e-01, -9.7267e-01, -6.9647e-02, -9.1824e-01,  8.1363e+00],\n",
            "         [-2.4383e-01,  2.2903e+00,  3.2189e+00, -3.4532e+00, -3.1572e-01,\n",
            "           2.6882e+00, -1.9901e+00, -2.1234e+00, -8.2863e-01, -1.0662e+00,\n",
            "           8.4113e-01, -1.7620e+00, -3.0788e+00, -3.2897e+00,  5.3095e+00],\n",
            "         [-2.2019e+00,  2.2428e+00,  6.3647e+00, -1.9954e+00, -1.1567e+00,\n",
            "           2.2579e+00, -2.2726e+00, -6.7881e-01, -3.6426e-01, -1.5198e+00,\n",
            "           1.5572e+00, -1.7790e+00, -2.8126e+00, -2.6169e+00,  6.3228e-02],\n",
            "         [-3.9630e-03, -1.0982e+00,  3.6960e-01,  1.9099e-01, -1.4229e+00,\n",
            "          -1.8968e+00, -6.9115e-01, -8.5154e-01, -6.6367e-01, -9.5435e-01,\n",
            "           3.5477e-01,  3.2800e-01,  1.0268e+00,  8.6312e+00, -3.5122e-01],\n",
            "         [ 3.5484e-01,  1.9743e+00,  3.7249e+00, -3.2301e+00, -4.9843e-01,\n",
            "           2.7873e+00, -1.3782e+00, -1.4378e+00, -3.2150e-01, -1.4195e+00,\n",
            "           2.0442e+00, -1.7095e+00, -2.9947e+00, -3.7211e+00,  1.1617e+00],\n",
            "         [ 5.9013e-01,  2.3213e+00,  4.6766e+00, -3.0479e+00, -1.8923e+00,\n",
            "           2.3982e+00, -1.4708e+00, -1.4878e+00, -6.5988e-01, -1.0087e+00,\n",
            "           1.8466e+00, -1.9404e+00, -2.9667e+00, -3.3851e+00,  1.6187e+00],\n",
            "         [ 1.9882e-01,  1.7634e+00,  3.4864e+00, -2.8074e+00, -1.0229e+00,\n",
            "           2.7633e+00, -1.7075e+00, -1.2173e+00, -9.4908e-01, -1.5171e+00,\n",
            "           2.1357e+00, -1.8844e+00, -2.8380e+00, -3.6207e+00,  2.7357e+00],\n",
            "         [-2.1963e-02,  1.2516e+00,  3.6216e+00, -2.5975e+00, -3.8288e-01,\n",
            "           9.5003e-01, -1.6918e+00, -2.1733e+00, -2.5957e-01, -1.8079e+00,\n",
            "           2.4331e+00, -1.8653e+00, -2.2409e+00, -2.2093e+00,  2.0254e+00],\n",
            "         [-6.9978e-03,  1.0320e+00,  3.0106e+00, -2.5770e+00,  9.1709e-01,\n",
            "           2.5213e+00, -1.3888e+00, -1.9280e+00, -4.7131e-01, -1.4562e+00,\n",
            "           1.6617e+00, -1.8044e+00, -2.3433e+00, -3.7769e+00,  1.5190e+00],\n",
            "         [ 1.5135e+00,  1.8577e+00,  3.7317e+00, -2.4907e+00, -1.0732e+00,\n",
            "           2.1967e+00, -1.3947e+00, -1.8692e+00, -1.1358e+00, -1.0345e+00,\n",
            "           2.4238e+00, -1.9121e+00, -3.4248e+00, -3.2376e+00,  1.7237e+00],\n",
            "         [ 4.7933e-01,  1.7646e+00,  3.3909e+00, -2.5724e+00, -1.1165e+00,\n",
            "           2.5148e+00, -1.8751e+00, -1.9401e+00, -9.6623e-01, -1.0831e+00,\n",
            "           3.1567e+00, -2.1410e+00, -2.6580e+00, -2.7737e+00,  2.3153e+00],\n",
            "         [-6.1546e-01,  2.0996e+00,  4.2867e+00, -2.3649e+00, -5.3570e-01,\n",
            "           2.8366e+00, -2.1523e+00, -1.4942e+00, -9.3837e-01, -1.4552e+00,\n",
            "           2.6006e+00, -2.3113e+00, -3.1973e+00, -3.0051e+00,  2.2877e+00],\n",
            "         [-1.6586e-01,  1.6962e+00,  3.6904e+00, -2.2863e+00, -1.4673e-01,\n",
            "           2.4916e+00, -2.0963e+00, -2.0108e+00, -8.3920e-01, -1.8656e+00,\n",
            "           2.9442e+00, -2.1474e+00, -3.0916e+00, -2.5961e+00,  3.0689e+00],\n",
            "         [ 8.2022e-01,  1.2272e+00,  3.1774e+00, -2.2357e+00, -1.4154e+00,\n",
            "           2.6798e+00, -1.8716e+00, -1.8007e+00, -1.3523e+00, -1.3147e+00,\n",
            "           2.8762e+00, -1.9172e+00, -2.7840e+00, -2.4346e+00,  2.5398e+00]]])\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'token_vecs_cat' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m word_vec \u001b[38;5;241m=\u001b[39m \u001b[43mget_embedding_finetuned\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn [5], line 55\u001b[0m, in \u001b[0;36mget_embedding_finetuned\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     36\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# ## WORD EMBEDDING\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# token_embeddings = torch.stack(hidden_states, dim=0)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# token_embeddings = torch.squeeze(token_embeddings, dim=1)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m#     # Use `cat_vec` to represent `token`.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m#     token_vecs_cat.append(cat_vec)\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtoken_vecs_cat\u001b[49m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'token_vecs_cat' is not defined"
          ]
        }
      ],
      "source": [
        "word_vec = get_embedding_finetuned(data[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrNvnbhL2giR"
      },
      "outputs": [],
      "source": [
        "representations = {}\n",
        "for i, line in enumerate(data):\n",
        "    word_vec = get_embedding_finetuned(line)\n",
        "    representations[i] = {'uid': line['uid'], 'vec': word_vec}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGOP-IGE2giR",
        "outputId": "50760935-4b58-4d0d-ccb4-f09210222516"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(representations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbOGeyvy2giR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "eOYt_7ZcnOq7"
      ]
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4804c4589afc49739b5c43ede4a3652b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_445b0aeb6c7f40d1bd2405cf0d0052a4",
              "IPY_MODEL_4a811d419e344ef6a6e8495b7d16864c",
              "IPY_MODEL_a2ac28066b734214abcd13563b6584a1"
            ],
            "layout": "IPY_MODEL_deef01942ad8419aae2c6439d52887c0"
          }
        },
        "445b0aeb6c7f40d1bd2405cf0d0052a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_668cc46696594381b263450c65482f1b",
            "placeholder": "​",
            "style": "IPY_MODEL_efac05718880470faaf1c3430830bfc1",
            "value": "config.json: 100%"
          }
        },
        "4a811d419e344ef6a6e8495b7d16864c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e67d8d8dc585483f9adb95ab95d39015",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_068b2d66354f4651a8940e724c1f8e3c",
            "value": 570
          }
        },
        "a2ac28066b734214abcd13563b6584a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af8a5fcb2fa45a6a624fe85545d108b",
            "placeholder": "​",
            "style": "IPY_MODEL_21603ac8ca884cb3a2e07699a3e6451f",
            "value": " 570/570 [00:00&lt;00:00, 21.5kB/s]"
          }
        },
        "deef01942ad8419aae2c6439d52887c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "668cc46696594381b263450c65482f1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efac05718880470faaf1c3430830bfc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e67d8d8dc585483f9adb95ab95d39015": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "068b2d66354f4651a8940e724c1f8e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5af8a5fcb2fa45a6a624fe85545d108b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21603ac8ca884cb3a2e07699a3e6451f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acf1bdb8f65f4536a2ecf46e17f8c1c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d8e80c2db07d45d6b87bbcebbad7b073",
              "IPY_MODEL_ea47994dcbd34688bef534389d2cf3fe",
              "IPY_MODEL_7a9c573700f148ca9d324c355047da29"
            ],
            "layout": "IPY_MODEL_862028ec5cfd417dbc8687467b6f8b39"
          }
        },
        "d8e80c2db07d45d6b87bbcebbad7b073": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_693900f497be4f92baee6b0d72934217",
            "placeholder": "​",
            "style": "IPY_MODEL_398e0fbaf2c043ddaeb7f17d5a6040ad",
            "value": "model.safetensors: 100%"
          }
        },
        "ea47994dcbd34688bef534389d2cf3fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b962bc68faf470eac179339d9b935de",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adbe6ec8bf03480a9374dc2db0b417e9",
            "value": 440449768
          }
        },
        "7a9c573700f148ca9d324c355047da29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7df99403ee3c41af80122bb6af9da374",
            "placeholder": "​",
            "style": "IPY_MODEL_4f937f0d9a724d89a65175715b4fb129",
            "value": " 440M/440M [00:06&lt;00:00, 99.2MB/s]"
          }
        },
        "862028ec5cfd417dbc8687467b6f8b39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "693900f497be4f92baee6b0d72934217": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "398e0fbaf2c043ddaeb7f17d5a6040ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b962bc68faf470eac179339d9b935de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adbe6ec8bf03480a9374dc2db0b417e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7df99403ee3c41af80122bb6af9da374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f937f0d9a724d89a65175715b4fb129": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51e27a876ebd44df8dce90f9305fa594": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47b47e0f90ce4fb2a5fe44730b2f8d3a",
              "IPY_MODEL_f27d1014c69a4f26b7ba216e44268ed3",
              "IPY_MODEL_200c2b0b0e3f49b1a74723d4e9a0bef3"
            ],
            "layout": "IPY_MODEL_833597568ee64670bb47e6a9396e7742"
          }
        },
        "47b47e0f90ce4fb2a5fe44730b2f8d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33278585265b433a91ac09dcf86d8cf8",
            "placeholder": "​",
            "style": "IPY_MODEL_c9234589906e4d428729ec70c30e69a0",
            "value": "vocab.txt: 100%"
          }
        },
        "f27d1014c69a4f26b7ba216e44268ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5403f766a6045ae96dfbbd3715634fb",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e61f7b838d63401fa5eaadc391689e8f",
            "value": 213450
          }
        },
        "200c2b0b0e3f49b1a74723d4e9a0bef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d24e82c1d141768c1f0abb4d7d6e7f",
            "placeholder": "​",
            "style": "IPY_MODEL_67a9c561f4634f9bae20d8bde670d1f0",
            "value": " 213k/213k [00:00&lt;00:00, 2.34MB/s]"
          }
        },
        "833597568ee64670bb47e6a9396e7742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33278585265b433a91ac09dcf86d8cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9234589906e4d428729ec70c30e69a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5403f766a6045ae96dfbbd3715634fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e61f7b838d63401fa5eaadc391689e8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0d24e82c1d141768c1f0abb4d7d6e7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67a9c561f4634f9bae20d8bde670d1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "907c397ea4104408be8a820171c02717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a4df8a3d705845e69a4e08bd6eda33fb",
              "IPY_MODEL_c8aff94fc41f4e2dbbaddf03b74af00c",
              "IPY_MODEL_79faf8456ae347a89f4008b41b8b73e5"
            ],
            "layout": "IPY_MODEL_a364d61d3128454c99e94a105e794af3"
          }
        },
        "a4df8a3d705845e69a4e08bd6eda33fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_949724225c804b5a9fc0f1d1a45d362e",
            "placeholder": "​",
            "style": "IPY_MODEL_433da48382f3481fad43153240225a67",
            "value": "config.json: 100%"
          }
        },
        "c8aff94fc41f4e2dbbaddf03b74af00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f7d0ee0e6144c88583ff06eb55483b",
            "max": 1110,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c6cbf5ddfbb4933a6c7594e4559ae2e",
            "value": 1110
          }
        },
        "79faf8456ae347a89f4008b41b8b73e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_863547bac2424dab9b80cc222905fee0",
            "placeholder": "​",
            "style": "IPY_MODEL_af2de6db785144b78d5a5bb4fe5be8e6",
            "value": " 1.11k/1.11k [00:00&lt;00:00, 19.7kB/s]"
          }
        },
        "a364d61d3128454c99e94a105e794af3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "949724225c804b5a9fc0f1d1a45d362e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433da48382f3481fad43153240225a67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03f7d0ee0e6144c88583ff06eb55483b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c6cbf5ddfbb4933a6c7594e4559ae2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "863547bac2424dab9b80cc222905fee0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af2de6db785144b78d5a5bb4fe5be8e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}