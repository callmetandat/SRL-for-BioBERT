{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: type: <class 'list'>\n",
      "prediction: ['O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', '[CLS]', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "label: ['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-A2', 'I-A2', 'O', 'B-A1', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\n",
      "lineTok: ['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-A2', 'I-A2', 'O', 'B-A1', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\n",
      "lineLab: ['O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', '[CLS]', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "prediction_new: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "label_new: ['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-A2', 'I-A2', 'O', 'O', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\n",
      "new1: [['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-A2', 'I-A2', 'O', 'O', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']]\n",
      "result_f1: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import ast\n",
    "\n",
    "\n",
    "data=[]\n",
    "prediction_new = []\n",
    "label_new = []\n",
    "\n",
    "# Read the file and extract the prediction and label columns\n",
    "line = \"17625\t['O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', '[CLS]', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', 'O']\t['B-A0', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-V', 'B-A2', 'I-A2', 'O', 'B-A1', 'I-A1', 'I-A1', 'O', 'O', 'O', 'O']\"\n",
    "\n",
    "\n",
    "uid, prediction, label = line.strip().split(\"\\t\")\n",
    "data.append((prediction.strip(\"[]\"), label.strip(\"[]\")))\n",
    "\n",
    "print(f\"data: type: {type(data)}\")\n",
    "print(f\"prediction: {prediction}\")\n",
    "print(f\"label: {label}\")\n",
    "# convert list to string\n",
    "predictions_data = [d[0] for d in data]\n",
    "labels_data = [d[1] for d in data]\n",
    "\n",
    "lineTok = ast.literal_eval(label)\n",
    "lineLab = ast.literal_eval(prediction)\n",
    "\n",
    "print(f\"lineTok: {lineTok}\")\n",
    "print(f\"lineLab: {lineLab}\")\n",
    "for (Tok, Lab) in zip(lineTok, lineLab):\n",
    "    \n",
    "    if Lab in ['[CLS]','[SEP]', 'X']: # replace non-text tokens with O. These will not be evaluated.\n",
    "        prediction_new.append('O')\n",
    "        label_new.append('O')\n",
    "        continue\n",
    "    if(Lab == \"B-V\"):\n",
    "        prediction_new.append(\"V\")\n",
    "    else:\n",
    "        prediction_new.append(Lab)\n",
    "        label_new.append(Tok)\n",
    "        \n",
    "print(f\"prediction_new: {prediction_new}\")\n",
    "print(f\"label_new: {label_new}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import recall_score as class_recall_score\n",
    "\n",
    "new1 = [label_new]\n",
    "print(f\"new1: {new1}\")\n",
    "new2 = [prediction_new]\n",
    "\n",
    "result_f1 = f1_score(label_new, prediction_new,average=\"micro\")\n",
    "\n",
    "print(f\"result_f1: {result_f1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "predictions = []\n",
    "\n",
    "filePath = \"./output/conllsrl_test_predictions_29.tsv\"\n",
    "with open(filePath, \"r\") as f:\n",
    "    for line in f:\n",
    "        # delete the first line\n",
    "        if \"uid\" in line:\n",
    "            continue\n",
    "        uid, prediction, label = line.strip().split(\"\\t\")\n",
    "        labels.append(label)\n",
    "        predictions.append(prediction)\n",
    "        data.append((prediction.strip(\"[]\"), label.strip(\"[]\")))\n",
    "\n",
    "print(\"prediction: \", type(data))\n",
    "# apply this conversion to all the elements in the list\n",
    "lineToks = [ast.literal_eval(label) for label in labels]\n",
    "lineLabs = [ast.literal_eval(prediction) for prediction in predictions]\n",
    "\n",
    "trueLabels = [] # labels\n",
    "predictLabels = [] # predictions\n",
    "\n",
    "for lineTok, lineLab in zip(lineToks, lineLabs):\n",
    "    if lineLab in ['[CLS]','[SEP]', 'X']: # replace non-text tokens with O. These will not be evaluated.\n",
    "        predictLabels.append('O')\n",
    "        trueLabels.append('O')\n",
    "        continue\n",
    "    if(lineLab == \"B-V\"):\n",
    "        predictLabels.append(\"V\")\n",
    "    else:\n",
    "        predictLabels.append(lineLab)\n",
    "        trueLabels.append(lineTok) \n",
    " \n",
    "# flatten the list of lists into a single list\n",
    "trueLabels = [item for sublist in trueLabels for item in sublist]\n",
    "predictLabels = [item for sublist in predictLabels for item in sublist]\n",
    "       \n",
    "result_f1 = f1_score(trueLabels, predictLabels,average=\"micro\")\n",
    "\n",
    "print(f\"result_f1: {result_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-12-01 15:45:42.204552: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-01 15:45:44.443682: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 15:45:47.634264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "#logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# dmis-lab/biobert-base-cased-v1.2\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-base-cased-v1.2', do_lower_case=True,truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"the a/t-rich mut sequence indicates that normal splicing was abolished by a g-to-a transition at the first nucleotide of intron 2.\"\n",
    "text1 = \"torc induction was abolished by deletion of the distal tor box (box1), which interrupt this open reading frame.\"\n",
    "text2 = \"torc induction was abolished by deletion of the distal tor box (box3), when demolish this writing frame.\"\n",
    "\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(\"[CLS] \" + text1 + \" [SEP]\")\n",
    "tokenized_text2 = tokenizer.tokenize(\"[CLS] \" + text2 + \" [SEP]\")\n",
    "\n",
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "indexed_tokens2 = tokenizer.convert_tokens_to_ids(tokenized_text2)\n",
    "\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "segments_ids2 = [1] * len(tokenized_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_text: [101, 1106, 19878, 18293, 1108, 8632, 1118, 3687, 26883, 1320, 1104, 1103, 4267, 19760, 1106, 1197, 2884, 113, 2884, 1475, 114, 117, 1134, 19717, 1142, 1501, 3455, 4207, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tokenized_text: {indexed_tokens}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(segments_ids))\n",
    "print(len(segments_ids2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "tokens_tensor2 = torch.tensor([indexed_tokens2])\n",
    "segments_tensors2 = torch.tensor([segments_ids2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                  output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                  )\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1686, -0.2858, -0.3261,  ..., -0.0276,  0.0383,  0.1640],\n",
       "          [-0.2659,  0.0911, -0.2904,  ..., -0.0518,  0.2286, -0.0701],\n",
       "          [-0.1257, -0.1021,  0.0349,  ..., -0.6787,  0.5009,  0.8158],\n",
       "          ...,\n",
       "          [ 0.7358,  0.3943,  0.0779,  ..., -0.6939, -0.3449, -0.0302],\n",
       "          [ 0.0593, -0.3172,  0.0352,  ...,  0.1207, -0.4333, -0.0917],\n",
       "          [-0.4895,  0.1848,  0.3578,  ..., -0.3979, -0.0418, -0.2135]]]),\n",
       " tensor([[[ 0.1778,  0.0206,  0.0094,  ..., -0.0476,  0.1028,  0.1027],\n",
       "          [-0.0802,  0.1250, -0.0769,  ...,  0.0508,  0.6060, -0.4218],\n",
       "          [ 0.0118,  0.0407, -0.3726,  ..., -0.9866,  0.8263,  0.6549],\n",
       "          ...,\n",
       "          [ 1.3002,  0.2144,  0.6183,  ..., -0.4371, -0.7979, -0.0119],\n",
       "          [ 0.0541, -0.2116,  0.2216,  ...,  0.2839, -0.3027, -0.3254],\n",
       "          [-0.2223,  0.1883,  0.2541,  ..., -0.5151,  0.3750, -0.1689]]]),\n",
       " tensor([[[ 0.1000, -0.2102, -0.0491,  ..., -0.0036, -0.0153,  0.0920],\n",
       "          [ 0.1070,  0.0310, -0.0383,  ...,  0.1757,  0.5379, -0.5025],\n",
       "          [-0.4677, -0.1140, -0.6522,  ..., -0.6893,  0.5559,  0.6513],\n",
       "          ...,\n",
       "          [ 1.4899,  0.2015,  0.2708,  ..., -0.4878, -0.8894,  0.1279],\n",
       "          [-0.2356, -0.3374,  0.2868,  ...,  0.4137, -0.3636, -0.1264],\n",
       "          [-0.2123, -0.1183,  0.2831,  ..., -0.2227,  0.3136, -0.2272]]]),\n",
       " tensor([[[ 0.0913, -0.1521,  0.0206,  ...,  0.0441,  0.0177,  0.1688],\n",
       "          [ 0.2949, -0.2286,  0.0739,  ...,  0.3620,  0.4095, -0.4206],\n",
       "          [-0.5660,  0.0311, -0.4741,  ..., -0.6570,  0.2359,  0.3800],\n",
       "          ...,\n",
       "          [ 1.6304,  0.0805,  0.3639,  ...,  0.1897, -0.7057, -0.1135],\n",
       "          [-0.5962, -0.5119,  0.4456,  ...,  0.2535, -0.3452, -0.3619],\n",
       "          [-0.0840, -0.0748,  0.1502,  ...,  0.0036,  0.0364, -0.0296]]]),\n",
       " tensor([[[ 0.1308, -0.4171, -0.2265,  ...,  0.0093,  0.1710,  0.4688],\n",
       "          [ 0.7472, -0.6520, -0.1213,  ...,  0.4984,  0.5750, -0.5272],\n",
       "          [-0.4281, -0.1668, -0.6851,  ..., -0.5059,  0.2981,  0.1352],\n",
       "          ...,\n",
       "          [ 1.5880,  0.4639,  0.9496,  ..., -0.2060, -0.3216,  0.1162],\n",
       "          [-0.9922, -0.9053,  0.5452,  ..., -0.5974, -0.4009, -0.3770],\n",
       "          [-0.0496, -0.0633,  0.0282,  ..., -0.0344,  0.0543,  0.0094]]]),\n",
       " tensor([[[-0.0401, -0.6772, -0.2631,  ..., -0.1030,  0.1882,  0.5832],\n",
       "          [ 0.5853, -0.2338, -0.4639,  ...,  0.5538,  0.8530, -0.0719],\n",
       "          [-0.1421,  0.2495, -0.6938,  ..., -0.7652,  0.3814,  0.1770],\n",
       "          ...,\n",
       "          [ 1.3585,  0.5003,  0.4463,  ...,  0.2012, -0.2145, -0.2209],\n",
       "          [-1.2394, -1.1005, -0.0339,  ..., -0.4816,  0.0291, -0.2719],\n",
       "          [-0.0261, -0.0508,  0.0321,  ...,  0.0149,  0.0094, -0.0249]]]),\n",
       " tensor([[[-0.0022, -0.7320, -0.5563,  ..., -0.2419, -0.0488,  0.6129],\n",
       "          [ 0.4891, -0.1354,  0.0799,  ...,  0.3091,  0.5820,  0.1732],\n",
       "          [-0.0553,  0.2430, -0.6071,  ..., -0.6998,  0.1863,  0.4275],\n",
       "          ...,\n",
       "          [ 1.4751,  0.2119,  0.0343,  ...,  0.2152, -0.0498, -0.0389],\n",
       "          [-1.0641, -0.7787,  0.1300,  ..., -0.9448,  0.0993, -0.1893],\n",
       "          [ 0.0137, -0.0488,  0.0087,  ...,  0.0038, -0.0285, -0.0387]]]),\n",
       " tensor([[[-0.4215, -0.6558, -0.4080,  ...,  0.2058,  0.1265,  0.6528],\n",
       "          [ 0.4407,  0.1792,  0.1771,  ...,  0.3474,  0.3758,  0.3490],\n",
       "          [-0.1292,  0.5487, -0.2287,  ..., -0.6784,  0.3514,  0.3932],\n",
       "          ...,\n",
       "          [ 1.2759, -0.0954,  0.7991,  ...,  0.3725,  0.2268, -0.1196],\n",
       "          [-1.3146, -1.1533,  0.1938,  ..., -0.7630,  0.3502, -0.0445],\n",
       "          [ 0.0213, -0.0171,  0.0328,  ..., -0.0043,  0.0215, -0.0388]]]),\n",
       " tensor([[[-6.2872e-01, -9.5742e-01, -3.6671e-01,  ..., -5.3258e-02,\n",
       "           -8.3488e-02,  6.7811e-01],\n",
       "          [ 2.2675e-01,  1.1865e-01,  3.0752e-01,  ..., -3.8235e-04,\n",
       "            3.2448e-01,  5.2462e-01],\n",
       "          [ 5.2309e-02,  3.3923e-01, -3.2009e-01,  ..., -9.4057e-01,\n",
       "           -9.4748e-02,  4.9101e-01],\n",
       "          ...,\n",
       "          [ 9.7363e-01, -5.1410e-01,  4.9835e-01,  ...,  4.5157e-01,\n",
       "            2.3260e-01, -7.4291e-02],\n",
       "          [-1.6793e+00, -1.3679e+00, -1.4466e-01,  ..., -3.4759e-01,\n",
       "           -1.1710e-01,  3.8453e-01],\n",
       "          [ 1.1299e-02, -5.4262e-02,  6.1458e-02,  ..., -3.5914e-02,\n",
       "           -2.2708e-02, -6.6156e-02]]]),\n",
       " tensor([[[-8.6242e-01, -5.2936e-01, -3.9180e-01,  ..., -2.4324e-01,\n",
       "           -6.4761e-02,  3.9209e-01],\n",
       "          [-3.5391e-04, -1.3004e-01,  3.1452e-02,  ..., -3.6318e-01,\n",
       "            5.0899e-01,  4.0565e-01],\n",
       "          [ 5.1928e-02,  4.0393e-01, -3.8411e-01,  ..., -9.6746e-01,\n",
       "           -7.9551e-02,  2.1189e-01],\n",
       "          ...,\n",
       "          [ 7.6887e-01, -3.9365e-01,  3.3451e-01,  ...,  2.8272e-01,\n",
       "           -1.3738e-01, -1.7344e-01],\n",
       "          [-1.5394e+00, -1.2286e+00, -6.3953e-01,  ..., -4.2061e-01,\n",
       "           -8.1443e-02,  2.4542e-01],\n",
       "          [ 4.1034e-02, -4.4493e-03,  1.2100e-02,  ..., -9.1969e-02,\n",
       "           -7.9203e-02, -2.3721e-02]]]),\n",
       " tensor([[[-1.1514, -0.5259, -0.1192,  ..., -0.2088, -0.1232,  0.3985],\n",
       "          [-0.2426, -0.4775,  0.0828,  ..., -0.3819,  0.5210,  0.4782],\n",
       "          [ 0.0374,  0.3940, -0.0896,  ..., -0.7586, -0.0356,  0.1636],\n",
       "          ...,\n",
       "          [ 0.4841, -0.5226,  0.3116,  ...,  0.4109, -0.1251,  0.0495],\n",
       "          [-1.2405, -1.0392, -0.2224,  ..., -0.1516,  0.0933,  0.6412],\n",
       "          [-0.0053,  0.0219, -0.0689,  ...,  0.0448, -0.0341,  0.0050]]]),\n",
       " tensor([[[-0.8665, -0.3595, -0.0880,  ..., -0.1060, -0.1043,  0.4725],\n",
       "          [-0.1574, -0.4977, -0.2502,  ..., -0.6825,  0.0433,  1.0496],\n",
       "          [ 0.2523,  0.5281, -0.2205,  ..., -0.5759, -0.2972,  0.3076],\n",
       "          ...,\n",
       "          [ 0.3775, -0.2958,  0.1795,  ...,  0.2023, -0.2887,  0.2988],\n",
       "          [-0.7912, -0.9862, -0.3685,  ...,  0.1868, -0.0372,  0.4220],\n",
       "          [ 0.0238,  0.0193, -0.0410,  ...,  0.0264, -0.0201,  0.0124]]]),\n",
       " tensor([[[-0.4771,  0.0626, -0.0724,  ...,  0.1989,  0.2751,  0.5593],\n",
       "          [-0.2376, -0.2702, -0.1184,  ..., -0.1776,  0.3517,  0.6783],\n",
       "          [-0.0287,  0.3490, -0.1473,  ..., -0.0835,  0.0473,  0.3525],\n",
       "          ...,\n",
       "          [ 0.0606, -0.1812,  0.0246,  ...,  0.1825, -0.0116,  0.4373],\n",
       "          [-0.3593, -0.4834, -0.2196,  ...,  0.3202,  0.3126,  0.2966],\n",
       "          [ 0.2160,  0.2671, -0.2992,  ...,  0.5929, -0.4620,  0.0945]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    outputs2 = model(tokens_tensor2, segments_tensors2)\n",
    "    hidden_states = outputs[2]\n",
    "    hidden_states2 = outputs2[2]\n",
    "outputs.hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings2 = torch.stack(hidden_states2, dim=0)\n",
    "\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings2 = torch.squeeze(token_embeddings2, dim=1)\n",
    "# Swap dimensions 0 and 1.\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings2 = token_embeddings2.permute(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "token_vecs_cat2 = []\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "    \n",
    "for token in token_embeddings2:\n",
    "    cat_vec2 = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    token_vecs_cat2.append(cat_vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test cosine similarity\n",
    "\n",
    "```python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_2_tensors(tensor1, tensor2):\n",
    "    \n",
    "    # Compute the dot product\n",
    "    dot_product = torch.dot(tensor1, tensor2)\n",
    "\n",
    "    # Compute the L2 (Euclidean) norms\n",
    "    norm_tensor1 = torch.norm(tensor1)\n",
    "    norm_tensor2 = torch.norm(tensor2)\n",
    "\n",
    "    # Calculate the cosine similarity\n",
    "    similarity = dot_product / (norm_tensor1 * norm_tensor2)\n",
    "\n",
    "    return similarity\n",
    "\n",
    "def cosine_similarity(sen1, sen2):\n",
    "    assert len(sen1) == len(sen2), \"Sentence lengths are not equal\"\n",
    "        \n",
    "    res_vec = []\n",
    "    for word in range(len(sen1)):\n",
    "        res_vec.append(cosine_similarity_2_tensors(sen1[word], sen2[word]))\n",
    "    return res_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9724),\n",
       " tensor(0.9487),\n",
       " tensor(0.9855),\n",
       " tensor(0.9867),\n",
       " tensor(0.9746),\n",
       " tensor(0.9765),\n",
       " tensor(0.9757),\n",
       " tensor(0.9840),\n",
       " tensor(0.9805),\n",
       " tensor(0.9894),\n",
       " tensor(0.9533),\n",
       " tensor(0.9677),\n",
       " tensor(0.9812),\n",
       " tensor(0.9790),\n",
       " tensor(0.9275),\n",
       " tensor(0.9729),\n",
       " tensor(0.9666),\n",
       " tensor(0.9850),\n",
       " tensor(0.9230),\n",
       " tensor(0.5345),\n",
       " tensor(0.9140),\n",
       " tensor(0.9237),\n",
       " tensor(0.6716),\n",
       " tensor(0.6131),\n",
       " tensor(0.5775),\n",
       " tensor(0.5866),\n",
       " tensor(0.5695),\n",
       " tensor(0.8508),\n",
       " tensor(0.9433),\n",
       " tensor(0.9849)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity_res = cosine_similarity(token_vecs_cat, token_vecs_cat2)\n",
    "cosine_similarity_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test cosine module similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_module_2_tensors(tensor1, tensor2):\n",
    "    cosine = cosine_similarity_2_tensors(tensor1, tensor2)\n",
    "    module = 1 - torch.abs(torch.norm(tensor1) - torch.norm(tensor2))/(torch.norm(tensor1) + torch.norm(tensor2))\n",
    "    \n",
    "    cosine_module = 1/2 * (cosine + module)\n",
    "\n",
    "    return cosine_module\n",
    "\n",
    "def cosine_module(sen1, sen2):\n",
    "    assert len(sen1) == len(sen2), \"Sentence lengths are not equal\"\n",
    "        \n",
    "    res_vec = []\n",
    "    for word in range(len(sen1)):\n",
    "        res_vec.append(cosine_module_2_tensors(sen1[word], sen2[word]))\n",
    "    return res_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.9729),\n",
       " tensor(0.9686),\n",
       " tensor(0.9924),\n",
       " tensor(0.9926),\n",
       " tensor(0.9818),\n",
       " tensor(0.9778),\n",
       " tensor(0.9816),\n",
       " tensor(0.9894),\n",
       " tensor(0.9820),\n",
       " tensor(0.9931),\n",
       " tensor(0.9692),\n",
       " tensor(0.9798),\n",
       " tensor(0.9903),\n",
       " tensor(0.9868),\n",
       " tensor(0.9493),\n",
       " tensor(0.9828),\n",
       " tensor(0.9830),\n",
       " tensor(0.9907),\n",
       " tensor(0.9526),\n",
       " tensor(0.6996),\n",
       " tensor(0.9545),\n",
       " tensor(0.9525),\n",
       " tensor(0.8316),\n",
       " tensor(0.7971),\n",
       " tensor(0.7316),\n",
       " tensor(0.7650),\n",
       " tensor(0.7807),\n",
       " tensor(0.9096),\n",
       " tensor(0.9647),\n",
       " tensor(0.9920)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_module_res = cosine_module(token_vecs_cat, token_vecs_cat2)\n",
    "cosine_module_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 15])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making and loading model\n",
    "import torch\n",
    "from models.model import multiTaskModel\n",
    "from utils.data_utils import TaskType, ModelType, NLP_MODELS\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "loadedDict = torch.load('./output/multi_task_model_0_1305.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "taskParams = loadedDict['task_params']\n",
    "\n",
    "modelName =taskParams.modelType.name.lower()\n",
    "_, _ , tokenizerClass, defaultName = NLP_MODELS[modelName]\n",
    "configName = taskParams.modelConfig\n",
    "\n",
    "#making tokenizer for model\n",
    "tokenizer = tokenizerClass.from_pretrained(configName)\n",
    "\n",
    "\n",
    "allParams = {}\n",
    "allParams['task_params'] = taskParams\n",
    "allParams['gpu'] = torch.cuda.is_available()\n",
    "# dummy values\n",
    "allParams['num_train_steps'] = 10\n",
    "allParams['warmup_steps'] = 0\n",
    "allParams['learning_rate'] = 2e-5\n",
    "allParams['epsilon'] = 1e-8\n",
    "\n",
    "model = multiTaskModel(allParams)\n",
    "model.load_multi_task_model(loadedDict)\n",
    "\n",
    "\n",
    "attention_masks = torch.tensor([[1] * 30])\n",
    "with torch.no_grad():\n",
    "    output = model.network(tokens_tensor, segments_tensors, attention_masks, 0, 'conllsrl')\n",
    "\n",
    "output[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "token_embeddings.size()\n",
    "\n",
    "# Stores the token vectors, with shape [22 x 3,072]\n",
    "token_vecs_cat = []\n",
    "\n",
    "# `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    \n",
    "    # `token` is a [12 x 768] tensor\n",
    "\n",
    "    # Concatenate the vectors (that is, append them together) from the last \n",
    "    # four layers.\n",
    "    # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "    cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "    \n",
    "    # Use `cat_vec` to represent `token`.\n",
    "    token_vecs_cat.append(cat_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_cat), len(token_vecs_cat[0])))\n",
    "print(token_vecs_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2377: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskName :  odict_values(['conllsrl'])\n",
      "allTasksList :  [{'data_task_id': 0, 'data_': [{'uid': 0, 'label': [12, 2, 13, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], 'token_id': [101, 1045, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'type_id': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'mask': [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}], 'data_task_type': <TaskType.NER: 3>, 'data_task_name': 'conllsrl'}]\n",
      "inferDataLoader :  <torch.utils.data.dataloader.DataLoader object at 0x7fa01171aeb0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n"
     ]
    }
   ],
   "source": [
    "text = [\"in addition, deletion of the distal tor box (box1) abolished torc induction whereas the presence of a dna fragment starting three bases upstream from box1 suffices for normal torc expression.\"]\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from infer_pipeline import inferPipeline\n",
    "from utils.data_utils import TaskType\n",
    "pipe = inferPipeline(modelPath='./output/multi_task_model_8_367.pt', maxSeqLen=50)\n",
    "\n",
    "data = pipe.infer(text, ['conllsrl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "def read_data(readPath):\n",
    "    \n",
    "    with open(readPath, 'r', encoding = 'utf-8') as file:\n",
    "        taskData = []\n",
    "        for i, line in enumerate(file):\n",
    "            sample = json.loads(line)\n",
    "            taskData.append(sample)\n",
    "            \n",
    "    return taskData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from models.model import multiTaskModel\n",
    "\n",
    "def get_embedding_finetuned(dataDir, readFile, wrtDir):\n",
    "    data = read_data(os.path.join(dataDir, readFile))\n",
    "    \n",
    "    # Load finetuned model \n",
    "    loadedDict = torch.load('../output/multi_task_model_9_13050.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "    taskParams = loadedDict['task_params']\n",
    "\n",
    "    allParams = {}\n",
    "    allParams['task_params'] = taskParams\n",
    "    allParams['gpu'] = torch.cuda.is_available()\n",
    "    # dummy values\n",
    "    allParams['num_train_steps'] = 10\n",
    "    allParams['warmup_steps'] = 0\n",
    "    allParams['learning_rate'] = 2e-5\n",
    "    allParams['epsilon'] = 1e-8\n",
    "\n",
    "   \n",
    "    model = multiTaskModel(allParams)\n",
    "    model.load_multi_task_model(loadedDict)\n",
    "    \n",
    "    for i, line in enumerate(data):\n",
    "        tokens_id = line['token_id']\n",
    "        segments_id = line['type_id']\n",
    "        u_id = line['uid']\n",
    "        attention_mask = line['mask']\n",
    "        \n",
    "        # Convert inputs to PyTorch tensors\n",
    "        tokens_tensor = torch.tensor([tokens_id])\n",
    "        \n",
    "        segments_tensors = torch.tensor([segments_id])\n",
    "        \n",
    "        print(\"Processed {} rows...\".format(i))\n",
    "        with torch.no_grad():\n",
    "            outputs = model.network(tokens_tensor, segments_tensors, attention_mask, 0, 'conllsrl')\n",
    "            print(\"\")\n",
    "            hidden_states = outputs[1][2]\n",
    "            print(\"done {} rows...\".format(i))\n",
    "        # `hidden_states` is a Python list.\n",
    "        # Each layer in the list is a torch tensor.\n",
    "        # `token_vecs` is a tensor with shape [50 x 768]\n",
    "        \n",
    "        ## WORD EMBEDDING\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "\n",
    "        token_embeddings.size()\n",
    "\n",
    "        # Stores the token vectors, with shape [22 x 3,072]\n",
    "        token_vecs_cat = []\n",
    "\n",
    "        # `token_embeddings` is a [22 x 12 x 768] tensor.\n",
    "\n",
    "        # For each token in the sentence...\n",
    "        for token in token_embeddings:\n",
    "            # `token` is a [12 x 768] tensor\n",
    "\n",
    "            # Concatenate the vectors (that is, append them together) from the last four layers.\n",
    "            # Each layer vector is 768 values, so `cat_vec` is length 3,072.\n",
    "            cat_vec = torch.cat((token[-1], token[-2], token[-3], token[-4]), dim=0)\n",
    "            \n",
    "            # Use `cat_vec` to represent `token`.\n",
    "            token_vecs_cat.append(cat_vec)\n",
    "\n",
    "        features = {\n",
    "                'uid': u_id,\n",
    "                'vec': token_vecs_cat}\n",
    "        # write u_id and token_vecs_cat to file\n",
    "        with open(os.path.join(wrtDir, 'finetuned_vecs_{}.pkl'.format(readFile.split('.')[0])), 'wb') as vecs_wri:\n",
    "            pickle.dump(features, vecs_wri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n",
      "/home/phatpham/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataDir = '/mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/data/coNLL_tsv/bert-base-uncased_prepared_data/'\n",
    "readFile = 'ner_conll_testa_abolish.json'\n",
    "wriDir = 'test_get_embedding_finetuned'\n",
    "vec_finetuned = get_embedding_finetuned(dataDir, readFile, wriDir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "def read_json_file(dirPath, wrtDir):\n",
    "    files = []\n",
    "    for path in os.listdir(dirPath):\n",
    "        if os.path.isfile(os.path.join(dirPath, path)):\n",
    "            files.append(path)\n",
    "            \n",
    "    \n",
    "    for file in files:\n",
    "        with open(os.path.join(dirPath, file), 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "            \n",
    "        vec_origin = get_embedding(data)\n",
    "        vec_finetuned = get_embedding_finetuned(data)\n",
    "        cosine = cosine_similarity(vec_origin, vec_finetuned)\n",
    "        cosine_module = cosine_module(vec_origin, vec_finetuned)\n",
    "        \n",
    "        features = {'uid': data['uid'], 'cosine': cosine, 'cosine_module': cosine_module}\n",
    "        with open(os.path.join(wrtDir, 'vecs_{}.pkl'.format(file.split('.')[0])), 'wb') as vecs_wri:\n",
    "            pickle.dump(features, vecs_wri)\n",
    "    return data\n",
    "\n",
    "data = read_json_file('./word_vecs_output/')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  280\n",
      "outputs:  3\n",
      "Number of layers: 13   (initial embeddings + 12 BERT layers)\n",
      "Number of batches: 1\n",
      "Number of tokens: 50\n",
      "Number of hidden units: 768\n",
      "      Type of hidden_states:  <class 'tuple'>\n",
      "Tensor shape for each layer:  torch.Size([1, 50, 768])\n",
      "Our final sentence embedding vector of shape: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertConfig, BertModel, BertTokenizer\n",
    "\n",
    "data = read_data('/mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/data/coNLL_tsv/bert-base-uncased_prepared_data/ner_conll_testa_abolish.json')\n",
    "    \n",
    "print(\"data shape: \", len(data))  # 280\n",
    "tokens_id = data[0]['token_id']\n",
    "segments_id = data[0]['type_id']\n",
    "\n",
    "\n",
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([tokens_id])\n",
    "segments_tensors = torch.tensor([segments_id])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('dmis-lab/biobert-base-cased-v1.2',\n",
    "                                output_hidden_states = True # Whether the model returns all hidden-states.\n",
    "                                )\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(tokens_tensor, segments_tensors)\n",
    "    print(\"outputs: \", len(outputs)) # 2\n",
    "    hidden_states = outputs[2]\n",
    "    \n",
    "    \n",
    "print (\"Number of layers:\", len(hidden_states), \"  (initial embeddings + 12 BERT layers)\")  #13\n",
    "layer_i = 0\n",
    "\n",
    "print (\"Number of batches:\", len(hidden_states[layer_i])) #1\n",
    "batch_i = 0\n",
    "\n",
    "print (\"Number of tokens:\", len(hidden_states[layer_i][batch_i])) #50\n",
    "token_i = 0\n",
    "\n",
    "print (\"Number of hidden units:\", len(hidden_states[layer_i][batch_i][token_i]))     # 768\n",
    "\n",
    "\n",
    "# `hidden_states` is a Python list.\n",
    "print('      Type of hidden_states: ', type(hidden_states)) # <class 'tuple'>\n",
    "\n",
    "# Each layer in the list is a torch tensor.\n",
    "print('Tensor shape for each layer: ', hidden_states[0].size()) # torch.Size([1, 50, 768])\n",
    "\n",
    "\n",
    "## Sentence Vectors\n",
    "# `hidden_states` has shape [13 x 1 x 50 x 768]\n",
    "\n",
    "# `token_vecs` is a tensor with shape [50 x 768]\n",
    "token_vecs = hidden_states[-2][0]\n",
    "\n",
    "# Calculate the average of all 22 token vectors.\n",
    "sentence_embedding = torch.mean(token_vecs, dim=0)\n",
    "print (\"Our final sentence embedding vector of shape:\", sentence_embedding.size()) # torch.Size([768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_vecs_cat:  2\n",
      "['22110', '22111', '22112', '22113', '22114', '22115', '22116', '22117', '22118', '22119', '22120', '22121', '22122', '22123', '22124', '22125', '22126', '22127', '22128', '22129', '22130', '22131', '22132', '22133', '22134', '22135', '22136', '22137', '22138', '22139', '22140', '22141']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('models/outputs.pkl', 'rb') as f:\n",
    "    token_vecs_cat = pickle.load(f)\n",
    "\n",
    "print(\"token_vecs_cat: \", len(token_vecs_cat)) # 50\n",
    "print(token_vecs_cat['uid']) # (3072,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'reduction'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/Phat Pham/Documents/THESIS/SRL-for-BioBERT/test.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Phat%20Pham/Documents/THESIS/SRL-for-BioBERT/test.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m, requires_grad\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Phat%20Pham/Documents/THESIS/SRL-for-BioBERT/test.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m3\u001b[39m, \u001b[39m5\u001b[39m)\u001b[39m.\u001b[39msoftmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Phat%20Pham/Documents/THESIS/SRL-for-BioBERT/test.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m output \u001b[39m=\u001b[39m loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Phat%20Pham/Documents/THESIS/SRL-for-BioBERT/test.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/Phat%20Pham/Documents/THESIS/SRL-for-BioBERT/test.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mbackward())\n",
      "File \u001b[0;32m~/anaconda3/envs/min_ds-env/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'reduction'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# Example of target with class indices\n",
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "print(output.backward())\n",
    "\n",
    "# Example of target with class probabilities\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5).softmax(dim=1)\n",
    "output = loss(input, target)\n",
    "print(output.shape)\n",
    "print(output.backward())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
